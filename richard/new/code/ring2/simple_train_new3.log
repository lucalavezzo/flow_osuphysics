['Network', 'BayBridgeNetwork', 'BayBridgeTollNetwork', 'BottleneckNetwork', 'FigureEightNetwork', 'TrafficLightGridNetwork', 'HighwayNetwork', 'RingNetwork', 'MergeNetwork', 'MultiRingNetwork', 'MiniCityNetwork', 'HighwayRampsNetwork']
['Env', 'AccelEnv', 'LaneChangeAccelEnv', 'LaneChangeAccelPOEnv', 'TrafficLightGridTestEnv', 'MergePOEnv', 'BottleneckEnv', 'BottleneckAccelEnv', 'WaveAttenuationEnv', 'WaveAttenuationPOEnv', 'TrafficLightGridEnv', 'TrafficLightGridPOEnv', 'BottleneckDesiredVelocityEnv', 'TestEnv', 'BayBridgeEnv', 'BottleNeckAccelEnv', 'DesiredVelocityEnv', 'PO_TrafficLightGridEnv', 'GreenWaveTestEnv']
WARNING:tensorflow:From /users/PYS1027/chnrhughes/.local/lib/python3.5/site-packages/tensorflow/python/compat/v2_compat.py:61: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.
Instructions for updating:
non-resource variables are not supported in the long term
2020-03-24 14:35:42,888	INFO node.py:498 -- Process STDOUT and STDERR is being redirected to /tmp/ray/session_2020-03-24_14-35-42_888204_143656/logs.
2020-03-24 14:35:43,001	INFO services.py:409 -- Waiting for redis server at 127.0.0.1:27270 to respond...
2020-03-24 14:35:43,116	INFO services.py:409 -- Waiting for redis server at 127.0.0.1:44228 to respond...
2020-03-24 14:35:43,116	INFO services.py:809 -- Starting Redis shard with 10.0 GB max memory.
2020-03-24 14:35:43,141	INFO node.py:512 -- Process STDOUT and STDERR is being redirected to /tmp/ray/session_2020-03-24_14-35-42_888204_143656/logs.
2020-03-24 14:35:43,142	WARNING services.py:1301 -- Warning: Capping object memory store to 20.0GB. To increase this further, specify `object_store_memory` when calling ray.init() or ray start.
2020-03-24 14:35:43,142	INFO services.py:1475 -- Starting the Plasma object store with 20.0 GB memory using /dev/shm.
2020-03-24 14:35:43,213	INFO trial_runner.py:176 -- Starting a new experiment.
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 0/2 CPUs, 0/0 GPUs
Memory usage on this node: 11.4/201.2 GB

2020-03-24 14:35:43,219	WARNING signature.py:108 -- The function with_updates has a **kwargs argument, which is currently not supported.
WARNING:tensorflow:From /users/PYS1027/chnrhughes/.local/lib/python3.5/site-packages/ray/tune/logger.py:133: The name tf.VERSION is deprecated. Please use tf.version.VERSION instead.

WARNING:tensorflow:From /users/PYS1027/chnrhughes/.local/lib/python3.5/site-packages/ray/tune/logger.py:138: The name tf.summary.FileWriter is deprecated. Please use tf.compat.v1.summary.FileWriter instead.

2020-03-24 14:35:43,231	ERROR log_sync.py:34 -- Log sync requires cluster to be setup with `ray up`.
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2/2 CPUs, 0/0 GPUs
Memory usage on this node: 11.5/201.2 GB
Result logdir: /users/PYS1027/chnrhughes/ray_results/simple_training_example_ring_v1
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - PPO_WaveAttenuationPOEnv-v0_0:	RUNNING

[2m[36m(pid=143796)[0m WARNING:tensorflow:From /users/PYS1027/chnrhughes/.local/lib/python3.5/site-packages/tensorflow/python/compat/v2_compat.py:61: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.
[2m[36m(pid=143796)[0m Instructions for updating:
[2m[36m(pid=143796)[0m non-resource variables are not supported in the long term
[2m[36m(pid=143796)[0m 2020-03-24 14:35:47,445	WARNING ppo.py:143 -- FYI: By default, the value function will not share layers with the policy model ('vf_share_layers': False).
[2m[36m(pid=143796)[0m 2020-03-24 14:35:48,570	INFO rollout_worker.py:319 -- Creating policy evaluation worker 0 on CPU (please ignore any CUDA init errors)
[2m[36m(pid=143796)[0m 2020-03-24 14:35:48.571588: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
[2m[36m(pid=143796)[0m 2020-03-24 14:35:48.576997: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2400000000 Hz
[2m[36m(pid=143796)[0m 2020-03-24 14:35:48.578676: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x6439140 executing computations on platform Host. Devices:
[2m[36m(pid=143796)[0m 2020-03-24 14:35:48.578707: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
[2m[36m(pid=143796)[0m WARNING:tensorflow:From /users/PYS1027/chnrhughes/.local/lib/python3.5/site-packages/ray/rllib/models/tf/fcnet_v1.py:48: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.
[2m[36m(pid=143796)[0m Instructions for updating:
[2m[36m(pid=143796)[0m Use keras.layers.dense instead.
[2m[36m(pid=143796)[0m WARNING:tensorflow:From /users/PYS1027/chnrhughes/.local/lib/python3.5/site-packages/ray/rllib/models/tf/fcnet_v1.py:48: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.
[2m[36m(pid=143796)[0m Instructions for updating:
[2m[36m(pid=143796)[0m Use keras.layers.dense instead.
[2m[36m(pid=143796)[0m WARNING:tensorflow:From /users/PYS1027/chnrhughes/.local/lib/python3.5/site-packages/ray/rllib/models/tf/tf_action_dist.py:138: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
[2m[36m(pid=143796)[0m Instructions for updating:
[2m[36m(pid=143796)[0m Use `tf.cast` instead.
[2m[36m(pid=143796)[0m WARNING:tensorflow:From /users/PYS1027/chnrhughes/.local/lib/python3.5/site-packages/ray/rllib/models/tf/tf_action_dist.py:138: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
[2m[36m(pid=143796)[0m Instructions for updating:
[2m[36m(pid=143796)[0m Use `tf.cast` instead.
[2m[36m(pid=143796)[0m 2020-03-24 14:35:49.009657: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1412] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.
[2m[36m(pid=143796)[0m 2020-03-24 14:35:49,025	INFO dynamic_tf_policy.py:324 -- Initializing loss function with dummy input:
[2m[36m(pid=143796)[0m 
[2m[36m(pid=143796)[0m { 'action_prob': <tf.Tensor 'default_policy/action_prob:0' shape=(?,) dtype=float32>,
[2m[36m(pid=143796)[0m   'actions': <tf.Tensor 'default_policy/actions:0' shape=(?, 1) dtype=float32>,
[2m[36m(pid=143796)[0m   'advantages': <tf.Tensor 'default_policy/advantages:0' shape=(?,) dtype=float32>,
[2m[36m(pid=143796)[0m   'behaviour_logits': <tf.Tensor 'default_policy/behaviour_logits:0' shape=(?, 2) dtype=float32>,
[2m[36m(pid=143796)[0m   'dones': <tf.Tensor 'default_policy/dones:0' shape=(?,) dtype=bool>,
[2m[36m(pid=143796)[0m   'new_obs': <tf.Tensor 'default_policy/new_obs:0' shape=(?, 3) dtype=float32>,
[2m[36m(pid=143796)[0m   'obs': <tf.Tensor 'default_policy/observation:0' shape=(?, 3) dtype=float32>,
[2m[36m(pid=143796)[0m   'prev_actions': <tf.Tensor 'default_policy/action:0' shape=(?, 1) dtype=float32>,
[2m[36m(pid=143796)[0m   'prev_rewards': <tf.Tensor 'default_policy/prev_reward:0' shape=(?,) dtype=float32>,
[2m[36m(pid=143796)[0m   'rewards': <tf.Tensor 'default_policy/rewards:0' shape=(?,) dtype=float32>,
[2m[36m(pid=143796)[0m   'value_targets': <tf.Tensor 'default_policy/value_targets:0' shape=(?,) dtype=float32>,
[2m[36m(pid=143796)[0m   'vf_preds': <tf.Tensor 'default_policy/vf_preds:0' shape=(?,) dtype=float32>}
[2m[36m(pid=143796)[0m 
[2m[36m(pid=143796)[0m WARNING:tensorflow:From /users/PYS1027/chnrhughes/.local/lib/python3.5/site-packages/tensorflow/python/ops/array_ops.py:1354: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
[2m[36m(pid=143796)[0m Instructions for updating:
[2m[36m(pid=143796)[0m Use tf.where in 2.0, which has the same broadcast rule as np.where
[2m[36m(pid=143796)[0m WARNING:tensorflow:From /users/PYS1027/chnrhughes/.local/lib/python3.5/site-packages/tensorflow/python/ops/array_ops.py:1354: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
[2m[36m(pid=143796)[0m Instructions for updating:
[2m[36m(pid=143796)[0m Use tf.where in 2.0, which has the same broadcast rule as np.where
[2m[36m(pid=143796)[0m 2020-03-24 14:35:49,793	INFO rollout_worker.py:742 -- Built policy map: {'default_policy': <ray.rllib.policy.tf_policy_template.PPOTFPolicy object at 0x2b674ad58c18>}
[2m[36m(pid=143796)[0m 2020-03-24 14:35:49,793	INFO rollout_worker.py:743 -- Built preprocessor map: {'default_policy': <ray.rllib.models.preprocessors.NoPreprocessor object at 0x2b674ad58b38>}
[2m[36m(pid=143796)[0m 2020-03-24 14:35:49,793	INFO rollout_worker.py:356 -- Built filter map: {'default_policy': <ray.rllib.utils.filter.NoFilter object at 0x2b674ad589e8>}
[2m[36m(pid=143796)[0m 2020-03-24 14:35:49,821	INFO multi_gpu_optimizer.py:93 -- LocalMultiGPUOptimizer devices ['/cpu:0']
[2m[36m(pid=143796)[0m 2020-03-24 14:35:52,240	WARNING util.py:47 -- Install gputil for GPU system monitoring.
[2m[36m(pid=143796)[0m WARNING:tensorflow:From /users/PYS1027/chnrhughes/.local/lib/python3.5/site-packages/ray/rllib/policy/tf_policy.py:570: Variable.load (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
[2m[36m(pid=143796)[0m Instructions for updating:
[2m[36m(pid=143796)[0m Prefer Variable.assign which has equivalent behavior in 2.X.
[2m[36m(pid=143796)[0m WARNING:tensorflow:From /users/PYS1027/chnrhughes/.local/lib/python3.5/site-packages/ray/rllib/policy/tf_policy.py:570: Variable.load (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
[2m[36m(pid=143796)[0m Instructions for updating:
[2m[36m(pid=143796)[0m Prefer Variable.assign which has equivalent behavior in 2.X.
[2m[36m(pid=143797)[0m WARNING:tensorflow:From /users/PYS1027/chnrhughes/.local/lib/python3.5/site-packages/tensorflow/python/compat/v2_compat.py:61: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.
[2m[36m(pid=143797)[0m Instructions for updating:
[2m[36m(pid=143797)[0m non-resource variables are not supported in the long term
[2m[36m(pid=143797)[0m 2020-03-24 14:35:54,723	INFO rollout_worker.py:319 -- Creating policy evaluation worker 1 on CPU (please ignore any CUDA init errors)
[2m[36m(pid=143797)[0m 2020-03-24 14:35:54.741856: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
[2m[36m(pid=143797)[0m 2020-03-24 14:35:54.745942: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2400000000 Hz
[2m[36m(pid=143797)[0m 2020-03-24 14:35:54.747526: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5cbc9d0 executing computations on platform Host. Devices:
[2m[36m(pid=143797)[0m 2020-03-24 14:35:54.747561: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
[2m[36m(pid=143797)[0m WARNING:tensorflow:From /users/PYS1027/chnrhughes/.local/lib/python3.5/site-packages/ray/rllib/models/tf/fcnet_v1.py:48: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.
[2m[36m(pid=143797)[0m Instructions for updating:
[2m[36m(pid=143797)[0m Use keras.layers.dense instead.
[2m[36m(pid=143797)[0m WARNING:tensorflow:From /users/PYS1027/chnrhughes/.local/lib/python3.5/site-packages/ray/rllib/models/tf/fcnet_v1.py:48: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.
[2m[36m(pid=143797)[0m Instructions for updating:
[2m[36m(pid=143797)[0m Use keras.layers.dense instead.
[2m[36m(pid=143797)[0m WARNING:tensorflow:From /users/PYS1027/chnrhughes/.local/lib/python3.5/site-packages/ray/rllib/models/tf/tf_action_dist.py:138: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
[2m[36m(pid=143797)[0m Instructions for updating:
[2m[36m(pid=143797)[0m Use `tf.cast` instead.
[2m[36m(pid=143797)[0m WARNING:tensorflow:From /users/PYS1027/chnrhughes/.local/lib/python3.5/site-packages/ray/rllib/models/tf/tf_action_dist.py:138: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
[2m[36m(pid=143797)[0m Instructions for updating:
[2m[36m(pid=143797)[0m Use `tf.cast` instead.
[2m[36m(pid=143797)[0m 2020-03-24 14:35:55.163478: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1412] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.
[2m[36m(pid=143797)[0m 2020-03-24 14:35:55,179	INFO dynamic_tf_policy.py:324 -- Initializing loss function with dummy input:
[2m[36m(pid=143797)[0m 
[2m[36m(pid=143797)[0m { 'action_prob': <tf.Tensor 'default_policy/action_prob:0' shape=(?,) dtype=float32>,
[2m[36m(pid=143797)[0m   'actions': <tf.Tensor 'default_policy/actions:0' shape=(?, 1) dtype=float32>,
[2m[36m(pid=143797)[0m   'advantages': <tf.Tensor 'default_policy/advantages:0' shape=(?,) dtype=float32>,
[2m[36m(pid=143797)[0m   'behaviour_logits': <tf.Tensor 'default_policy/behaviour_logits:0' shape=(?, 2) dtype=float32>,
[2m[36m(pid=143797)[0m   'dones': <tf.Tensor 'default_policy/dones:0' shape=(?,) dtype=bool>,
[2m[36m(pid=143797)[0m   'new_obs': <tf.Tensor 'default_policy/new_obs:0' shape=(?, 3) dtype=float32>,
[2m[36m(pid=143797)[0m   'obs': <tf.Tensor 'default_policy/observation:0' shape=(?, 3) dtype=float32>,
[2m[36m(pid=143797)[0m   'prev_actions': <tf.Tensor 'default_policy/action:0' shape=(?, 1) dtype=float32>,
[2m[36m(pid=143797)[0m   'prev_rewards': <tf.Tensor 'default_policy/prev_reward:0' shape=(?,) dtype=float32>,
[2m[36m(pid=143797)[0m   'rewards': <tf.Tensor 'default_policy/rewards:0' shape=(?,) dtype=float32>,
[2m[36m(pid=143797)[0m   'value_targets': <tf.Tensor 'default_policy/value_targets:0' shape=(?,) dtype=float32>,
[2m[36m(pid=143797)[0m   'vf_preds': <tf.Tensor 'default_policy/vf_preds:0' shape=(?,) dtype=float32>}
[2m[36m(pid=143797)[0m 
[2m[36m(pid=143797)[0m WARNING:tensorflow:From /users/PYS1027/chnrhughes/.local/lib/python3.5/site-packages/tensorflow/python/ops/array_ops.py:1354: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
[2m[36m(pid=143797)[0m Instructions for updating:
[2m[36m(pid=143797)[0m Use tf.where in 2.0, which has the same broadcast rule as np.where
[2m[36m(pid=143797)[0m WARNING:tensorflow:From /users/PYS1027/chnrhughes/.local/lib/python3.5/site-packages/tensorflow/python/ops/array_ops.py:1354: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
[2m[36m(pid=143797)[0m Instructions for updating:
[2m[36m(pid=143797)[0m Use tf.where in 2.0, which has the same broadcast rule as np.where
[2m[36m(pid=143797)[0m WARNING:tensorflow:From /users/PYS1027/chnrhughes/.local/lib/python3.5/site-packages/ray/rllib/policy/tf_policy.py:570: Variable.load (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
[2m[36m(pid=143797)[0m Instructions for updating:
[2m[36m(pid=143797)[0m Prefer Variable.assign which has equivalent behavior in 2.X.
[2m[36m(pid=143797)[0m WARNING:tensorflow:From /users/PYS1027/chnrhughes/.local/lib/python3.5/site-packages/ray/rllib/policy/tf_policy.py:570: Variable.load (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
[2m[36m(pid=143797)[0m Instructions for updating:
[2m[36m(pid=143797)[0m Prefer Variable.assign which has equivalent behavior in 2.X.
[2m[36m(pid=143797)[0m 
[2m[36m(pid=143797)[0m -----------------------
[2m[36m(pid=143797)[0m ring length: 507
[2m[36m(pid=143797)[0m v_max: 12.825950528689797
[2m[36m(pid=143797)[0m -----------------------
[2m[36m(pid=143797)[0m 2020-03-24 14:35:55,975	INFO rollout_worker.py:451 -- Generating sample batch of size 200
[2m[36m(pid=143797)[0m 2020-03-24 14:35:59,162	INFO sampler.py:304 -- Raw obs from env: { 0: { 'agent0': np.ndarray((3,), dtype=float64, min=-0.009, max=0.828, mean=0.286)}}
[2m[36m(pid=143797)[0m 2020-03-24 14:35:59,162	INFO sampler.py:305 -- Info return from env: {0: {'agent0': None}}
[2m[36m(pid=143797)[0m 2020-03-24 14:35:59,163	INFO sampler.py:403 -- Preprocessed obs: np.ndarray((3,), dtype=float64, min=-0.009, max=0.828, mean=0.286)
[2m[36m(pid=143797)[0m 2020-03-24 14:35:59,163	INFO sampler.py:407 -- Filtered obs: np.ndarray((3,), dtype=float64, min=-0.009, max=0.828, mean=0.286)
[2m[36m(pid=143797)[0m 2020-03-24 14:35:59,163	INFO sampler.py:521 -- Inputs to compute_actions():
[2m[36m(pid=143797)[0m 
[2m[36m(pid=143797)[0m { 'default_policy': [ { 'data': { 'agent_id': 'agent0',
[2m[36m(pid=143797)[0m                                   'env_id': 0,
[2m[36m(pid=143797)[0m                                   'info': None,
[2m[36m(pid=143797)[0m                                   'obs': np.ndarray((3,), dtype=float64, min=-0.009, max=0.828, mean=0.286),
[2m[36m(pid=143797)[0m                                   'prev_action': np.ndarray((1,), dtype=float32, min=0.0, max=0.0, mean=0.0),
[2m[36m(pid=143797)[0m                                   'prev_reward': 0.0,
[2m[36m(pid=143797)[0m                                   'rnn_state': []},
[2m[36m(pid=143797)[0m                         'type': 'PolicyEvalData'}]}
[2m[36m(pid=143797)[0m 
[2m[36m(pid=143797)[0m 2020-03-24 14:35:59,164	INFO tf_run_builder.py:92 -- Executing TF run without tracing. To dump TF timeline traces to disk, set the TF_TIMELINE_DIR environment variable.
[2m[36m(pid=143797)[0m 2020-03-24 14:35:59,197	INFO sampler.py:548 -- Outputs of compute_actions():
[2m[36m(pid=143797)[0m 
[2m[36m(pid=143797)[0m { 'default_policy': ( np.ndarray((1, 1), dtype=float32, min=0.023, max=0.023, mean=0.023),
[2m[36m(pid=143797)[0m                       [],
[2m[36m(pid=143797)[0m                       { 'action_prob': np.ndarray((1,), dtype=float32, min=0.397, max=0.397, mean=0.397),
[2m[36m(pid=143797)[0m                         'behaviour_logits': np.ndarray((1, 2), dtype=float32, min=0.002, max=0.005, mean=0.004),
[2m[36m(pid=143797)[0m                         'vf_preds': np.ndarray((1,), dtype=float32, min=0.007, max=0.007, mean=0.007)})}
[2m[36m(pid=143797)[0m 
[2m[36m(pid=143797)[0m 2020-03-24 14:36:00,016	INFO sample_batch_builder.py:161 -- Trajectory fragment after postprocess_trajectory():
[2m[36m(pid=143797)[0m 
[2m[36m(pid=143797)[0m { 'agent0': { 'data': { 'action_prob': np.ndarray((200,), dtype=float32, min=0.001, max=0.397, mean=0.276),
[2m[36m(pid=143797)[0m                         'actions': np.ndarray((200, 1), dtype=float32, min=-3.359, max=2.369, mean=-0.054),
[2m[36m(pid=143797)[0m                         'advantages': np.ndarray((200,), dtype=float32, min=-11.886, max=4.782, mean=-4.061),
[2m[36m(pid=143797)[0m                         'agent_index': np.ndarray((200,), dtype=int64, min=0.0, max=0.0, mean=0.0),
[2m[36m(pid=143797)[0m                         'behaviour_logits': np.ndarray((200, 2), dtype=float32, min=0.002, max=0.005, mean=0.003),
[2m[36m(pid=143797)[0m                         'dones': np.ndarray((200,), dtype=bool, min=0.0, max=0.0, mean=0.0),
[2m[36m(pid=143797)[0m                         'eps_id': np.ndarray((200,), dtype=int64, min=1790170181.0, max=1790170181.0, mean=1790170181.0),
[2m[36m(pid=143797)[0m                         'infos': np.ndarray((200,), dtype=object, head={}),
[2m[36m(pid=143797)[0m                         'new_obs': np.ndarray((200, 3), dtype=float32, min=-0.012, max=0.827, mean=0.288),
[2m[36m(pid=143797)[0m                         'obs': np.ndarray((200, 3), dtype=float32, min=-0.012, max=0.828, mean=0.288),
[2m[36m(pid=143797)[0m                         'prev_actions': np.ndarray((200, 1), dtype=float32, min=-3.359, max=2.369, mean=-0.044),
[2m[36m(pid=143797)[0m                         'prev_rewards': np.ndarray((200,), dtype=float32, min=-1.581, max=2.407, mean=-0.095),
[2m[36m(pid=143797)[0m                         'rewards': np.ndarray((200,), dtype=float32, min=-1.582, max=2.407, mean=-0.103),
[2m[36m(pid=143797)[0m                         't': np.ndarray((200,), dtype=int64, min=0.0, max=199.0, mean=99.5),
[2m[36m(pid=143797)[0m                         'unroll_id': np.ndarray((200,), dtype=int64, min=0.0, max=0.0, mean=0.0),
[2m[36m(pid=143797)[0m                         'value_targets': np.ndarray((200,), dtype=float32, min=-11.88, max=4.789, mean=-4.054),
[2m[36m(pid=143797)[0m                         'vf_preds': np.ndarray((200,), dtype=float32, min=0.006, max=0.007, mean=0.007)},
[2m[36m(pid=143797)[0m               'type': 'SampleBatch'}}
[2m[36m(pid=143797)[0m 
[2m[36m(pid=143797)[0m 2020-03-24 14:36:00,018	INFO rollout_worker.py:485 -- Completed sample batch:
[2m[36m(pid=143797)[0m 
[2m[36m(pid=143797)[0m { 'data': { 'action_prob': np.ndarray((200,), dtype=float32, min=0.001, max=0.397, mean=0.276),
[2m[36m(pid=143797)[0m             'actions': np.ndarray((200, 1), dtype=float32, min=-3.359, max=2.369, mean=-0.054),
[2m[36m(pid=143797)[0m             'advantages': np.ndarray((200,), dtype=float32, min=-11.886, max=4.782, mean=-4.061),
[2m[36m(pid=143797)[0m             'agent_index': np.ndarray((200,), dtype=int64, min=0.0, max=0.0, mean=0.0),
[2m[36m(pid=143797)[0m             'behaviour_logits': np.ndarray((200, 2), dtype=float32, min=0.002, max=0.005, mean=0.003),
[2m[36m(pid=143797)[0m             'dones': np.ndarray((200,), dtype=bool, min=0.0, max=0.0, mean=0.0),
[2m[36m(pid=143797)[0m             'eps_id': np.ndarray((200,), dtype=int64, min=1790170181.0, max=1790170181.0, mean=1790170181.0),
[2m[36m(pid=143797)[0m             'infos': np.ndarray((200,), dtype=object, head={}),
[2m[36m(pid=143797)[0m             'new_obs': np.ndarray((200, 3), dtype=float32, min=-0.012, max=0.827, mean=0.288),
[2m[36m(pid=143797)[0m             'obs': np.ndarray((200, 3), dtype=float32, min=-0.012, max=0.828, mean=0.288),
[2m[36m(pid=143797)[0m             'prev_actions': np.ndarray((200, 1), dtype=float32, min=-3.359, max=2.369, mean=-0.044),
[2m[36m(pid=143797)[0m             'prev_rewards': np.ndarray((200,), dtype=float32, min=-1.581, max=2.407, mean=-0.095),
[2m[36m(pid=143797)[0m             'rewards': np.ndarray((200,), dtype=float32, min=-1.582, max=2.407, mean=-0.103),
[2m[36m(pid=143797)[0m             't': np.ndarray((200,), dtype=int64, min=0.0, max=199.0, mean=99.5),
[2m[36m(pid=143797)[0m             'unroll_id': np.ndarray((200,), dtype=int64, min=0.0, max=0.0, mean=0.0),
[2m[36m(pid=143797)[0m             'value_targets': np.ndarray((200,), dtype=float32, min=-11.88, max=4.789, mean=-4.054),
[2m[36m(pid=143797)[0m             'vf_preds': np.ndarray((200,), dtype=float32, min=0.006, max=0.007, mean=0.007)},
[2m[36m(pid=143797)[0m   'type': 'SampleBatch'}
[2m[36m(pid=143797)[0m 
[2m[36m(pid=143797)[0m 
[2m[36m(pid=143797)[0m -----------------------
[2m[36m(pid=143797)[0m ring length: 513
[2m[36m(pid=143797)[0m v_max: 13.043759057511211
[2m[36m(pid=143797)[0m -----------------------
[2m[36m(pid=143797)[0m 
[2m[36m(pid=143797)[0m -----------------------
[2m[36m(pid=143797)[0m ring length: 512
[2m[36m(pid=143797)[0m v_max: 13.007554232214234
[2m[36m(pid=143797)[0m -----------------------
[2m[36m(pid=143797)[0m 
[2m[36m(pid=143797)[0m -----------------------
[2m[36m(pid=143797)[0m ring length: 502
[2m[36m(pid=143797)[0m v_max: 12.64340242846283
[2m[36m(pid=143797)[0m -----------------------
[2m[36m(pid=143797)[0m 
[2m[36m(pid=143797)[0m -----------------------
[2m[36m(pid=143797)[0m ring length: 495
[2m[36m(pid=143797)[0m v_max: 12.386304743340318
[2m[36m(pid=143797)[0m -----------------------
[2m[36m(pid=143797)[0m 
[2m[36m(pid=143797)[0m -----------------------
[2m[36m(pid=143797)[0m ring length: 503
[2m[36m(pid=143797)[0m v_max: 12.679986184756686
[2m[36m(pid=143797)[0m -----------------------
[2m[36m(pid=143796)[0m 2020-03-24 14:36:59,863	INFO tf_policy.py:355 -- Optimizing variable <tf.Variable 'default_policy/default_model/fc1/kernel:0' shape=(3, 32) dtype=float32_ref>
[2m[36m(pid=143796)[0m 2020-03-24 14:36:59,863	INFO tf_policy.py:355 -- Optimizing variable <tf.Variable 'default_policy/default_model/fc1/bias:0' shape=(32,) dtype=float32_ref>
[2m[36m(pid=143796)[0m 2020-03-24 14:36:59,863	INFO tf_policy.py:355 -- Optimizing variable <tf.Variable 'default_policy/default_model/fc2/kernel:0' shape=(32, 32) dtype=float32_ref>
[2m[36m(pid=143796)[0m 2020-03-24 14:36:59,863	INFO tf_policy.py:355 -- Optimizing variable <tf.Variable 'default_policy/default_model/fc2/bias:0' shape=(32,) dtype=float32_ref>
[2m[36m(pid=143796)[0m 2020-03-24 14:36:59,863	INFO tf_policy.py:355 -- Optimizing variable <tf.Variable 'default_policy/default_model/fc3/kernel:0' shape=(32, 32) dtype=float32_ref>
[2m[36m(pid=143796)[0m 2020-03-24 14:36:59,863	INFO tf_policy.py:355 -- Optimizing variable <tf.Variable 'default_policy/default_model/fc3/bias:0' shape=(32,) dtype=float32_ref>
[2m[36m(pid=143796)[0m 2020-03-24 14:36:59,863	INFO tf_policy.py:355 -- Optimizing variable <tf.Variable 'default_policy/default_model/fc_out/kernel:0' shape=(32, 2) dtype=float32_ref>
[2m[36m(pid=143796)[0m 2020-03-24 14:36:59,863	INFO tf_policy.py:355 -- Optimizing variable <tf.Variable 'default_policy/default_model/fc_out/bias:0' shape=(2,) dtype=float32_ref>
[2m[36m(pid=143796)[0m 2020-03-24 14:36:59,864	INFO tf_policy.py:355 -- Optimizing variable <tf.Variable 'default_policy/value_function/fc1/kernel:0' shape=(3, 32) dtype=float32_ref>
[2m[36m(pid=143796)[0m 2020-03-24 14:36:59,864	INFO tf_policy.py:355 -- Optimizing variable <tf.Variable 'default_policy/value_function/fc1/bias:0' shape=(32,) dtype=float32_ref>
[2m[36m(pid=143796)[0m 2020-03-24 14:36:59,864	INFO tf_policy.py:355 -- Optimizing variable <tf.Variable 'default_policy/value_function/fc2/kernel:0' shape=(32, 32) dtype=float32_ref>
[2m[36m(pid=143796)[0m 2020-03-24 14:36:59,864	INFO tf_policy.py:355 -- Optimizing variable <tf.Variable 'default_policy/value_function/fc2/bias:0' shape=(32,) dtype=float32_ref>
[2m[36m(pid=143796)[0m 2020-03-24 14:36:59,864	INFO tf_policy.py:355 -- Optimizing variable <tf.Variable 'default_policy/value_function/fc3/kernel:0' shape=(32, 32) dtype=float32_ref>
[2m[36m(pid=143796)[0m 2020-03-24 14:36:59,864	INFO tf_policy.py:355 -- Optimizing variable <tf.Variable 'default_policy/value_function/fc3/bias:0' shape=(32,) dtype=float32_ref>
[2m[36m(pid=143796)[0m 2020-03-24 14:36:59,864	INFO tf_policy.py:355 -- Optimizing variable <tf.Variable 'default_policy/value_function/fc_out/kernel:0' shape=(32, 1) dtype=float32_ref>
[2m[36m(pid=143796)[0m 2020-03-24 14:36:59,864	INFO tf_policy.py:355 -- Optimizing variable <tf.Variable 'default_policy/value_function/fc_out/bias:0' shape=(1,) dtype=float32_ref>
[2m[36m(pid=143796)[0m 2020-03-24 14:36:59,866	INFO multi_gpu_impl.py:146 -- Training on concatenated sample batches:
[2m[36m(pid=143796)[0m 
[2m[36m(pid=143796)[0m { 'inputs': [ np.ndarray((10000, 1), dtype=float32, min=-3.669, max=3.71, mean=-0.006),
[2m[36m(pid=143796)[0m               np.ndarray((10000,), dtype=float32, min=-2.612, max=2.478, mean=-0.391),
[2m[36m(pid=143796)[0m               np.ndarray((10000, 3), dtype=float32, min=-0.179, max=0.887, mean=0.282),
[2m[36m(pid=143796)[0m               np.ndarray((10000, 1), dtype=float32, min=-3.669, max=3.71, mean=-0.006),
[2m[36m(pid=143796)[0m               np.ndarray((10000,), dtype=float32, min=-3.329, max=2.342, mean=-0.0),
[2m[36m(pid=143796)[0m               np.ndarray((10000, 2), dtype=float32, min=0.001, max=0.006, mean=0.003),
[2m[36m(pid=143796)[0m               np.ndarray((10000,), dtype=float32, min=-44.635, max=12.724, mean=-10.963),
[2m[36m(pid=143796)[0m               np.ndarray((10000,), dtype=float32, min=0.003, max=0.008, mean=0.006)],
[2m[36m(pid=143796)[0m   'placeholders': [ <tf.Tensor 'default_policy/action:0' shape=(?, 1) dtype=float32>,
[2m[36m(pid=143796)[0m                     <tf.Tensor 'default_policy/prev_reward:0' shape=(?,) dtype=float32>,
[2m[36m(pid=143796)[0m                     <tf.Tensor 'default_policy/observation:0' shape=(?, 3) dtype=float32>,
[2m[36m(pid=143796)[0m                     <tf.Tensor 'default_policy/actions:0' shape=(?, 1) dtype=float32>,
[2m[36m(pid=143796)[0m                     <tf.Tensor 'default_policy/advantages:0' shape=(?,) dtype=float32>,
[2m[36m(pid=143796)[0m                     <tf.Tensor 'default_policy/behaviour_logits:0' shape=(?, 2) dtype=float32>,
[2m[36m(pid=143796)[0m                     <tf.Tensor 'default_policy/value_targets:0' shape=(?,) dtype=float32>,
[2m[36m(pid=143796)[0m                     <tf.Tensor 'default_policy/vf_preds:0' shape=(?,) dtype=float32>],
[2m[36m(pid=143796)[0m   'state_inputs': []}
[2m[36m(pid=143796)[0m 
[2m[36m(pid=143796)[0m 2020-03-24 14:36:59,866	INFO multi_gpu_impl.py:191 -- Divided 10000 rollout sequences, each of length 1, among 1 devices.
Result for PPO_WaveAttenuationPOEnv-v0_0:
  custom_metrics: {}
  date: 2020-03-24_14-37-00
  done: false
  episode_len_mean: 2000.0
  episode_reward_max: -323.50394138557726
  episode_reward_mean: -783.551012644215
  episode_reward_min: -1209.8218716258086
  episodes_this_iter: 5
  episodes_total: 5
  experiment_id: 3169a4f824ed4a02b4b42d55753086c5
  hostname: p0056.ten.osc.edu
  info:
    grad_time_ms: 587.832
    learner:
      default_policy:
        cur_kl_coeff: 0.20000000298023224
        cur_lr: 4.999999873689376e-05
        entropy: 1.4108350276947021
        entropy_coeff: 0.0
        kl: 0.0004946121480315924
        policy_loss: -0.0022642312105745077
        total_loss: 222.27789306640625
        vf_explained_var: -3.5643577575683594e-05
        vf_loss: 222.27999877929688
    load_time_ms: 50.648
    num_steps_sampled: 10000
    num_steps_trained: 10000
    sample_time_ms: 67048.897
    update_time_ms: 536.481
  iterations_since_restore: 1
  node_ip: 10.4.1.55
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 2.722448979591837
    ram_util_percent: 5.996938775510205
  pid: 143796
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 4.128647665895947
    mean_inference_ms: 0.5509674805377128
    mean_processing_ms: 1.69328395968234
  time_since_restore: 68.29244589805603
  time_this_iter_s: 68.29244589805603
  time_total_s: 68.29244589805603
  timestamp: 1585075020
  timesteps_since_restore: 10000
  timesteps_this_iter: 10000
  timesteps_total: 10000
  training_iteration: 1
  trial_id: 44d516d6
  
WARNING:tensorflow:From /users/PYS1027/chnrhughes/.local/lib/python3.5/site-packages/ray/tune/logger.py:118: The name tf.Summary is deprecated. Please use tf.compat.v1.Summary instead.

== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2/2 CPUs, 0/0 GPUs
Memory usage on this node: 12.0/201.2 GB
Result logdir: /users/PYS1027/chnrhughes/ray_results/simple_training_example_ring_v1
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - PPO_WaveAttenuationPOEnv-v0_0:	RUNNING, [2 CPUs, 0 GPUs], [pid=143796], 68 s, 1 iter, 10000 ts, -784 rew

[2m[36m(pid=143797)[0m 
[2m[36m(pid=143797)[0m -----------------------
[2m[36m(pid=143797)[0m ring length: 514
[2m[36m(pid=143797)[0m v_max: 13.079924697543293
[2m[36m(pid=143797)[0m -----------------------
[2m[36m(pid=143797)[0m 
[2m[36m(pid=143797)[0m -----------------------
[2m[36m(pid=143797)[0m ring length: 502
[2m[36m(pid=143797)[0m v_max: 12.64340242846283
[2m[36m(pid=143797)[0m -----------------------
[2m[36m(pid=143797)[0m 
[2m[36m(pid=143797)[0m -----------------------
[2m[36m(pid=143797)[0m ring length: 497
[2m[36m(pid=143797)[0m v_max: 12.45993945925872
[2m[36m(pid=143797)[0m -----------------------
[2m[36m(pid=143797)[0m 
[2m[36m(pid=143797)[0m -----------------------
[2m[36m(pid=143797)[0m ring length: 509
[2m[36m(pid=143797)[0m v_max: 12.89870698649076
[2m[36m(pid=143797)[0m -----------------------
[2m[36m(pid=143797)[0m 
[2m[36m(pid=143797)[0m -----------------------
[2m[36m(pid=143797)[0m ring length: 511
[2m[36m(pid=143797)[0m v_max: 12.97131045565535
[2m[36m(pid=143797)[0m -----------------------
Result for PPO_WaveAttenuationPOEnv-v0_0:
  custom_metrics: {}
  date: 2020-03-24_14-38-01
  done: false
  episode_len_mean: 2000.0
  episode_reward_max: -270.59393595253346
  episode_reward_mean: -802.9072285199388
  episode_reward_min: -1277.0016180523676
  episodes_this_iter: 5
  episodes_total: 10
  experiment_id: 3169a4f824ed4a02b4b42d55753086c5
  hostname: p0056.ten.osc.edu
  info:
    grad_time_ms: 420.212
    learner:
      default_policy:
        cur_kl_coeff: 0.10000000149011612
        cur_lr: 4.999999873689376e-05
        entropy: 1.3981246948242188
        entropy_coeff: 0.0
        kl: 0.0008138979901559651
        policy_loss: -0.0027405188884586096
        total_loss: 239.17300415039062
        vf_explained_var: -0.00017440319061279297
        vf_loss: 239.17564392089844
    load_time_ms: 26.397
    num_steps_sampled: 20000
    num_steps_trained: 20000
    sample_time_ms: 63853.325
    update_time_ms: 269.485
  iterations_since_restore: 2
  node_ip: 10.4.1.55
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 2.6999999999999993
    ram_util_percent: 6.0
  pid: 143796
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 4.051493417063297
    mean_inference_ms: 0.5502133461881575
    mean_processing_ms: 1.691024908466574
  time_since_restore: 129.21344757080078
  time_this_iter_s: 60.92100167274475
  time_total_s: 129.21344757080078
  timestamp: 1585075081
  timesteps_since_restore: 20000
  timesteps_this_iter: 10000
  timesteps_total: 20000
  training_iteration: 2
  trial_id: 44d516d6
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2/2 CPUs, 0/0 GPUs
Memory usage on this node: 12.1/201.2 GB
Result logdir: /users/PYS1027/chnrhughes/ray_results/simple_training_example_ring_v1
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - PPO_WaveAttenuationPOEnv-v0_0:	RUNNING, [2 CPUs, 0 GPUs], [pid=143796], 129 s, 2 iter, 20000 ts, -803 rew

[2m[36m(pid=143797)[0m 
[2m[36m(pid=143797)[0m -----------------------
[2m[36m(pid=143797)[0m ring length: 512
[2m[36m(pid=143797)[0m v_max: 13.007554232214234
[2m[36m(pid=143797)[0m -----------------------
[2m[36m(pid=143797)[0m 
[2m[36m(pid=143797)[0m -----------------------
[2m[36m(pid=143797)[0m ring length: 511
[2m[36m(pid=143797)[0m v_max: 12.97131045565535
[2m[36m(pid=143797)[0m -----------------------
[2m[36m(pid=143797)[0m 
[2m[36m(pid=143797)[0m -----------------------
[2m[36m(pid=143797)[0m ring length: 498
[2m[36m(pid=143797)[0m v_max: 12.496703821373096
[2m[36m(pid=143797)[0m -----------------------
[2m[36m(pid=143797)[0m 
[2m[36m(pid=143797)[0m -----------------------
[2m[36m(pid=143797)[0m ring length: 504
[2m[36m(pid=143797)[0m v_max: 12.716533109302146
[2m[36m(pid=143797)[0m -----------------------
[2m[36m(pid=143797)[0m 
[2m[36m(pid=143797)[0m -----------------------
[2m[36m(pid=143797)[0m ring length: 516
[2m[36m(pid=143797)[0m v_max: 13.152137487657606
[2m[36m(pid=143797)[0m -----------------------
Result for PPO_WaveAttenuationPOEnv-v0_0:
  custom_metrics: {}
  date: 2020-03-24_14-39-02
  done: false
  episode_len_mean: 2000.0
  episode_reward_max: -270.59393595253346
  episode_reward_mean: -867.8352712536912
  episode_reward_min: -1561.815718655835
  episodes_this_iter: 5
  episodes_total: 15
  experiment_id: 3169a4f824ed4a02b4b42d55753086c5
  hostname: p0056.ten.osc.edu
  info:
    grad_time_ms: 356.605
    learner:
      default_policy:
        cur_kl_coeff: 0.05000000074505806
        cur_lr: 4.999999873689376e-05
        entropy: 1.3811404705047607
        entropy_coeff: 0.0
        kl: 0.0019717910327017307
        policy_loss: -0.004585998598486185
        total_loss: 366.2756042480469
        vf_explained_var: -0.00043213367462158203
        vf_loss: 366.2801208496094
    load_time_ms: 18.616
    num_steps_sampled: 30000
    num_steps_trained: 30000
    sample_time_ms: 62814.724
    update_time_ms: 180.411
  iterations_since_restore: 3
  node_ip: 10.4.1.55
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 2.6930232558139533
    ram_util_percent: 6.0
  pid: 143796
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 4.007725835477822
    mean_inference_ms: 0.5516269201101394
    mean_processing_ms: 1.6896623922261749
  time_since_restore: 190.19202661514282
  time_this_iter_s: 60.97857904434204
  time_total_s: 190.19202661514282
  timestamp: 1585075142
  timesteps_since_restore: 30000
  timesteps_this_iter: 10000
  timesteps_total: 30000
  training_iteration: 3
  trial_id: 44d516d6
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2/2 CPUs, 0/0 GPUs
Memory usage on this node: 12.1/201.2 GB
Result logdir: /users/PYS1027/chnrhughes/ray_results/simple_training_example_ring_v1
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - PPO_WaveAttenuationPOEnv-v0_0:	RUNNING, [2 CPUs, 0 GPUs], [pid=143796], 190 s, 3 iter, 30000 ts, -868 rew

[2m[36m(pid=143797)[0m 
[2m[36m(pid=143797)[0m -----------------------
[2m[36m(pid=143797)[0m ring length: 502
[2m[36m(pid=143797)[0m v_max: 12.64340242846283
[2m[36m(pid=143797)[0m -----------------------
[2m[36m(pid=143797)[0m 
[2m[36m(pid=143797)[0m -----------------------
[2m[36m(pid=143797)[0m ring length: 516
[2m[36m(pid=143797)[0m v_max: 13.152137487657606
[2m[36m(pid=143797)[0m -----------------------
[2m[36m(pid=143797)[0m 
[2m[36m(pid=143797)[0m -----------------------
[2m[36m(pid=143797)[0m ring length: 510
[2m[36m(pid=143797)[0m v_max: 12.93502796218664
[2m[36m(pid=143797)[0m -----------------------
[2m[36m(pid=143797)[0m 
[2m[36m(pid=143797)[0m -----------------------
[2m[36m(pid=143797)[0m ring length: 500
[2m[36m(pid=143797)[0m v_max: 12.570125367437457
[2m[36m(pid=143797)[0m -----------------------
[2m[36m(pid=143797)[0m 
[2m[36m(pid=143797)[0m -----------------------
[2m[36m(pid=143797)[0m ring length: 494
[2m[36m(pid=143797)[0m v_max: 12.34943486433356
[2m[36m(pid=143797)[0m -----------------------
Result for PPO_WaveAttenuationPOEnv-v0_0:
  custom_metrics: {}
  date: 2020-03-24_14-40-03
  done: false
  episode_len_mean: 2000.0
  episode_reward_max: -62.36642211636733
  episode_reward_mean: -722.6104285585475
  episode_reward_min: -1561.815718655835
  episodes_this_iter: 5
  episodes_total: 20
  experiment_id: 3169a4f824ed4a02b4b42d55753086c5
  hostname: p0056.ten.osc.edu
  info:
    grad_time_ms: 325.545
    learner:
      default_policy:
        cur_kl_coeff: 0.02500000037252903
        cur_lr: 4.999999873689376e-05
        entropy: 1.3457783460617065
        entropy_coeff: 0.0
        kl: 0.004160418175160885
        policy_loss: -0.010747956112027168
        total_loss: 61.41086196899414
        vf_explained_var: -6.330013275146484e-05
        vf_loss: 61.421504974365234
    load_time_ms: 14.501
    num_steps_sampled: 40000
    num_steps_trained: 40000
    sample_time_ms: 62226.476
    update_time_ms: 135.917
  iterations_since_restore: 4
  node_ip: 10.4.1.55
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 2.705747126436782
    ram_util_percent: 6.0
  pid: 143796
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 3.980579169307256
    mean_inference_ms: 0.5500748024169992
    mean_processing_ms: 1.6884722302161645
  time_since_restore: 250.89624571800232
  time_this_iter_s: 60.7042191028595
  time_total_s: 250.89624571800232
  timestamp: 1585075203
  timesteps_since_restore: 40000
  timesteps_this_iter: 10000
  timesteps_total: 40000
  training_iteration: 4
  trial_id: 44d516d6
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2/2 CPUs, 0/0 GPUs
Memory usage on this node: 12.1/201.2 GB
Result logdir: /users/PYS1027/chnrhughes/ray_results/simple_training_example_ring_v1
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - PPO_WaveAttenuationPOEnv-v0_0:	RUNNING, [2 CPUs, 0 GPUs], [pid=143796], 250 s, 4 iter, 40000 ts, -723 rew

[2m[36m(pid=143797)[0m 
[2m[36m(pid=143797)[0m -----------------------
[2m[36m(pid=143797)[0m ring length: 517
[2m[36m(pid=143797)[0m v_max: 13.188184171646189
[2m[36m(pid=143797)[0m -----------------------
[2m[36m(pid=143797)[0m 
[2m[36m(pid=143797)[0m -----------------------
[2m[36m(pid=143797)[0m ring length: 505
[2m[36m(pid=143797)[0m v_max: 12.753042965621004
[2m[36m(pid=143797)[0m -----------------------
[2m[36m(pid=143797)[0m 
[2m[36m(pid=143797)[0m -----------------------
[2m[36m(pid=143797)[0m ring length: 504
[2m[36m(pid=143797)[0m v_max: 12.716533109302146
[2m[36m(pid=143797)[0m -----------------------
[2m[36m(pid=143797)[0m 
[2m[36m(pid=143797)[0m -----------------------
[2m[36m(pid=143797)[0m ring length: 509
[2m[36m(pid=143797)[0m v_max: 12.89870698649076
[2m[36m(pid=143797)[0m -----------------------
[2m[36m(pid=143797)[0m 
[2m[36m(pid=143797)[0m -----------------------
[2m[36m(pid=143797)[0m ring length: 498
[2m[36m(pid=143797)[0m v_max: 12.496703821373096
[2m[36m(pid=143797)[0m -----------------------
Result for PPO_WaveAttenuationPOEnv-v0_0:
  custom_metrics: {}
  date: 2020-03-24_14-41-04
  done: false
  episode_len_mean: 2000.0
  episode_reward_max: 24.73130282888918
  episode_reward_mean: -611.7877746782319
  episode_reward_min: -1561.815718655835
  episodes_this_iter: 5
  episodes_total: 25
  experiment_id: 3169a4f824ed4a02b4b42d55753086c5
  hostname: p0056.ten.osc.edu
  info:
    grad_time_ms: 310.815
    learner:
      default_policy:
        cur_kl_coeff: 0.012500000186264515
        cur_lr: 4.999999873689376e-05
        entropy: 1.3080915212631226
        entropy_coeff: 0.0
        kl: 0.006412934977561235
        policy_loss: -0.012898705899715424
        total_loss: 52.562686920166016
        vf_explained_var: -0.00015866756439208984
        vf_loss: 52.57550048828125
    load_time_ms: 12.01
    num_steps_sampled: 50000
    num_steps_trained: 50000
    sample_time_ms: 61950.3
    update_time_ms: 109.176
  iterations_since_restore: 5
  node_ip: 10.4.1.55
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 2.690804597701149
    ram_util_percent: 6.0
  pid: 143796
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 3.961623516271729
    mean_inference_ms: 0.5499498655839321
    mean_processing_ms: 1.6872919126550103
  time_since_restore: 312.00504064559937
  time_this_iter_s: 61.108794927597046
  time_total_s: 312.00504064559937
  timestamp: 1585075264
  timesteps_since_restore: 50000
  timesteps_this_iter: 10000
  timesteps_total: 50000
  training_iteration: 5
  trial_id: 44d516d6
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2/2 CPUs, 0/0 GPUs
Memory usage on this node: 12.1/201.2 GB
Result logdir: /users/PYS1027/chnrhughes/ray_results/simple_training_example_ring_v1
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - PPO_WaveAttenuationPOEnv-v0_0:	RUNNING, [2 CPUs, 0 GPUs], [pid=143796], 312 s, 5 iter, 50000 ts, -612 rew

[2m[36m(pid=143797)[0m 
[2m[36m(pid=143797)[0m -----------------------
[2m[36m(pid=143797)[0m ring length: 513
[2m[36m(pid=143797)[0m v_max: 13.043759057511211
[2m[36m(pid=143797)[0m -----------------------
[2m[36m(pid=143797)[0m 
[2m[36m(pid=143797)[0m -----------------------
[2m[36m(pid=143797)[0m ring length: 506
[2m[36m(pid=143797)[0m v_max: 12.789515517436104
[2m[36m(pid=143797)[0m -----------------------
[2m[36m(pid=143797)[0m 
[2m[36m(pid=143797)[0m -----------------------
[2m[36m(pid=143797)[0m ring length: 517
[2m[36m(pid=143797)[0m v_max: 13.188184171646189
[2m[36m(pid=143797)[0m -----------------------
[2m[36m(pid=143797)[0m 
[2m[36m(pid=143797)[0m -----------------------
[2m[36m(pid=143797)[0m ring length: 502
[2m[36m(pid=143797)[0m v_max: 12.64340242846283
[2m[36m(pid=143797)[0m -----------------------
[2m[36m(pid=143797)[0m 
[2m[36m(pid=143797)[0m -----------------------
[2m[36m(pid=143797)[0m ring length: 517
[2m[36m(pid=143797)[0m v_max: 13.188184171646189
[2m[36m(pid=143797)[0m -----------------------
Result for PPO_WaveAttenuationPOEnv-v0_0:
  custom_metrics: {}
  date: 2020-03-24_14-42-05
  done: false
  episode_len_mean: 2000.0
  episode_reward_max: 390.98303690352265
  episode_reward_mean: -475.2054463643492
  episode_reward_min: -1561.815718655835
  episodes_this_iter: 5
  episodes_total: 30
  experiment_id: 3169a4f824ed4a02b4b42d55753086c5
  hostname: p0056.ten.osc.edu
  info:
    grad_time_ms: 299.974
    learner:
      default_policy:
        cur_kl_coeff: 0.0062500000931322575
        cur_lr: 4.999999873689376e-05
        entropy: 1.262837529182434
        entropy_coeff: 0.0
        kl: 0.007942224852740765
        policy_loss: -0.016526227816939354
        total_loss: 46.52778625488281
        vf_explained_var: -6.365776062011719e-05
        vf_loss: 46.54426956176758
    load_time_ms: 10.426
    num_steps_sampled: 60000
    num_steps_trained: 60000
    sample_time_ms: 61812.234
    update_time_ms: 91.333
  iterations_since_restore: 6
  node_ip: 10.4.1.55
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 3.22183908045977
    ram_util_percent: 6.0
  pid: 143796
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 3.9483804379949237
    mean_inference_ms: 0.5499415602005425
    mean_processing_ms: 1.686507593424976
  time_since_restore: 373.3828284740448
  time_this_iter_s: 61.377787828445435
  time_total_s: 373.3828284740448
  timestamp: 1585075325
  timesteps_since_restore: 60000
  timesteps_this_iter: 10000
  timesteps_total: 60000
  training_iteration: 6
  trial_id: 44d516d6
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2/2 CPUs, 0/0 GPUs
Memory usage on this node: 12.1/201.2 GB
Result logdir: /users/PYS1027/chnrhughes/ray_results/simple_training_example_ring_v1
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - PPO_WaveAttenuationPOEnv-v0_0:	RUNNING, [2 CPUs, 0 GPUs], [pid=143796], 373 s, 6 iter, 60000 ts, -475 rew

[2m[36m(pid=143797)[0m 
[2m[36m(pid=143797)[0m -----------------------
[2m[36m(pid=143797)[0m ring length: 509
[2m[36m(pid=143797)[0m v_max: 12.89870698649076
[2m[36m(pid=143797)[0m -----------------------
[2m[36m(pid=143797)[0m 
[2m[36m(pid=143797)[0m -----------------------
[2m[36m(pid=143797)[0m ring length: 500
[2m[36m(pid=143797)[0m v_max: 12.570125367437457
[2m[36m(pid=143797)[0m -----------------------
[2m[36m(pid=143797)[0m 
[2m[36m(pid=143797)[0m -----------------------
[2m[36m(pid=143797)[0m ring length: 502
[2m[36m(pid=143797)[0m v_max: 12.64340242846283
[2m[36m(pid=143797)[0m -----------------------
[2m[36m(pid=143797)[0m 
[2m[36m(pid=143797)[0m -----------------------
[2m[36m(pid=143797)[0m ring length: 512
[2m[36m(pid=143797)[0m v_max: 13.007554232214234
[2m[36m(pid=143797)[0m -----------------------
[2m[36m(pid=143797)[0m 
[2m[36m(pid=143797)[0m -----------------------
[2m[36m(pid=143797)[0m ring length: 508
[2m[36m(pid=143797)[0m v_max: 12.862347763562411
[2m[36m(pid=143797)[0m -----------------------
Result for PPO_WaveAttenuationPOEnv-v0_0:
  custom_metrics: {}
  date: 2020-03-24_14-43-07
  done: false
  episode_len_mean: 2000.0
  episode_reward_max: 712.6061457047739
  episode_reward_mean: -314.0672235071538
  episode_reward_min: -1561.815718655835
  episodes_this_iter: 5
  episodes_total: 35
  experiment_id: 3169a4f824ed4a02b4b42d55753086c5
  hostname: p0056.ten.osc.edu
  info:
    grad_time_ms: 288.913
    learner:
      default_policy:
        cur_kl_coeff: 0.0031250000465661287
        cur_lr: 4.999999873689376e-05
        entropy: 1.2131571769714355
        entropy_coeff: 0.0
        kl: 0.00951731763780117
        policy_loss: -0.01843627169728279
        total_loss: 115.92569732666016
        vf_explained_var: 4.172325134277344e-07
        vf_loss: 115.9441146850586
    load_time_ms: 9.215
    num_steps_sampled: 70000
    num_steps_trained: 70000
    sample_time_ms: 61791.832
    update_time_ms: 78.599
  iterations_since_restore: 7
  node_ip: 10.4.1.55
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 5.564044943820225
    ram_util_percent: 6.0044943820224725
  pid: 143796
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 3.9398549793858018
    mean_inference_ms: 0.5492441059889683
    mean_processing_ms: 1.6864686116270722
  time_since_restore: 435.28451681137085
  time_this_iter_s: 61.90168833732605
  time_total_s: 435.28451681137085
  timestamp: 1585075387
  timesteps_since_restore: 70000
  timesteps_this_iter: 10000
  timesteps_total: 70000
  training_iteration: 7
  trial_id: 44d516d6
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2/2 CPUs, 0/0 GPUs
Memory usage on this node: 12.2/201.2 GB
Result logdir: /users/PYS1027/chnrhughes/ray_results/simple_training_example_ring_v1
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - PPO_WaveAttenuationPOEnv-v0_0:	RUNNING, [2 CPUs, 0 GPUs], [pid=143796], 435 s, 7 iter, 70000 ts, -314 rew

[2m[36m(pid=143797)[0m 
[2m[36m(pid=143797)[0m -----------------------
[2m[36m(pid=143797)[0m ring length: 494
[2m[36m(pid=143797)[0m v_max: 12.34943486433356
[2m[36m(pid=143797)[0m -----------------------
[2m[36m(pid=143797)[0m 
[2m[36m(pid=143797)[0m -----------------------
[2m[36m(pid=143797)[0m ring length: 514
[2m[36m(pid=143797)[0m v_max: 13.079924697543293
[2m[36m(pid=143797)[0m -----------------------
[2m[36m(pid=143797)[0m 
[2m[36m(pid=143797)[0m -----------------------
[2m[36m(pid=143797)[0m ring length: 496
[2m[36m(pid=143797)[0m v_max: 12.423139687457347
[2m[36m(pid=143797)[0m -----------------------
[2m[36m(pid=143797)[0m 
[2m[36m(pid=143797)[0m -----------------------
[2m[36m(pid=143797)[0m ring length: 520
[2m[36m(pid=143797)[0m v_max: 13.296082591662728
[2m[36m(pid=143797)[0m -----------------------
[2m[36m(pid=143797)[0m 
[2m[36m(pid=143797)[0m -----------------------
[2m[36m(pid=143797)[0m ring length: 516
[2m[36m(pid=143797)[0m v_max: 13.152137487657606
[2m[36m(pid=143797)[0m -----------------------
Result for PPO_WaveAttenuationPOEnv-v0_0:
  custom_metrics: {}
  date: 2020-03-24_14-44-08
  done: false
  episode_len_mean: 2000.0
  episode_reward_max: 982.2692593302104
  episode_reward_mean: -193.01049217146524
  episode_reward_min: -1561.815718655835
  episodes_this_iter: 5
  episodes_total: 40
  experiment_id: 3169a4f824ed4a02b4b42d55753086c5
  hostname: p0056.ten.osc.edu
  info:
    grad_time_ms: 280.518
    learner:
      default_policy:
        cur_kl_coeff: 0.0015625000232830644
        cur_lr: 4.999999873689376e-05
        entropy: 1.1704667806625366
        entropy_coeff: 0.0
        kl: 0.00826189573854208
        policy_loss: -0.014606695622205734
        total_loss: 137.51974487304688
        vf_explained_var: 0.0002243518829345703
        vf_loss: 137.53433227539062
    load_time_ms: 8.451
    num_steps_sampled: 80000
    num_steps_trained: 80000
    sample_time_ms: 61647.072
    update_time_ms: 69.076
  iterations_since_restore: 8
  node_ip: 10.4.1.55
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 2.756976744186047
    ram_util_percent: 6.047674418604651
  pid: 143796
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 3.9326701774555466
    mean_inference_ms: 0.5485484495953241
    mean_processing_ms: 1.6863121577039102
  time_since_restore: 496.1520833969116
  time_this_iter_s: 60.86756658554077
  time_total_s: 496.1520833969116
  timestamp: 1585075448
  timesteps_since_restore: 80000
  timesteps_this_iter: 10000
  timesteps_total: 80000
  training_iteration: 8
  trial_id: 44d516d6
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2/2 CPUs, 0/0 GPUs
Memory usage on this node: 12.1/201.2 GB
Result logdir: /users/PYS1027/chnrhughes/ray_results/simple_training_example_ring_v1
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - PPO_WaveAttenuationPOEnv-v0_0:	RUNNING, [2 CPUs, 0 GPUs], [pid=143796], 496 s, 8 iter, 80000 ts, -193 rew

[2m[36m(pid=143797)[0m 
[2m[36m(pid=143797)[0m -----------------------
[2m[36m(pid=143797)[0m ring length: 519
[2m[36m(pid=143797)[0m v_max: 13.260156955398273
[2m[36m(pid=143797)[0m -----------------------
[2m[36m(pid=143797)[0m 
[2m[36m(pid=143797)[0m -----------------------
[2m[36m(pid=143797)[0m ring length: 516
[2m[36m(pid=143797)[0m v_max: 13.152137487657606
[2m[36m(pid=143797)[0m -----------------------
[2m[36m(pid=143797)[0m 
[2m[36m(pid=143797)[0m -----------------------
[2m[36m(pid=143797)[0m ring length: 492
[2m[36m(pid=143797)[0m v_max: 12.275591251518899
[2m[36m(pid=143797)[0m -----------------------
[2m[36m(pid=143797)[0m 
[2m[36m(pid=143797)[0m -----------------------
[2m[36m(pid=143797)[0m ring length: 501
[2m[36m(pid=143797)[0m v_max: 12.606782077081403
[2m[36m(pid=143797)[0m -----------------------
[2m[36m(pid=143797)[0m 
[2m[36m(pid=143797)[0m -----------------------
[2m[36m(pid=143797)[0m ring length: 498
[2m[36m(pid=143797)[0m v_max: 12.496703821373096
[2m[36m(pid=143797)[0m -----------------------
Result for PPO_WaveAttenuationPOEnv-v0_0:
  custom_metrics: {}
  date: 2020-03-24_14-45-09
  done: false
  episode_len_mean: 2000.0
  episode_reward_max: 1142.134837038234
  episode_reward_mean: -65.44254072645545
  episode_reward_min: -1561.815718655835
  episodes_this_iter: 5
  episodes_total: 45
  experiment_id: 3169a4f824ed4a02b4b42d55753086c5
  hostname: p0056.ten.osc.edu
  info:
    grad_time_ms: 274.076
    learner:
      default_policy:
        cur_kl_coeff: 0.0007812500116415322
        cur_lr: 4.999999873689376e-05
        entropy: 1.1240665912628174
        entropy_coeff: 0.0
        kl: 0.008334103040397167
        policy_loss: -0.014236760325729847
        total_loss: 216.30859375
        vf_explained_var: 0.0004019737243652344
        vf_loss: 216.32284545898438
    load_time_ms: 7.737
    num_steps_sampled: 90000
    num_steps_trained: 90000
    sample_time_ms: 61523.995
    update_time_ms: 61.651
  iterations_since_restore: 9
  node_ip: 10.4.1.55
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 2.7275862068965524
    ram_util_percent: 6.0
  pid: 143796
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 3.9265975433300797
    mean_inference_ms: 0.5476987850087552
    mean_processing_ms: 1.6861163686426728
  time_since_restore: 556.9238231182098
  time_this_iter_s: 60.77173972129822
  time_total_s: 556.9238231182098
  timestamp: 1585075509
  timesteps_since_restore: 90000
  timesteps_this_iter: 10000
  timesteps_total: 90000
  training_iteration: 9
  trial_id: 44d516d6
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2/2 CPUs, 0/0 GPUs
Memory usage on this node: 12.1/201.2 GB
Result logdir: /users/PYS1027/chnrhughes/ray_results/simple_training_example_ring_v1
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - PPO_WaveAttenuationPOEnv-v0_0:	RUNNING, [2 CPUs, 0 GPUs], [pid=143796], 556 s, 9 iter, 90000 ts, -65.4 rew

[2m[36m(pid=143797)[0m 
[2m[36m(pid=143797)[0m -----------------------
[2m[36m(pid=143797)[0m ring length: 497
[2m[36m(pid=143797)[0m v_max: 12.45993945925872
[2m[36m(pid=143797)[0m -----------------------
[2m[36m(pid=143797)[0m 
[2m[36m(pid=143797)[0m -----------------------
[2m[36m(pid=143797)[0m ring length: 512
[2m[36m(pid=143797)[0m v_max: 13.007554232214234
[2m[36m(pid=143797)[0m -----------------------
[2m[36m(pid=143797)[0m 
[2m[36m(pid=143797)[0m -----------------------
[2m[36m(pid=143797)[0m ring length: 520
[2m[36m(pid=143797)[0m v_max: 13.296082591662728
[2m[36m(pid=143797)[0m -----------------------
[2m[36m(pid=143797)[0m 
[2m[36m(pid=143797)[0m -----------------------
[2m[36m(pid=143797)[0m ring length: 516
[2m[36m(pid=143797)[0m v_max: 13.152137487657606
[2m[36m(pid=143797)[0m -----------------------
[2m[36m(pid=143797)[0m 
[2m[36m(pid=143797)[0m -----------------------
[2m[36m(pid=143797)[0m ring length: 509
[2m[36m(pid=143797)[0m v_max: 12.89870698649076
[2m[36m(pid=143797)[0m -----------------------
Result for PPO_WaveAttenuationPOEnv-v0_0:
  custom_metrics: {}
  date: 2020-03-24_14-46-09
  done: false
  episode_len_mean: 2000.0
  episode_reward_max: 1722.892388005749
  episode_reward_mean: 69.80810668803414
  episode_reward_min: -1561.815718655835
  episodes_this_iter: 5
  episodes_total: 50
  experiment_id: 3169a4f824ed4a02b4b42d55753086c5
  hostname: p0056.ten.osc.edu
  info:
    grad_time_ms: 269.164
    learner:
      default_policy:
        cur_kl_coeff: 0.0003906250058207661
        cur_lr: 4.999999873689376e-05
        entropy: 1.0809252262115479
        entropy_coeff: 0.0
        kl: 0.007415714208036661
        policy_loss: -0.012043727561831474
        total_loss: 379.37213134765625
        vf_explained_var: 0.0006691217422485352
        vf_loss: 379.3841857910156
    load_time_ms: 7.189
    num_steps_sampled: 100000
    num_steps_trained: 100000
    sample_time_ms: 61390.026
    update_time_ms: 55.785
  iterations_since_restore: 10
  node_ip: 10.4.1.55
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 2.6976744186046506
    ram_util_percent: 6.0
  pid: 143796
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 3.921301306948195
    mean_inference_ms: 0.546560242133229
    mean_processing_ms: 1.6858721467675855
  time_since_restore: 617.3447766304016
  time_this_iter_s: 60.42095351219177
  time_total_s: 617.3447766304016
  timestamp: 1585075569
  timesteps_since_restore: 100000
  timesteps_this_iter: 10000
  timesteps_total: 100000
  training_iteration: 10
  trial_id: 44d516d6
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2/2 CPUs, 0/0 GPUs
Memory usage on this node: 12.1/201.2 GB
Result logdir: /users/PYS1027/chnrhughes/ray_results/simple_training_example_ring_v1
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - PPO_WaveAttenuationPOEnv-v0_0:	RUNNING, [2 CPUs, 0 GPUs], [pid=143796], 617 s, 10 iter, 100000 ts, 69.8 rew

[2m[36m(pid=143797)[0m 
[2m[36m(pid=143797)[0m -----------------------
[2m[36m(pid=143797)[0m ring length: 506
[2m[36m(pid=143797)[0m v_max: 12.789515517436104
[2m[36m(pid=143797)[0m -----------------------
[2m[36m(pid=143797)[0m 
[2m[36m(pid=143797)[0m -----------------------
[2m[36m(pid=143797)[0m ring length: 490
[2m[36m(pid=143797)[0m v_max: 12.201610748825663
[2m[36m(pid=143797)[0m -----------------------
[2m[36m(pid=143797)[0m 
[2m[36m(pid=143797)[0m -----------------------
[2m[36m(pid=143797)[0m ring length: 519
[2m[36m(pid=143797)[0m v_max: 13.260156955398273
[2m[36m(pid=143797)[0m -----------------------
[2m[36m(pid=143797)[0m 
[2m[36m(pid=143797)[0m -----------------------
[2m[36m(pid=143797)[0m ring length: 500
[2m[36m(pid=143797)[0m v_max: 12.570125367437457
[2m[36m(pid=143797)[0m -----------------------
[2m[36m(pid=143797)[0m 
[2m[36m(pid=143797)[0m -----------------------
[2m[36m(pid=143797)[0m ring length: 510
[2m[36m(pid=143797)[0m v_max: 12.93502796218664
[2m[36m(pid=143797)[0m -----------------------
Result for PPO_WaveAttenuationPOEnv-v0_0:
  custom_metrics: {}
  date: 2020-03-24_14-47-10
  done: false
  episode_len_mean: 2000.0
  episode_reward_max: 1722.892388005749
  episode_reward_mean: 190.54320095805
  episode_reward_min: -1561.815718655835
  episodes_this_iter: 5
  episodes_total: 55
  experiment_id: 3169a4f824ed4a02b4b42d55753086c5
  hostname: p0056.ten.osc.edu
  info:
    grad_time_ms: 234.142
    learner:
      default_policy:
        cur_kl_coeff: 0.00019531250291038305
        cur_lr: 4.999999873689376e-05
        entropy: 1.0334320068359375
        entropy_coeff: 0.0
        kl: 0.009754381142556667
        policy_loss: -0.015538293868303299
        total_loss: 434.1919860839844
        vf_explained_var: 0.0009492635726928711
        vf_loss: 434.2076110839844
    load_time_ms: 2.344
    num_steps_sampled: 110000
    num_steps_trained: 110000
    sample_time_ms: 60712.704
    update_time_ms: 2.346
  iterations_since_restore: 11
  node_ip: 10.4.1.55
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 2.8476744186046514
    ram_util_percent: 6.0
  pid: 143796
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 3.9166359242822426
    mean_inference_ms: 0.5453599068237495
    mean_processing_ms: 1.6856110457604927
  time_since_restore: 677.8696677684784
  time_this_iter_s: 60.52489113807678
  time_total_s: 677.8696677684784
  timestamp: 1585075630
  timesteps_since_restore: 110000
  timesteps_this_iter: 10000
  timesteps_total: 110000
  training_iteration: 11
  trial_id: 44d516d6
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2/2 CPUs, 0/0 GPUs
Memory usage on this node: 12.2/201.2 GB
Result logdir: /users/PYS1027/chnrhughes/ray_results/simple_training_example_ring_v1
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - PPO_WaveAttenuationPOEnv-v0_0:	RUNNING, [2 CPUs, 0 GPUs], [pid=143796], 677 s, 11 iter, 110000 ts, 191 rew

[2m[36m(pid=143797)[0m 
[2m[36m(pid=143797)[0m -----------------------
[2m[36m(pid=143797)[0m ring length: 506
[2m[36m(pid=143797)[0m v_max: 12.789515517436104
[2m[36m(pid=143797)[0m -----------------------
[2m[36m(pid=143797)[0m 
[2m[36m(pid=143797)[0m -----------------------
[2m[36m(pid=143797)[0m ring length: 493
[2m[36m(pid=143797)[0m v_max: 12.31253028789948
[2m[36m(pid=143797)[0m -----------------------
[2m[36m(pid=143797)[0m 
[2m[36m(pid=143797)[0m -----------------------
[2m[36m(pid=143797)[0m ring length: 511
[2m[36m(pid=143797)[0m v_max: 12.97131045565535
[2m[36m(pid=143797)[0m -----------------------
[2m[36m(pid=143797)[0m 
[2m[36m(pid=143797)[0m -----------------------
[2m[36m(pid=143797)[0m ring length: 494
[2m[36m(pid=143797)[0m v_max: 12.34943486433356
[2m[36m(pid=143797)[0m -----------------------
[2m[36m(pid=143797)[0m 
[2m[36m(pid=143797)[0m -----------------------
[2m[36m(pid=143797)[0m ring length: 495
[2m[36m(pid=143797)[0m v_max: 12.386304743340318
[2m[36m(pid=143797)[0m -----------------------
Result for PPO_WaveAttenuationPOEnv-v0_0:
  custom_metrics: {}
  date: 2020-03-24_14-48-10
  done: false
  episode_len_mean: 2000.0
  episode_reward_max: 1969.725423661068
  episode_reward_mean: 323.19963375571314
  episode_reward_min: -1561.815718655835
  episodes_this_iter: 5
  episodes_total: 60
  experiment_id: 3169a4f824ed4a02b4b42d55753086c5
  hostname: p0056.ten.osc.edu
  info:
    grad_time_ms: 231.484
    learner:
      default_policy:
        cur_kl_coeff: 9.765625145519152e-05
        cur_lr: 4.999999873689376e-05
        entropy: 0.9913507699966431
        entropy_coeff: 0.0
        kl: 0.006979397032409906
        policy_loss: -0.010334240272641182
        total_loss: 656.7589111328125
        vf_explained_var: 0.0005597472190856934
        vf_loss: 656.7692260742188
    load_time_ms: 2.348
    num_steps_sampled: 120000
    num_steps_trained: 120000
    sample_time_ms: 60693.083
    update_time_ms: 2.324
  iterations_since_restore: 12
  node_ip: 10.4.1.55
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 2.832183908045977
    ram_util_percent: 6.0
  pid: 143796
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 3.9125333182171533
    mean_inference_ms: 0.5442565292321656
    mean_processing_ms: 1.685326113897915
  time_since_restore: 738.5687584877014
  time_this_iter_s: 60.69909071922302
  time_total_s: 738.5687584877014
  timestamp: 1585075690
  timesteps_since_restore: 120000
  timesteps_this_iter: 10000
  timesteps_total: 120000
  training_iteration: 12
  trial_id: 44d516d6
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2/2 CPUs, 0/0 GPUs
Memory usage on this node: 12.1/201.2 GB
Result logdir: /users/PYS1027/chnrhughes/ray_results/simple_training_example_ring_v1
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - PPO_WaveAttenuationPOEnv-v0_0:	RUNNING, [2 CPUs, 0 GPUs], [pid=143796], 738 s, 12 iter, 120000 ts, 323 rew

[2m[36m(pid=143797)[0m 
[2m[36m(pid=143797)[0m -----------------------
[2m[36m(pid=143797)[0m ring length: 512
[2m[36m(pid=143797)[0m v_max: 13.007554232214234
[2m[36m(pid=143797)[0m -----------------------
[2m[36m(pid=143797)[0m 
[2m[36m(pid=143797)[0m -----------------------
[2m[36m(pid=143797)[0m ring length: 500
[2m[36m(pid=143797)[0m v_max: 12.570125367437457
[2m[36m(pid=143797)[0m -----------------------
[2m[36m(pid=143797)[0m 
[2m[36m(pid=143797)[0m -----------------------
[2m[36m(pid=143797)[0m ring length: 505
[2m[36m(pid=143797)[0m v_max: 12.753042965621004
[2m[36m(pid=143797)[0m -----------------------
[2m[36m(pid=143797)[0m 
[2m[36m(pid=143797)[0m -----------------------
[2m[36m(pid=143797)[0m ring length: 497
[2m[36m(pid=143797)[0m v_max: 12.45993945925872
[2m[36m(pid=143797)[0m -----------------------
[2m[36m(pid=143797)[0m 
[2m[36m(pid=143797)[0m -----------------------
[2m[36m(pid=143797)[0m ring length: 512
[2m[36m(pid=143797)[0m v_max: 13.007554232214234
[2m[36m(pid=143797)[0m -----------------------
Result for PPO_WaveAttenuationPOEnv-v0_0:
  custom_metrics: {}
  date: 2020-03-24_14-49-11
  done: false
  episode_len_mean: 2000.0
  episode_reward_max: 2124.822600837616
  episode_reward_mean: 454.0898617298736
  episode_reward_min: -1561.815718655835
  episodes_this_iter: 5
  episodes_total: 65
  experiment_id: 3169a4f824ed4a02b4b42d55753086c5
  hostname: p0056.ten.osc.edu
  info:
    grad_time_ms: 231.247
    learner:
      default_policy:
        cur_kl_coeff: 4.882812572759576e-05
        cur_lr: 4.999999873689376e-05
        entropy: 0.9504814743995667
        entropy_coeff: 0.0
        kl: 0.0067220632918179035
        policy_loss: -0.010391022078692913
        total_loss: 836.100830078125
        vf_explained_var: 0.00041550397872924805
        vf_loss: 836.1112670898438
    load_time_ms: 2.273
    num_steps_sampled: 130000
    num_steps_trained: 130000
    sample_time_ms: 60687.391
    update_time_ms: 2.319
  iterations_since_restore: 13
  node_ip: 10.4.1.55
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 2.645348837209302
    ram_util_percent: 6.0
  pid: 143796
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 3.908905892447721
    mean_inference_ms: 0.5433322597892034
    mean_processing_ms: 1.685062896072716
  time_since_restore: 799.4877619743347
  time_this_iter_s: 60.9190034866333
  time_total_s: 799.4877619743347
  timestamp: 1585075751
  timesteps_since_restore: 130000
  timesteps_this_iter: 10000
  timesteps_total: 130000
  training_iteration: 13
  trial_id: 44d516d6
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2/2 CPUs, 0/0 GPUs
Memory usage on this node: 12.1/201.2 GB
Result logdir: /users/PYS1027/chnrhughes/ray_results/simple_training_example_ring_v1
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - PPO_WaveAttenuationPOEnv-v0_0:	RUNNING, [2 CPUs, 0 GPUs], [pid=143796], 799 s, 13 iter, 130000 ts, 454 rew

[2m[36m(pid=143797)[0m 
[2m[36m(pid=143797)[0m -----------------------
[2m[36m(pid=143797)[0m ring length: 515
[2m[36m(pid=143797)[0m v_max: 13.116050918675148
[2m[36m(pid=143797)[0m -----------------------
[2m[36m(pid=143797)[0m 
[2m[36m(pid=143797)[0m -----------------------
[2m[36m(pid=143797)[0m ring length: 514
[2m[36m(pid=143797)[0m v_max: 13.079924697543293
[2m[36m(pid=143797)[0m -----------------------
[2m[36m(pid=143797)[0m 
[2m[36m(pid=143797)[0m -----------------------
[2m[36m(pid=143797)[0m ring length: 518
[2m[36m(pid=143797)[0m v_max: 13.22419073821961
[2m[36m(pid=143797)[0m -----------------------
[2m[36m(pid=143797)[0m 
[2m[36m(pid=143797)[0m -----------------------
[2m[36m(pid=143797)[0m ring length: 508
[2m[36m(pid=143797)[0m v_max: 12.862347763562411
[2m[36m(pid=143797)[0m -----------------------
[2m[36m(pid=143797)[0m 
[2m[36m(pid=143797)[0m -----------------------
[2m[36m(pid=143797)[0m ring length: 515
[2m[36m(pid=143797)[0m v_max: 13.116050918675148
[2m[36m(pid=143797)[0m -----------------------
Result for PPO_WaveAttenuationPOEnv-v0_0:
  custom_metrics: {}
  date: 2020-03-24_14-50-12
  done: false
  episode_len_mean: 2000.0
  episode_reward_max: 2467.6550779695026
  episode_reward_mean: 593.1997500256566
  episode_reward_min: -1561.815718655835
  episodes_this_iter: 5
  episodes_total: 70
  experiment_id: 3169a4f824ed4a02b4b42d55753086c5
  hostname: p0056.ten.osc.edu
  info:
    grad_time_ms: 231.405
    learner:
      default_policy:
        cur_kl_coeff: 2.441406286379788e-05
        cur_lr: 4.999999873689376e-05
        entropy: 0.9139317274093628
        entropy_coeff: 0.0
        kl: 0.005493381526321173
        policy_loss: -0.00774077232927084
        total_loss: 1151.38330078125
        vf_explained_var: 0.00024259090423583984
        vf_loss: 1151.3912353515625
    load_time_ms: 2.39
    num_steps_sampled: 140000
    num_steps_trained: 140000
    sample_time_ms: 60719.876
    update_time_ms: 2.283
  iterations_since_restore: 14
  node_ip: 10.4.1.55
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 2.6816091954022987
    ram_util_percent: 6.0
  pid: 143796
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 3.905692408101172
    mean_inference_ms: 0.542551343706115
    mean_processing_ms: 1.684848893571156
  time_since_restore: 860.5207362174988
  time_this_iter_s: 61.03297424316406
  time_total_s: 860.5207362174988
  timestamp: 1585075812
  timesteps_since_restore: 140000
  timesteps_this_iter: 10000
  timesteps_total: 140000
  training_iteration: 14
  trial_id: 44d516d6
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2/2 CPUs, 0/0 GPUs
Memory usage on this node: 12.1/201.2 GB
Result logdir: /users/PYS1027/chnrhughes/ray_results/simple_training_example_ring_v1
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - PPO_WaveAttenuationPOEnv-v0_0:	RUNNING, [2 CPUs, 0 GPUs], [pid=143796], 860 s, 14 iter, 140000 ts, 593 rew

[2m[36m(pid=143797)[0m 
[2m[36m(pid=143797)[0m -----------------------
[2m[36m(pid=143797)[0m ring length: 498
[2m[36m(pid=143797)[0m v_max: 12.496703821373096
[2m[36m(pid=143797)[0m -----------------------
[2m[36m(pid=143797)[0m 
[2m[36m(pid=143797)[0m -----------------------
[2m[36m(pid=143797)[0m ring length: 492
[2m[36m(pid=143797)[0m v_max: 12.275591251518899
[2m[36m(pid=143797)[0m -----------------------
[2m[36m(pid=143797)[0m 
[2m[36m(pid=143797)[0m -----------------------
[2m[36m(pid=143797)[0m ring length: 520
[2m[36m(pid=143797)[0m v_max: 13.296082591662728
[2m[36m(pid=143797)[0m -----------------------
[2m[36m(pid=143797)[0m 
[2m[36m(pid=143797)[0m -----------------------
[2m[36m(pid=143797)[0m ring length: 498
[2m[36m(pid=143797)[0m v_max: 12.496703821373096
[2m[36m(pid=143797)[0m -----------------------
[2m[36m(pid=143797)[0m 
[2m[36m(pid=143797)[0m -----------------------
[2m[36m(pid=143797)[0m ring length: 509
[2m[36m(pid=143797)[0m v_max: 12.89870698649076
[2m[36m(pid=143797)[0m -----------------------
Result for PPO_WaveAttenuationPOEnv-v0_0:
  custom_metrics: {}
  date: 2020-03-24_14-51-13
  done: false
  episode_len_mean: 2000.0
  episode_reward_max: 2683.2085819410995
  episode_reward_mean: 716.8222458972791
  episode_reward_min: -1561.815718655835
  episodes_this_iter: 5
  episodes_total: 75
  experiment_id: 3169a4f824ed4a02b4b42d55753086c5
  hostname: p0056.ten.osc.edu
  info:
    grad_time_ms: 227.844
    learner:
      default_policy:
        cur_kl_coeff: 1.220703143189894e-05
        cur_lr: 4.999999873689376e-05
        entropy: 0.882128894329071
        entropy_coeff: 0.0
        kl: 0.0049757156521081924
        policy_loss: -0.007402282673865557
        total_loss: 1203.111328125
        vf_explained_var: 0.0002993345260620117
        vf_loss: 1203.1187744140625
    load_time_ms: 2.386
    num_steps_sampled: 150000
    num_steps_trained: 150000
    sample_time_ms: 60707.219
    update_time_ms: 2.288
  iterations_since_restore: 15
  node_ip: 10.4.1.55
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 2.6873563218390806
    ram_util_percent: 6.0
  pid: 143796
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 3.902843728034312
    mean_inference_ms: 0.5418464025985771
    mean_processing_ms: 1.6846610443138816
  time_since_restore: 921.4662342071533
  time_this_iter_s: 60.94549798965454
  time_total_s: 921.4662342071533
  timestamp: 1585075873
  timesteps_since_restore: 150000
  timesteps_this_iter: 10000
  timesteps_total: 150000
  training_iteration: 15
  trial_id: 44d516d6
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2/2 CPUs, 0/0 GPUs
Memory usage on this node: 12.1/201.2 GB
Result logdir: /users/PYS1027/chnrhughes/ray_results/simple_training_example_ring_v1
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - PPO_WaveAttenuationPOEnv-v0_0:	RUNNING, [2 CPUs, 0 GPUs], [pid=143796], 921 s, 15 iter, 150000 ts, 717 rew

[2m[36m(pid=143797)[0m 
[2m[36m(pid=143797)[0m -----------------------
[2m[36m(pid=143797)[0m ring length: 502
[2m[36m(pid=143797)[0m v_max: 12.64340242846283
[2m[36m(pid=143797)[0m -----------------------
[2m[36m(pid=143797)[0m 
[2m[36m(pid=143797)[0m -----------------------
[2m[36m(pid=143797)[0m ring length: 520
[2m[36m(pid=143797)[0m v_max: 13.296082591662728
[2m[36m(pid=143797)[0m -----------------------
[2m[36m(pid=143797)[0m 
[2m[36m(pid=143797)[0m -----------------------
[2m[36m(pid=143797)[0m ring length: 490
[2m[36m(pid=143797)[0m v_max: 12.201610748825663
[2m[36m(pid=143797)[0m -----------------------
[2m[36m(pid=143797)[0m 
[2m[36m(pid=143797)[0m -----------------------
[2m[36m(pid=143797)[0m ring length: 517
[2m[36m(pid=143797)[0m v_max: 13.188184171646189
[2m[36m(pid=143797)[0m -----------------------
[2m[36m(pid=143797)[0m 
[2m[36m(pid=143797)[0m -----------------------
[2m[36m(pid=143797)[0m ring length: 513
[2m[36m(pid=143797)[0m v_max: 13.043759057511211
[2m[36m(pid=143797)[0m -----------------------
Result for PPO_WaveAttenuationPOEnv-v0_0:
  custom_metrics: {}
  date: 2020-03-24_14-52-14
  done: false
  episode_len_mean: 2000.0
  episode_reward_max: 2817.320387246599
  episode_reward_mean: 837.2438059281442
  episode_reward_min: -1561.815718655835
  episodes_this_iter: 5
  episodes_total: 80
  experiment_id: 3169a4f824ed4a02b4b42d55753086c5
  hostname: p0056.ten.osc.edu
  info:
    grad_time_ms: 225.669
    learner:
      default_policy:
        cur_kl_coeff: 6.10351571594947e-06
        cur_lr: 4.999999873689376e-05
        entropy: 0.8489494323730469
        entropy_coeff: 0.0
        kl: 0.004333944525569677
        policy_loss: -0.00614037923514843
        total_loss: 1397.8382568359375
        vf_explained_var: 0.0002809762954711914
        vf_loss: 1397.8443603515625
    load_time_ms: 2.324
    num_steps_sampled: 160000
    num_steps_trained: 160000
    sample_time_ms: 60642.5
    update_time_ms: 2.261
  iterations_since_restore: 16
  node_ip: 10.4.1.55
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 2.6965517241379313
    ram_util_percent: 6.0
  pid: 143796
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 3.9002546390261417
    mean_inference_ms: 0.5411331023398609
    mean_processing_ms: 1.6845213809735913
  time_since_restore: 982.1744170188904
  time_this_iter_s: 60.70818281173706
  time_total_s: 982.1744170188904
  timestamp: 1585075934
  timesteps_since_restore: 160000
  timesteps_this_iter: 10000
  timesteps_total: 160000
  training_iteration: 16
  trial_id: 44d516d6
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2/2 CPUs, 0/0 GPUs
Memory usage on this node: 12.1/201.2 GB
Result logdir: /users/PYS1027/chnrhughes/ray_results/simple_training_example_ring_v1
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - PPO_WaveAttenuationPOEnv-v0_0:	RUNNING, [2 CPUs, 0 GPUs], [pid=143796], 982 s, 16 iter, 160000 ts, 837 rew

[2m[36m(pid=143797)[0m 
[2m[36m(pid=143797)[0m -----------------------
[2m[36m(pid=143797)[0m ring length: 501
[2m[36m(pid=143797)[0m v_max: 12.606782077081403
[2m[36m(pid=143797)[0m -----------------------
[2m[36m(pid=143797)[0m 
[2m[36m(pid=143797)[0m -----------------------
[2m[36m(pid=143797)[0m ring length: 501
[2m[36m(pid=143797)[0m v_max: 12.606782077081403
[2m[36m(pid=143797)[0m -----------------------
[2m[36m(pid=143797)[0m 
[2m[36m(pid=143797)[0m -----------------------
[2m[36m(pid=143797)[0m ring length: 503
[2m[36m(pid=143797)[0m v_max: 12.679986184756686
[2m[36m(pid=143797)[0m -----------------------
[2m[36m(pid=143797)[0m 
[2m[36m(pid=143797)[0m -----------------------
[2m[36m(pid=143797)[0m ring length: 498
[2m[36m(pid=143797)[0m v_max: 12.496703821373096
[2m[36m(pid=143797)[0m -----------------------
[2m[36m(pid=143797)[0m 
[2m[36m(pid=143797)[0m -----------------------
[2m[36m(pid=143797)[0m ring length: 494
[2m[36m(pid=143797)[0m v_max: 12.34943486433356
[2m[36m(pid=143797)[0m -----------------------
Result for PPO_WaveAttenuationPOEnv-v0_0:
  custom_metrics: {}
  date: 2020-03-24_14-53-15
  done: false
  episode_len_mean: 2000.0
  episode_reward_max: 2817.320387246599
  episode_reward_mean: 947.5359776427173
  episode_reward_min: -1561.815718655835
  episodes_this_iter: 5
  episodes_total: 85
  experiment_id: 3169a4f824ed4a02b4b42d55753086c5
  hostname: p0056.ten.osc.edu
  info:
    grad_time_ms: 225.285
    learner:
      default_policy:
        cur_kl_coeff: 3.051757857974735e-06
        cur_lr: 4.999999873689376e-05
        entropy: 0.818906843662262
        entropy_coeff: 0.0
        kl: 0.004257345572113991
        policy_loss: -0.006059321574866772
        total_loss: 1462.6898193359375
        vf_explained_var: 7.12275505065918e-05
        vf_loss: 1462.6961669921875
    load_time_ms: 2.313
    num_steps_sampled: 170000
    num_steps_trained: 170000
    sample_time_ms: 60562.341
    update_time_ms: 2.259
  iterations_since_restore: 17
  node_ip: 10.4.1.55
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 2.6942528735632187
    ram_util_percent: 6.0
  pid: 143796
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 3.897926798841153
    mean_inference_ms: 0.5405604171255948
    mean_processing_ms: 1.6843819260096582
  time_since_restore: 1043.270670890808
  time_this_iter_s: 61.096253871917725
  time_total_s: 1043.270670890808
  timestamp: 1585075995
  timesteps_since_restore: 170000
  timesteps_this_iter: 10000
  timesteps_total: 170000
  training_iteration: 17
  trial_id: 44d516d6
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2/2 CPUs, 0/0 GPUs
Memory usage on this node: 12.1/201.2 GB
Result logdir: /users/PYS1027/chnrhughes/ray_results/simple_training_example_ring_v1
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - PPO_WaveAttenuationPOEnv-v0_0:	RUNNING, [2 CPUs, 0 GPUs], [pid=143796], 1043 s, 17 iter, 170000 ts, 948 rew

[2m[36m(pid=143797)[0m 
[2m[36m(pid=143797)[0m -----------------------
[2m[36m(pid=143797)[0m ring length: 496
[2m[36m(pid=143797)[0m v_max: 12.423139687457347
[2m[36m(pid=143797)[0m -----------------------
[2m[36m(pid=143797)[0m 
[2m[36m(pid=143797)[0m -----------------------
[2m[36m(pid=143797)[0m ring length: 512
[2m[36m(pid=143797)[0m v_max: 13.007554232214234
[2m[36m(pid=143797)[0m -----------------------
[2m[36m(pid=143797)[0m 
[2m[36m(pid=143797)[0m -----------------------
[2m[36m(pid=143797)[0m ring length: 503
[2m[36m(pid=143797)[0m v_max: 12.679986184756686
[2m[36m(pid=143797)[0m -----------------------
[2m[36m(pid=143797)[0m 
[2m[36m(pid=143797)[0m -----------------------
[2m[36m(pid=143797)[0m ring length: 516
[2m[36m(pid=143797)[0m v_max: 13.152137487657606
[2m[36m(pid=143797)[0m -----------------------
[2m[36m(pid=143797)[0m 
[2m[36m(pid=143797)[0m -----------------------
[2m[36m(pid=143797)[0m ring length: 500
[2m[36m(pid=143797)[0m v_max: 12.570125367437457
[2m[36m(pid=143797)[0m -----------------------
Result for PPO_WaveAttenuationPOEnv-v0_0:
  custom_metrics: {}
  date: 2020-03-24_14-54-17
  done: false
  episode_len_mean: 2000.0
  episode_reward_max: 3022.4657505711575
  episode_reward_mean: 1053.1372321765357
  episode_reward_min: -1561.815718655835
  episodes_this_iter: 5
  episodes_total: 90
  experiment_id: 3169a4f824ed4a02b4b42d55753086c5
  hostname: p0056.ten.osc.edu
  info:
    grad_time_ms: 225.025
    learner:
      default_policy:
        cur_kl_coeff: 1.5258789289873675e-06
        cur_lr: 4.999999873689376e-05
        entropy: 0.7957285046577454
        entropy_coeff: 0.0
        kl: 0.008560189045965672
        policy_loss: -0.006017349660396576
        total_loss: 1613.557861328125
        vf_explained_var: 0.00013941526412963867
        vf_loss: 1613.5638427734375
    load_time_ms: 2.2
    num_steps_sampled: 180000
    num_steps_trained: 180000
    sample_time_ms: 60642.371
    update_time_ms: 2.213
  iterations_since_restore: 18
  node_ip: 10.4.1.55
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 2.768965517241379
    ram_util_percent: 6.0
  pid: 143796
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 3.8960656246674734
    mean_inference_ms: 0.5400083993661088
    mean_processing_ms: 1.684260887031623
  time_since_restore: 1104.9333908557892
  time_this_iter_s: 61.66271996498108
  time_total_s: 1104.9333908557892
  timestamp: 1585076057
  timesteps_since_restore: 180000
  timesteps_this_iter: 10000
  timesteps_total: 180000
  training_iteration: 18
  trial_id: 44d516d6
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2/2 CPUs, 0/0 GPUs
Memory usage on this node: 12.1/201.2 GB
Result logdir: /users/PYS1027/chnrhughes/ray_results/simple_training_example_ring_v1
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - PPO_WaveAttenuationPOEnv-v0_0:	RUNNING, [2 CPUs, 0 GPUs], [pid=143796], 1104 s, 18 iter, 180000 ts, 1.05e+03 rew

[2m[36m(pid=143797)[0m 
[2m[36m(pid=143797)[0m -----------------------
[2m[36m(pid=143797)[0m ring length: 495
[2m[36m(pid=143797)[0m v_max: 12.386304743340318
[2m[36m(pid=143797)[0m -----------------------
[2m[36m(pid=143797)[0m 
[2m[36m(pid=143797)[0m -----------------------
[2m[36m(pid=143797)[0m ring length: 505
[2m[36m(pid=143797)[0m v_max: 12.753042965621004
[2m[36m(pid=143797)[0m -----------------------
[2m[36m(pid=143797)[0m 
[2m[36m(pid=143797)[0m -----------------------
[2m[36m(pid=143797)[0m ring length: 490
[2m[36m(pid=143797)[0m v_max: 12.201610748825663
[2m[36m(pid=143797)[0m -----------------------
[2m[36m(pid=143797)[0m 
[2m[36m(pid=143797)[0m -----------------------
[2m[36m(pid=143797)[0m ring length: 513
[2m[36m(pid=143797)[0m v_max: 13.043759057511211
[2m[36m(pid=143797)[0m -----------------------
[2m[36m(pid=143797)[0m 
[2m[36m(pid=143797)[0m -----------------------
[2m[36m(pid=143797)[0m ring length: 508
[2m[36m(pid=143797)[0m v_max: 12.862347763562411
[2m[36m(pid=143797)[0m -----------------------
Result for PPO_WaveAttenuationPOEnv-v0_0:
  custom_metrics: {}
  date: 2020-03-24_14-55-18
  done: false
  episode_len_mean: 2000.0
  episode_reward_max: 3022.4657505711575
  episode_reward_mean: 1127.6441616996822
  episode_reward_min: -1561.815718655835
  episodes_this_iter: 5
  episodes_total: 95
  experiment_id: 3169a4f824ed4a02b4b42d55753086c5
  hostname: p0056.ten.osc.edu
  info:
    grad_time_ms: 225.368
    learner:
      default_policy:
        cur_kl_coeff: 7.629394644936838e-07
        cur_lr: 4.999999873689376e-05
        entropy: 0.7778713703155518
        entropy_coeff: 0.0
        kl: 0.0037608405109494925
        policy_loss: -0.0043883235193789005
        total_loss: 1244.0692138671875
        vf_explained_var: 0.0023737549781799316
        vf_loss: 1244.0733642578125
    load_time_ms: 2.197
    num_steps_sampled: 190000
    num_steps_trained: 190000
    sample_time_ms: 60628.618
    update_time_ms: 2.205
  iterations_since_restore: 19
  node_ip: 10.4.1.55
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 2.7091954022988505
    ram_util_percent: 6.0
  pid: 143796
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 3.894282873410008
    mean_inference_ms: 0.539491251388448
    mean_processing_ms: 1.68415002920698
  time_since_restore: 1165.572279214859
  time_this_iter_s: 60.638888359069824
  time_total_s: 1165.572279214859
  timestamp: 1585076118
  timesteps_since_restore: 190000
  timesteps_this_iter: 10000
  timesteps_total: 190000
  training_iteration: 19
  trial_id: 44d516d6
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2/2 CPUs, 0/0 GPUs
Memory usage on this node: 12.1/201.2 GB
Result logdir: /users/PYS1027/chnrhughes/ray_results/simple_training_example_ring_v1
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - PPO_WaveAttenuationPOEnv-v0_0:	RUNNING, [2 CPUs, 0 GPUs], [pid=143796], 1165 s, 19 iter, 190000 ts, 1.13e+03 rew

[2m[36m(pid=143797)[0m 
[2m[36m(pid=143797)[0m -----------------------
[2m[36m(pid=143797)[0m ring length: 520
[2m[36m(pid=143797)[0m v_max: 13.296082591662728
[2m[36m(pid=143797)[0m -----------------------
[2m[36m(pid=143797)[0m 
[2m[36m(pid=143797)[0m -----------------------
[2m[36m(pid=143797)[0m ring length: 501
[2m[36m(pid=143797)[0m v_max: 12.606782077081403
[2m[36m(pid=143797)[0m -----------------------
[2m[36m(pid=143797)[0m 
[2m[36m(pid=143797)[0m -----------------------
[2m[36m(pid=143797)[0m ring length: 501
[2m[36m(pid=143797)[0m v_max: 12.606782077081403
[2m[36m(pid=143797)[0m -----------------------
[2m[36m(pid=143797)[0m 
[2m[36m(pid=143797)[0m -----------------------
[2m[36m(pid=143797)[0m ring length: 496
[2m[36m(pid=143797)[0m v_max: 12.423139687457347
[2m[36m(pid=143797)[0m -----------------------
[2m[36m(pid=143797)[0m 
[2m[36m(pid=143797)[0m -----------------------
[2m[36m(pid=143797)[0m ring length: 494
[2m[36m(pid=143797)[0m v_max: 12.34943486433356
[2m[36m(pid=143797)[0m -----------------------
Result for PPO_WaveAttenuationPOEnv-v0_0:
  custom_metrics: {}
  date: 2020-03-24_14-56-19
  done: false
  episode_len_mean: 2000.0
  episode_reward_max: 3279.096487979419
  episode_reward_mean: 1220.525822688069
  episode_reward_min: -1561.815718655835
  episodes_this_iter: 5
  episodes_total: 100
  experiment_id: 3169a4f824ed4a02b4b42d55753086c5
  hostname: p0056.ten.osc.edu
  info:
    grad_time_ms: 225.436
    learner:
      default_policy:
        cur_kl_coeff: 3.814697322468419e-07
        cur_lr: 4.999999873689376e-05
        entropy: 0.7485518455505371
        entropy_coeff: 0.0
        kl: 0.0034255520440638065
        policy_loss: -0.0029737490694969893
        total_loss: 1775.04443359375
        vf_explained_var: 0.00020635128021240234
        vf_loss: 1775.0472412109375
    load_time_ms: 2.217
    num_steps_sampled: 200000
    num_steps_trained: 200000
    sample_time_ms: 60690.469
    update_time_ms: 2.125
  iterations_since_restore: 20
  node_ip: 10.4.1.55
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 2.7045977011494253
    ram_util_percent: 6.0
  pid: 143796
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 3.8926163371609617
    mean_inference_ms: 0.5390674731540893
    mean_processing_ms: 1.684047541639286
  time_since_restore: 1226.6114563941956
  time_this_iter_s: 61.03917717933655
  time_total_s: 1226.6114563941956
  timestamp: 1585076179
  timesteps_since_restore: 200000
  timesteps_this_iter: 10000
  timesteps_total: 200000
  training_iteration: 20
  trial_id: 44d516d6
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2/2 CPUs, 0/0 GPUs
Memory usage on this node: 12.1/201.2 GB
Result logdir: /users/PYS1027/chnrhughes/ray_results/simple_training_example_ring_v1
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - PPO_WaveAttenuationPOEnv-v0_0:	RUNNING, [2 CPUs, 0 GPUs], [pid=143796], 1226 s, 20 iter, 200000 ts, 1.22e+03 rew

[2m[36m(pid=143797)[0m 
[2m[36m(pid=143797)[0m -----------------------
[2m[36m(pid=143797)[0m ring length: 502
[2m[36m(pid=143797)[0m v_max: 12.64340242846283
[2m[36m(pid=143797)[0m -----------------------
[2m[36m(pid=143797)[0m 
[2m[36m(pid=143797)[0m -----------------------
[2m[36m(pid=143797)[0m ring length: 491
[2m[36m(pid=143797)[0m v_max: 12.238617992673053
[2m[36m(pid=143797)[0m -----------------------
[2m[36m(pid=143797)[0m 
[2m[36m(pid=143797)[0m -----------------------
[2m[36m(pid=143797)[0m ring length: 497
[2m[36m(pid=143797)[0m v_max: 12.45993945925872
[2m[36m(pid=143797)[0m -----------------------
[2m[36m(pid=143797)[0m 
[2m[36m(pid=143797)[0m -----------------------
[2m[36m(pid=143797)[0m ring length: 504
[2m[36m(pid=143797)[0m v_max: 12.716533109302146
[2m[36m(pid=143797)[0m -----------------------
[2m[36m(pid=143797)[0m 
[2m[36m(pid=143797)[0m -----------------------
[2m[36m(pid=143797)[0m ring length: 502
[2m[36m(pid=143797)[0m v_max: 12.64340242846283
[2m[36m(pid=143797)[0m -----------------------
Result for PPO_WaveAttenuationPOEnv-v0_0:
  custom_metrics: {}
  date: 2020-03-24_14-57-20
  done: false
  episode_len_mean: 2000.0
  episode_reward_max: 3279.096487979419
  episode_reward_mean: 1410.606853664509
  episode_reward_min: -1561.815718655835
  episodes_this_iter: 5
  episodes_total: 105
  experiment_id: 3169a4f824ed4a02b4b42d55753086c5
  hostname: p0056.ten.osc.edu
  info:
    grad_time_ms: 223.158
    learner:
      default_policy:
        cur_kl_coeff: 1.9073486612342094e-07
        cur_lr: 4.999999873689376e-05
        entropy: 0.7277855277061462
        entropy_coeff: 0.0
        kl: 0.003253970295190811
        policy_loss: -0.002429322572425008
        total_loss: 1807.12158203125
        vf_explained_var: 5.733966827392578e-05
        vf_loss: 1807.1236572265625
    load_time_ms: 2.195
    num_steps_sampled: 210000
    num_steps_trained: 210000
    sample_time_ms: 60745.325
    update_time_ms: 2.109
  iterations_since_restore: 21
  node_ip: 10.4.1.55
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 2.686206896551724
    ram_util_percent: 6.0
  pid: 143796
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 3.8791863186031406
    mean_inference_ms: 0.5381038608324065
    mean_processing_ms: 1.6834821513579532
  time_since_restore: 1287.6597561836243
  time_this_iter_s: 61.04829978942871
  time_total_s: 1287.6597561836243
  timestamp: 1585076240
  timesteps_since_restore: 210000
  timesteps_this_iter: 10000
  timesteps_total: 210000
  training_iteration: 21
  trial_id: 44d516d6
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2/2 CPUs, 0/0 GPUs
Memory usage on this node: 12.1/201.2 GB
Result logdir: /users/PYS1027/chnrhughes/ray_results/simple_training_example_ring_v1
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - PPO_WaveAttenuationPOEnv-v0_0:	RUNNING, [2 CPUs, 0 GPUs], [pid=143796], 1287 s, 21 iter, 210000 ts, 1.41e+03 rew

[2m[36m(pid=143797)[0m 
[2m[36m(pid=143797)[0m -----------------------
[2m[36m(pid=143797)[0m ring length: 493
[2m[36m(pid=143797)[0m v_max: 12.31253028789948
[2m[36m(pid=143797)[0m -----------------------
[2m[36m(pid=143797)[0m 
[2m[36m(pid=143797)[0m -----------------------
[2m[36m(pid=143797)[0m ring length: 507
[2m[36m(pid=143797)[0m v_max: 12.825950528689797
[2m[36m(pid=143797)[0m -----------------------
[2m[36m(pid=143797)[0m 
[2m[36m(pid=143797)[0m -----------------------
[2m[36m(pid=143797)[0m ring length: 510
[2m[36m(pid=143797)[0m v_max: 12.93502796218664
[2m[36m(pid=143797)[0m -----------------------
[2m[36m(pid=143797)[0m 
[2m[36m(pid=143797)[0m -----------------------
[2m[36m(pid=143797)[0m ring length: 492
[2m[36m(pid=143797)[0m v_max: 12.275591251518899
[2m[36m(pid=143797)[0m -----------------------
[2m[36m(pid=143797)[0m 
[2m[36m(pid=143797)[0m -----------------------
[2m[36m(pid=143797)[0m ring length: 490
[2m[36m(pid=143797)[0m v_max: 12.201610748825663
[2m[36m(pid=143797)[0m -----------------------
Result for PPO_WaveAttenuationPOEnv-v0_0:
  custom_metrics: {}
  date: 2020-03-24_14-58-21
  done: false
  episode_len_mean: 2000.0
  episode_reward_max: 3279.096487979419
  episode_reward_mean: 1601.848733777513
  episode_reward_min: -1561.815718655835
  episodes_this_iter: 5
  episodes_total: 110
  experiment_id: 3169a4f824ed4a02b4b42d55753086c5
  hostname: p0056.ten.osc.edu
  info:
    grad_time_ms: 222.237
    learner:
      default_policy:
        cur_kl_coeff: 9.536743306171047e-08
        cur_lr: 4.999999873689376e-05
        entropy: 0.7110336422920227
        entropy_coeff: 0.0
        kl: 0.004121097736060619
        policy_loss: -0.0019352592062205076
        total_loss: 1789.509765625
        vf_explained_var: 0.0001933574676513672
        vf_loss: 1789.5115966796875
    load_time_ms: 2.181
    num_steps_sampled: 220000
    num_steps_trained: 220000
    sample_time_ms: 60769.126
    update_time_ms: 2.081
  iterations_since_restore: 22
  node_ip: 10.4.1.55
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 2.7137931034482756
    ram_util_percent: 6.0
  pid: 143796
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 3.8734693556501103
    mean_inference_ms: 0.5371874676966383
    mean_processing_ms: 1.6831340005291426
  time_since_restore: 1348.5856535434723
  time_this_iter_s: 60.92589735984802
  time_total_s: 1348.5856535434723
  timestamp: 1585076301
  timesteps_since_restore: 220000
  timesteps_this_iter: 10000
  timesteps_total: 220000
  training_iteration: 22
  trial_id: 44d516d6
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2/2 CPUs, 0/0 GPUs
Memory usage on this node: 12.1/201.2 GB
Result logdir: /users/PYS1027/chnrhughes/ray_results/simple_training_example_ring_v1
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - PPO_WaveAttenuationPOEnv-v0_0:	RUNNING, [2 CPUs, 0 GPUs], [pid=143796], 1348 s, 22 iter, 220000 ts, 1.6e+03 rew

[2m[36m(pid=143797)[0m 
[2m[36m(pid=143797)[0m -----------------------
[2m[36m(pid=143797)[0m ring length: 499
[2m[36m(pid=143797)[0m v_max: 12.533432536501882
[2m[36m(pid=143797)[0m -----------------------
[2m[36m(pid=143797)[0m 
[2m[36m(pid=143797)[0m -----------------------
[2m[36m(pid=143797)[0m ring length: 511
[2m[36m(pid=143797)[0m v_max: 12.97131045565535
[2m[36m(pid=143797)[0m -----------------------
[2m[36m(pid=143797)[0m 
[2m[36m(pid=143797)[0m -----------------------
[2m[36m(pid=143797)[0m ring length: 493
[2m[36m(pid=143797)[0m v_max: 12.31253028789948
[2m[36m(pid=143797)[0m -----------------------
[2m[36m(pid=143797)[0m 
[2m[36m(pid=143797)[0m -----------------------
[2m[36m(pid=143797)[0m ring length: 503
[2m[36m(pid=143797)[0m v_max: 12.679986184756686
[2m[36m(pid=143797)[0m -----------------------
[2m[36m(pid=143797)[0m 
[2m[36m(pid=143797)[0m -----------------------
[2m[36m(pid=143797)[0m ring length: 505
[2m[36m(pid=143797)[0m v_max: 12.753042965621004
[2m[36m(pid=143797)[0m -----------------------
Result for PPO_WaveAttenuationPOEnv-v0_0:
  custom_metrics: {}
  date: 2020-03-24_14-59-22
  done: false
  episode_len_mean: 2000.0
  episode_reward_max: 3279.096487979419
  episode_reward_mean: 1793.646096998171
  episode_reward_min: -510.1660740044789
  episodes_this_iter: 5
  episodes_total: 115
  experiment_id: 3169a4f824ed4a02b4b42d55753086c5
  hostname: p0056.ten.osc.edu
  info:
    grad_time_ms: 221.658
    learner:
      default_policy:
        cur_kl_coeff: 4.7683716530855236e-08
        cur_lr: 4.999999873689376e-05
        entropy: 0.6896448135375977
        entropy_coeff: 0.0
        kl: 0.002932222792878747
        policy_loss: -0.003297637216746807
        total_loss: 1613.7183837890625
        vf_explained_var: 0.000644385814666748
        vf_loss: 1613.7218017578125
    load_time_ms: 2.149
    num_steps_sampled: 230000
    num_steps_trained: 230000
    sample_time_ms: 60763.619
    update_time_ms: 2.063
  iterations_since_restore: 23
  node_ip: 10.4.1.55
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 2.6499999999999995
    ram_util_percent: 6.0
  pid: 143796
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 3.870405881091309
    mean_inference_ms: 0.5360416449078684
    mean_processing_ms: 1.6828598444486065
  time_since_restore: 1409.441786289215
  time_this_iter_s: 60.8561327457428
  time_total_s: 1409.441786289215
  timestamp: 1585076362
  timesteps_since_restore: 230000
  timesteps_this_iter: 10000
  timesteps_total: 230000
  training_iteration: 23
  trial_id: 44d516d6
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2/2 CPUs, 0/0 GPUs
Memory usage on this node: 12.1/201.2 GB
Result logdir: /users/PYS1027/chnrhughes/ray_results/simple_training_example_ring_v1
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - PPO_WaveAttenuationPOEnv-v0_0:	RUNNING, [2 CPUs, 0 GPUs], [pid=143796], 1409 s, 23 iter, 230000 ts, 1.79e+03 rew

[2m[36m(pid=143797)[0m 
[2m[36m(pid=143797)[0m -----------------------
[2m[36m(pid=143797)[0m ring length: 494
[2m[36m(pid=143797)[0m v_max: 12.34943486433356
[2m[36m(pid=143797)[0m -----------------------
[2m[36m(pid=143797)[0m 
[2m[36m(pid=143797)[0m -----------------------
[2m[36m(pid=143797)[0m ring length: 520
[2m[36m(pid=143797)[0m v_max: 13.296082591662728
[2m[36m(pid=143797)[0m -----------------------
[2m[36m(pid=143797)[0m 
[2m[36m(pid=143797)[0m -----------------------
[2m[36m(pid=143797)[0m ring length: 508
[2m[36m(pid=143797)[0m v_max: 12.862347763562411
[2m[36m(pid=143797)[0m -----------------------
[2m[36m(pid=143797)[0m 
[2m[36m(pid=143797)[0m -----------------------
[2m[36m(pid=143797)[0m ring length: 501
[2m[36m(pid=143797)[0m v_max: 12.606782077081403
[2m[36m(pid=143797)[0m -----------------------
[2m[36m(pid=143797)[0m 
[2m[36m(pid=143797)[0m -----------------------
[2m[36m(pid=143797)[0m ring length: 512
[2m[36m(pid=143797)[0m v_max: 13.007554232214234
[2m[36m(pid=143797)[0m -----------------------
Result for PPO_WaveAttenuationPOEnv-v0_0:
  custom_metrics: {}
  date: 2020-03-24_15-00-23
  done: false
  episode_len_mean: 2000.0
  episode_reward_max: 3312.2928835058046
  episode_reward_mean: 1966.457127680716
  episode_reward_min: -400.5354780884762
  episodes_this_iter: 5
  episodes_total: 120
  experiment_id: 3169a4f824ed4a02b4b42d55753086c5
  hostname: p0056.ten.osc.edu
  info:
    grad_time_ms: 220.864
    learner:
      default_policy:
        cur_kl_coeff: 2.3841858265427618e-08
        cur_lr: 4.999999873689376e-05
        entropy: 0.6677730083465576
        entropy_coeff: 0.0
        kl: 0.005607748404145241
        policy_loss: -0.0030897941906005144
        total_loss: 1987.3724365234375
        vf_explained_var: 0.0001672506332397461
        vf_loss: 1987.3756103515625
    load_time_ms: 2.01
    num_steps_sampled: 240000
    num_steps_trained: 240000
    sample_time_ms: 60760.605
    update_time_ms: 2.049
  iterations_since_restore: 24
  node_ip: 10.4.1.55
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 2.791954022988506
    ram_util_percent: 6.0
  pid: 143796
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 3.8683814999153
    mean_inference_ms: 0.5353543959479568
    mean_processing_ms: 1.682671332479167
  time_since_restore: 1470.435551404953
  time_this_iter_s: 60.993765115737915
  time_total_s: 1470.435551404953
  timestamp: 1585076423
  timesteps_since_restore: 240000
  timesteps_this_iter: 10000
  timesteps_total: 240000
  training_iteration: 24
  trial_id: 44d516d6
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2/2 CPUs, 0/0 GPUs
Memory usage on this node: 12.1/201.2 GB
Result logdir: /users/PYS1027/chnrhughes/ray_results/simple_training_example_ring_v1
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - PPO_WaveAttenuationPOEnv-v0_0:	RUNNING, [2 CPUs, 0 GPUs], [pid=143796], 1470 s, 24 iter, 240000 ts, 1.97e+03 rew

[2m[36m(pid=143797)[0m 
[2m[36m(pid=143797)[0m -----------------------
[2m[36m(pid=143797)[0m ring length: 494
[2m[36m(pid=143797)[0m v_max: 12.34943486433356
[2m[36m(pid=143797)[0m -----------------------
[2m[36m(pid=143797)[0m 
[2m[36m(pid=143797)[0m -----------------------
[2m[36m(pid=143797)[0m ring length: 502
[2m[36m(pid=143797)[0m v_max: 12.64340242846283
[2m[36m(pid=143797)[0m -----------------------
[2m[36m(pid=143797)[0m 
[2m[36m(pid=143797)[0m -----------------------
[2m[36m(pid=143797)[0m ring length: 505
[2m[36m(pid=143797)[0m v_max: 12.753042965621004
[2m[36m(pid=143797)[0m -----------------------
[2m[36m(pid=143797)[0m 
[2m[36m(pid=143797)[0m -----------------------
[2m[36m(pid=143797)[0m ring length: 512
[2m[36m(pid=143797)[0m v_max: 13.007554232214234
[2m[36m(pid=143797)[0m -----------------------
[2m[36m(pid=143797)[0m 
[2m[36m(pid=143797)[0m -----------------------
[2m[36m(pid=143797)[0m ring length: 516
[2m[36m(pid=143797)[0m v_max: 13.152137487657606
[2m[36m(pid=143797)[0m -----------------------
Result for PPO_WaveAttenuationPOEnv-v0_0:
  custom_metrics: {}
  date: 2020-03-24_15-01-23
  done: false
  episode_len_mean: 2000.0
  episode_reward_max: 3312.2928835058046
  episode_reward_mean: 2100.293490836254
  episode_reward_min: 63.0343730145401
  episodes_this_iter: 5
  episodes_total: 125
  experiment_id: 3169a4f824ed4a02b4b42d55753086c5
  hostname: p0056.ten.osc.edu
  info:
    grad_time_ms: 222.392
    learner:
      default_policy:
        cur_kl_coeff: 1.1920929132713809e-08
        cur_lr: 4.999999873689376e-05
        entropy: 0.6642405986785889
        entropy_coeff: 0.0
        kl: 0.005949255544692278
        policy_loss: -0.00126065278891474
        total_loss: 1323.7481689453125
        vf_explained_var: 0.002413630485534668
        vf_loss: 1323.7493896484375
    load_time_ms: 2.044
    num_steps_sampled: 250000
    num_steps_trained: 250000
    sample_time_ms: 60748.679
    update_time_ms: 2.071
  iterations_since_restore: 25
  node_ip: 10.4.1.55
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 2.68735632183908
    ram_util_percent: 6.0
  pid: 143796
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 3.8669302186378065
    mean_inference_ms: 0.5345148985565161
    mean_processing_ms: 1.682592442463988
  time_since_restore: 1531.2779688835144
  time_this_iter_s: 60.8424174785614
  time_total_s: 1531.2779688835144
  timestamp: 1585076483
  timesteps_since_restore: 250000
  timesteps_this_iter: 10000
  timesteps_total: 250000
  training_iteration: 25
  trial_id: 44d516d6
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2/2 CPUs, 0/0 GPUs
Memory usage on this node: 12.1/201.2 GB
Result logdir: /users/PYS1027/chnrhughes/ray_results/simple_training_example_ring_v1
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - PPO_WaveAttenuationPOEnv-v0_0:	RUNNING, [2 CPUs, 0 GPUs], [pid=143796], 1531 s, 25 iter, 250000 ts, 2.1e+03 rew

[2m[36m(pid=143796)[0m 2020-03-24 15:01:23,857	WARNING ppo.py:121 -- The magnitude of your environment rewards are more than 210.0x the scale of `vf_clip_param`. This means that it will take more than 210.0 iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.
[2m[36m(pid=143797)[0m 
[2m[36m(pid=143797)[0m -----------------------
[2m[36m(pid=143797)[0m ring length: 497
[2m[36m(pid=143797)[0m v_max: 12.45993945925872
[2m[36m(pid=143797)[0m -----------------------
[2m[36m(pid=143797)[0m 
[2m[36m(pid=143797)[0m -----------------------
[2m[36m(pid=143797)[0m ring length: 513
[2m[36m(pid=143797)[0m v_max: 13.043759057511211
[2m[36m(pid=143797)[0m -----------------------
[2m[36m(pid=143797)[0m 
[2m[36m(pid=143797)[0m -----------------------
[2m[36m(pid=143797)[0m ring length: 501
[2m[36m(pid=143797)[0m v_max: 12.606782077081403
[2m[36m(pid=143797)[0m -----------------------
[2m[36m(pid=143797)[0m 
[2m[36m(pid=143797)[0m -----------------------
[2m[36m(pid=143797)[0m ring length: 515
[2m[36m(pid=143797)[0m v_max: 13.116050918675148
[2m[36m(pid=143797)[0m -----------------------
[2m[36m(pid=143797)[0m 
[2m[36m(pid=143797)[0m -----------------------
[2m[36m(pid=143797)[0m ring length: 498
[2m[36m(pid=143797)[0m v_max: 12.496703821373096
[2m[36m(pid=143797)[0m -----------------------
Result for PPO_WaveAttenuationPOEnv-v0_0:
  custom_metrics: {}
  date: 2020-03-24_15-02-25
  done: false
  episode_len_mean: 2000.0
  episode_reward_max: 3393.4441113094736
  episode_reward_mean: 2253.336028162392
  episode_reward_min: 295.80203566447676
  episodes_this_iter: 5
  episodes_total: 130
  experiment_id: 3169a4f824ed4a02b4b42d55753086c5
  hostname: p0056.ten.osc.edu
  info:
    grad_time_ms: 222.591
    learner:
      default_policy:
        cur_kl_coeff: 5.9604645663569045e-09
        cur_lr: 4.999999873689376e-05
        entropy: 0.6336913108825684
        entropy_coeff: 0.0
        kl: 0.002826838521286845
        policy_loss: -0.0032058146316558123
        total_loss: 2117.654052734375
        vf_explained_var: 0.00011879205703735352
        vf_loss: 2117.656982421875
    load_time_ms: 2.054
    num_steps_sampled: 260000
    num_steps_trained: 260000
    sample_time_ms: 60798.362
    update_time_ms: 2.069
  iterations_since_restore: 26
  node_ip: 10.4.1.55
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 2.7103448275862068
    ram_util_percent: 6.0
  pid: 143796
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 3.865633716791603
    mean_inference_ms: 0.533708650863338
    mean_processing_ms: 1.6825096948577936
  time_since_restore: 1592.4850192070007
  time_this_iter_s: 61.20705032348633
  time_total_s: 1592.4850192070007
  timestamp: 1585076545
  timesteps_since_restore: 260000
  timesteps_this_iter: 10000
  timesteps_total: 260000
  training_iteration: 26
  trial_id: 44d516d6
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2/2 CPUs, 0/0 GPUs
Memory usage on this node: 12.1/201.2 GB
Result logdir: /users/PYS1027/chnrhughes/ray_results/simple_training_example_ring_v1
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - PPO_WaveAttenuationPOEnv-v0_0:	RUNNING, [2 CPUs, 0 GPUs], [pid=143796], 1592 s, 26 iter, 260000 ts, 2.25e+03 rew

[2m[36m(pid=143796)[0m 2020-03-24 15:02:25,084	WARNING ppo.py:121 -- The magnitude of your environment rewards are more than 225.0x the scale of `vf_clip_param`. This means that it will take more than 225.0 iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.
[2m[36m(pid=143797)[0m 
[2m[36m(pid=143797)[0m -----------------------
[2m[36m(pid=143797)[0m ring length: 504
[2m[36m(pid=143797)[0m v_max: 12.716533109302146
[2m[36m(pid=143797)[0m -----------------------
[2m[36m(pid=143797)[0m 
[2m[36m(pid=143797)[0m -----------------------
[2m[36m(pid=143797)[0m ring length: 495
[2m[36m(pid=143797)[0m v_max: 12.386304743340318
[2m[36m(pid=143797)[0m -----------------------
[2m[36m(pid=143797)[0m 
[2m[36m(pid=143797)[0m -----------------------
[2m[36m(pid=143797)[0m ring length: 493
[2m[36m(pid=143797)[0m v_max: 12.31253028789948
[2m[36m(pid=143797)[0m -----------------------
[2m[36m(pid=143797)[0m 
[2m[36m(pid=143797)[0m -----------------------
[2m[36m(pid=143797)[0m ring length: 513
[2m[36m(pid=143797)[0m v_max: 13.043759057511211
[2m[36m(pid=143797)[0m -----------------------
[2m[36m(pid=143797)[0m 
[2m[36m(pid=143797)[0m -----------------------
[2m[36m(pid=143797)[0m ring length: 501
[2m[36m(pid=143797)[0m v_max: 12.606782077081403
[2m[36m(pid=143797)[0m -----------------------
Result for PPO_WaveAttenuationPOEnv-v0_0:
  custom_metrics: {}
  date: 2020-03-24_15-03-26
  done: false
  episode_len_mean: 2000.0
  episode_reward_max: 3560.67512629273
  episode_reward_mean: 2388.1277883212506
  episode_reward_min: 295.80203566447676
  episodes_this_iter: 5
  episodes_total: 135
  experiment_id: 3169a4f824ed4a02b4b42d55753086c5
  hostname: p0056.ten.osc.edu
  info:
    grad_time_ms: 222.594
    learner:
      default_policy:
        cur_kl_coeff: 2.9802322831784522e-09
        cur_lr: 4.999999873689376e-05
        entropy: 0.6143374443054199
        entropy_coeff: 0.0
        kl: 0.0025287331081926823
        policy_loss: -0.002096541691571474
        total_loss: 2231.6640625
        vf_explained_var: 0.00010776519775390625
        vf_loss: 2231.66552734375
    load_time_ms: 2.07
    num_steps_sampled: 270000
    num_steps_trained: 270000
    sample_time_ms: 60820.269
    update_time_ms: 2.042
  iterations_since_restore: 27
  node_ip: 10.4.1.55
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 3.0413793103448263
    ram_util_percent: 6.0
  pid: 143796
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 3.864062641408447
    mean_inference_ms: 0.5331227114645668
    mean_processing_ms: 1.6822592010885733
  time_since_restore: 1653.8018097877502
  time_this_iter_s: 61.31679058074951
  time_total_s: 1653.8018097877502
  timestamp: 1585076606
  timesteps_since_restore: 270000
  timesteps_this_iter: 10000
  timesteps_total: 270000
  training_iteration: 27
  trial_id: 44d516d6
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2/2 CPUs, 0/0 GPUs
Memory usage on this node: 12.1/201.2 GB
Result logdir: /users/PYS1027/chnrhughes/ray_results/simple_training_example_ring_v1
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - PPO_WaveAttenuationPOEnv-v0_0:	RUNNING, [2 CPUs, 0 GPUs], [pid=143796], 1653 s, 27 iter, 270000 ts, 2.39e+03 rew

[2m[36m(pid=143796)[0m 2020-03-24 15:03:26,410	WARNING ppo.py:121 -- The magnitude of your environment rewards are more than 239.0x the scale of `vf_clip_param`. This means that it will take more than 239.0 iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.
[2m[36m(pid=143797)[0m 
[2m[36m(pid=143797)[0m -----------------------
[2m[36m(pid=143797)[0m ring length: 498
[2m[36m(pid=143797)[0m v_max: 12.496703821373096
[2m[36m(pid=143797)[0m -----------------------
[2m[36m(pid=143797)[0m 
[2m[36m(pid=143797)[0m -----------------------
[2m[36m(pid=143797)[0m ring length: 497
[2m[36m(pid=143797)[0m v_max: 12.45993945925872
[2m[36m(pid=143797)[0m -----------------------
[2m[36m(pid=143797)[0m 
[2m[36m(pid=143797)[0m -----------------------
[2m[36m(pid=143797)[0m ring length: 491
[2m[36m(pid=143797)[0m v_max: 12.238617992673053
[2m[36m(pid=143797)[0m -----------------------
[2m[36m(pid=143797)[0m 
[2m[36m(pid=143797)[0m -----------------------
[2m[36m(pid=143797)[0m ring length: 505
[2m[36m(pid=143797)[0m v_max: 12.753042965621004
[2m[36m(pid=143797)[0m -----------------------
[2m[36m(pid=143797)[0m 
[2m[36m(pid=143797)[0m -----------------------
[2m[36m(pid=143797)[0m ring length: 493
[2m[36m(pid=143797)[0m v_max: 12.31253028789948
[2m[36m(pid=143797)[0m -----------------------
Result for PPO_WaveAttenuationPOEnv-v0_0:
  custom_metrics: {}
  date: 2020-03-24_15-04-27
  done: false
  episode_len_mean: 2000.0
  episode_reward_max: 3576.7027872657563
  episode_reward_mean: 2527.0020155936218
  episode_reward_min: 634.32449466576
  episodes_this_iter: 5
  episodes_total: 140
  experiment_id: 3169a4f824ed4a02b4b42d55753086c5
  hostname: p0056.ten.osc.edu
  info:
    grad_time_ms: 221.062
    learner:
      default_policy:
        cur_kl_coeff: 1.4901161415892261e-09
        cur_lr: 4.999999873689376e-05
        entropy: 0.5885140895843506
        entropy_coeff: 0.0
        kl: 0.002793974941596389
        policy_loss: -0.00307940854690969
        total_loss: 2328.739990234375
        vf_explained_var: 1.9609928131103516e-05
        vf_loss: 2328.742919921875
    load_time_ms: 2.106
    num_steps_sampled: 280000
    num_steps_trained: 280000
    sample_time_ms: 60782.595
    update_time_ms: 2.07
  iterations_since_restore: 28
  node_ip: 10.4.1.55
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 2.7170454545454543
    ram_util_percent: 6.0
  pid: 143796
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 3.862814204088768
    mean_inference_ms: 0.5326323945037874
    mean_processing_ms: 1.682062424710742
  time_since_restore: 1715.0733180046082
  time_this_iter_s: 61.27150821685791
  time_total_s: 1715.0733180046082
  timestamp: 1585076667
  timesteps_since_restore: 280000
  timesteps_this_iter: 10000
  timesteps_total: 280000
  training_iteration: 28
  trial_id: 44d516d6
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2/2 CPUs, 0/0 GPUs
Memory usage on this node: 12.1/201.2 GB
Result logdir: /users/PYS1027/chnrhughes/ray_results/simple_training_example_ring_v1
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - PPO_WaveAttenuationPOEnv-v0_0:	RUNNING, [2 CPUs, 0 GPUs], [pid=143796], 1715 s, 28 iter, 280000 ts, 2.53e+03 rew

[2m[36m(pid=143796)[0m 2020-03-24 15:04:27,690	WARNING ppo.py:121 -- The magnitude of your environment rewards are more than 253.0x the scale of `vf_clip_param`. This means that it will take more than 253.0 iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.
[2m[36m(pid=143797)[0m 
[2m[36m(pid=143797)[0m -----------------------
[2m[36m(pid=143797)[0m ring length: 519
[2m[36m(pid=143797)[0m v_max: 13.260156955398273
[2m[36m(pid=143797)[0m -----------------------
[2m[36m(pid=143797)[0m 
[2m[36m(pid=143797)[0m -----------------------
[2m[36m(pid=143797)[0m ring length: 507
[2m[36m(pid=143797)[0m v_max: 12.825950528689797
[2m[36m(pid=143797)[0m -----------------------
[2m[36m(pid=143797)[0m 
[2m[36m(pid=143797)[0m -----------------------
[2m[36m(pid=143797)[0m ring length: 490
[2m[36m(pid=143797)[0m v_max: 12.201610748825663
[2m[36m(pid=143797)[0m -----------------------
[2m[36m(pid=143797)[0m 
[2m[36m(pid=143797)[0m -----------------------
[2m[36m(pid=143797)[0m ring length: 499
[2m[36m(pid=143797)[0m v_max: 12.533432536501882
[2m[36m(pid=143797)[0m -----------------------
[2m[36m(pid=143797)[0m 
[2m[36m(pid=143797)[0m -----------------------
[2m[36m(pid=143797)[0m ring length: 503
[2m[36m(pid=143797)[0m v_max: 12.679986184756686
[2m[36m(pid=143797)[0m -----------------------
Result for PPO_WaveAttenuationPOEnv-v0_0:
  custom_metrics: {}
  date: 2020-03-24_15-05-28
  done: false
  episode_len_mean: 2000.0
  episode_reward_max: 3844.0883608037834
  episode_reward_mean: 2657.6723773836734
  episode_reward_min: 673.2829641783154
  episodes_this_iter: 5
  episodes_total: 145
  experiment_id: 3169a4f824ed4a02b4b42d55753086c5
  hostname: p0056.ten.osc.edu
  info:
    grad_time_ms: 218.81
    learner:
      default_policy:
        cur_kl_coeff: 7.450580707946131e-10
        cur_lr: 4.999999873689376e-05
        entropy: 0.5623329877853394
        entropy_coeff: 0.0
        kl: 0.0027078052517026663
        policy_loss: -0.00266095157712698
        total_loss: 2532.781494140625
        vf_explained_var: 7.259845733642578e-05
        vf_loss: 2532.784423828125
    load_time_ms: 2.114
    num_steps_sampled: 290000
    num_steps_trained: 290000
    sample_time_ms: 60802.996
    update_time_ms: 2.061
  iterations_since_restore: 29
  node_ip: 10.4.1.55
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 2.6686046511627906
    ram_util_percent: 6.0
  pid: 143796
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 3.861790496746772
    mean_inference_ms: 0.532238167271893
    mean_processing_ms: 1.6818909816774132
  time_since_restore: 1775.8923461437225
  time_this_iter_s: 60.81902813911438
  time_total_s: 1775.8923461437225
  timestamp: 1585076728
  timesteps_since_restore: 290000
  timesteps_this_iter: 10000
  timesteps_total: 290000
  training_iteration: 29
  trial_id: 44d516d6
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2/2 CPUs, 0/0 GPUs
Memory usage on this node: 12.1/201.2 GB
Result logdir: /users/PYS1027/chnrhughes/ray_results/simple_training_example_ring_v1
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - PPO_WaveAttenuationPOEnv-v0_0:	RUNNING, [2 CPUs, 0 GPUs], [pid=143796], 1775 s, 29 iter, 290000 ts, 2.66e+03 rew

[2m[36m(pid=143796)[0m 2020-03-24 15:05:28,518	WARNING ppo.py:121 -- The magnitude of your environment rewards are more than 266.0x the scale of `vf_clip_param`. This means that it will take more than 266.0 iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.
[2m[36m(pid=143797)[0m 
[2m[36m(pid=143797)[0m -----------------------
[2m[36m(pid=143797)[0m ring length: 519
[2m[36m(pid=143797)[0m v_max: 13.260156955398273
[2m[36m(pid=143797)[0m -----------------------
[2m[36m(pid=143797)[0m 
[2m[36m(pid=143797)[0m -----------------------
[2m[36m(pid=143797)[0m ring length: 516
[2m[36m(pid=143797)[0m v_max: 13.152137487657606
[2m[36m(pid=143797)[0m -----------------------
[2m[36m(pid=143797)[0m 
[2m[36m(pid=143797)[0m -----------------------
[2m[36m(pid=143797)[0m ring length: 516
[2m[36m(pid=143797)[0m v_max: 13.152137487657606
[2m[36m(pid=143797)[0m -----------------------
[2m[36m(pid=143797)[0m 
[2m[36m(pid=143797)[0m -----------------------
[2m[36m(pid=143797)[0m ring length: 509
[2m[36m(pid=143797)[0m v_max: 12.89870698649076
[2m[36m(pid=143797)[0m -----------------------
[2m[36m(pid=143797)[0m 
[2m[36m(pid=143797)[0m -----------------------
[2m[36m(pid=143797)[0m ring length: 518
[2m[36m(pid=143797)[0m v_max: 13.22419073821961
[2m[36m(pid=143797)[0m -----------------------
Result for PPO_WaveAttenuationPOEnv-v0_0:
  custom_metrics: {}
  date: 2020-03-24_15-06-29
  done: false
  episode_len_mean: 2000.0
  episode_reward_max: 3874.991846196366
  episode_reward_mean: 2780.5844395127083
  episode_reward_min: 1045.712244908356
  episodes_this_iter: 5
  episodes_total: 150
  experiment_id: 3169a4f824ed4a02b4b42d55753086c5
  hostname: p0056.ten.osc.edu
  info:
    grad_time_ms: 217.433
    learner:
      default_policy:
        cur_kl_coeff: 3.7252903539730653e-10
        cur_lr: 4.999999873689376e-05
        entropy: 0.5506674647331238
        entropy_coeff: 0.0
        kl: 0.0038337355945259333
        policy_loss: -0.000866894144564867
        total_loss: 2786.472900390625
        vf_explained_var: 3.463029861450195e-05
        vf_loss: 2786.473876953125
    load_time_ms: 2.068
    num_steps_sampled: 300000
    num_steps_trained: 300000
    sample_time_ms: 60776.875
    update_time_ms: 2.069
  iterations_since_restore: 30
  node_ip: 10.4.1.55
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 2.780459770114942
    ram_util_percent: 6.0
  pid: 143796
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 3.8609844048034643
    mean_inference_ms: 0.5320253570644595
    mean_processing_ms: 1.6817618775206211
  time_since_restore: 1836.655499458313
  time_this_iter_s: 60.763153314590454
  time_total_s: 1836.655499458313
  timestamp: 1585076789
  timesteps_since_restore: 300000
  timesteps_this_iter: 10000
  timesteps_total: 300000
  training_iteration: 30
  trial_id: 44d516d6
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2/2 CPUs, 0/0 GPUs
Memory usage on this node: 12.1/201.2 GB
Result logdir: /users/PYS1027/chnrhughes/ray_results/simple_training_example_ring_v1
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - PPO_WaveAttenuationPOEnv-v0_0:	RUNNING, [2 CPUs, 0 GPUs], [pid=143796], 1836 s, 30 iter, 300000 ts, 2.78e+03 rew

[2m[36m(pid=143796)[0m 2020-03-24 15:06:29,291	WARNING ppo.py:121 -- The magnitude of your environment rewards are more than 278.0x the scale of `vf_clip_param`. This means that it will take more than 278.0 iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.
[2m[36m(pid=143797)[0m 
[2m[36m(pid=143797)[0m -----------------------
[2m[36m(pid=143797)[0m ring length: 494
[2m[36m(pid=143797)[0m v_max: 12.34943486433356
[2m[36m(pid=143797)[0m -----------------------
[2m[36m(pid=143797)[0m 
[2m[36m(pid=143797)[0m -----------------------
[2m[36m(pid=143797)[0m ring length: 515
[2m[36m(pid=143797)[0m v_max: 13.116050918675148
[2m[36m(pid=143797)[0m -----------------------
[2m[36m(pid=143797)[0m 
[2m[36m(pid=143797)[0m -----------------------
[2m[36m(pid=143797)[0m ring length: 499
[2m[36m(pid=143797)[0m v_max: 12.533432536501882
[2m[36m(pid=143797)[0m -----------------------
[2m[36m(pid=143797)[0m 
[2m[36m(pid=143797)[0m -----------------------
[2m[36m(pid=143797)[0m ring length: 519
[2m[36m(pid=143797)[0m v_max: 13.260156955398273
[2m[36m(pid=143797)[0m -----------------------
[2m[36m(pid=143797)[0m 
[2m[36m(pid=143797)[0m -----------------------
[2m[36m(pid=143797)[0m ring length: 497
[2m[36m(pid=143797)[0m v_max: 12.45993945925872
[2m[36m(pid=143797)[0m -----------------------
Result for PPO_WaveAttenuationPOEnv-v0_0:
  custom_metrics: {}
  date: 2020-03-24_15-07-29
  done: false
  episode_len_mean: 2000.0
  episode_reward_max: 3874.991846196366
  episode_reward_mean: 2893.9833010739403
  episode_reward_min: 1495.4889628231135
  episodes_this_iter: 5
  episodes_total: 155
  experiment_id: 3169a4f824ed4a02b4b42d55753086c5
  hostname: p0056.ten.osc.edu
  info:
    grad_time_ms: 216.974
    learner:
      default_policy:
        cur_kl_coeff: 1.8626451769865326e-10
        cur_lr: 4.999999873689376e-05
        entropy: 0.533161997795105
        entropy_coeff: 0.0
        kl: 0.0013429111568257213
        policy_loss: -0.0016334077809005976
        total_loss: 2661.7958984375
        vf_explained_var: 4.279613494873047e-05
        vf_loss: 2661.797607421875
    load_time_ms: 2.067
    num_steps_sampled: 310000
    num_steps_trained: 310000
    sample_time_ms: 60716.857
    update_time_ms: 2.066
  iterations_since_restore: 31
  node_ip: 10.4.1.55
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 2.6790697674418604
    ram_util_percent: 6.0
  pid: 143796
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 3.860328983461203
    mean_inference_ms: 0.5318847658755722
    mean_processing_ms: 1.681675837134506
  time_since_restore: 1897.0993201732635
  time_this_iter_s: 60.44382071495056
  time_total_s: 1897.0993201732635
  timestamp: 1585076849
  timesteps_since_restore: 310000
  timesteps_this_iter: 10000
  timesteps_total: 310000
  training_iteration: 31
  trial_id: 44d516d6
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2/2 CPUs, 0/0 GPUs
Memory usage on this node: 12.1/201.2 GB
Result logdir: /users/PYS1027/chnrhughes/ray_results/simple_training_example_ring_v1
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - PPO_WaveAttenuationPOEnv-v0_0:	RUNNING, [2 CPUs, 0 GPUs], [pid=143796], 1897 s, 31 iter, 310000 ts, 2.89e+03 rew

[2m[36m(pid=143796)[0m 2020-03-24 15:07:29,754	WARNING ppo.py:121 -- The magnitude of your environment rewards are more than 289.0x the scale of `vf_clip_param`. This means that it will take more than 289.0 iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.
[2m[36m(pid=143797)[0m 
[2m[36m(pid=143797)[0m -----------------------
[2m[36m(pid=143797)[0m ring length: 517
[2m[36m(pid=143797)[0m v_max: 13.188184171646189
[2m[36m(pid=143797)[0m -----------------------
[2m[36m(pid=143797)[0m 
[2m[36m(pid=143797)[0m -----------------------
[2m[36m(pid=143797)[0m ring length: 490
[2m[36m(pid=143797)[0m v_max: 12.201610748825663
[2m[36m(pid=143797)[0m -----------------------
[2m[36m(pid=143797)[0m 
[2m[36m(pid=143797)[0m -----------------------
[2m[36m(pid=143797)[0m ring length: 511
[2m[36m(pid=143797)[0m v_max: 12.97131045565535
[2m[36m(pid=143797)[0m -----------------------
[2m[36m(pid=143797)[0m 
[2m[36m(pid=143797)[0m -----------------------
[2m[36m(pid=143797)[0m ring length: 506
[2m[36m(pid=143797)[0m v_max: 12.789515517436104
[2m[36m(pid=143797)[0m -----------------------
[2m[36m(pid=143797)[0m 
[2m[36m(pid=143797)[0m -----------------------
[2m[36m(pid=143797)[0m ring length: 499
[2m[36m(pid=143797)[0m v_max: 12.533432536501882
[2m[36m(pid=143797)[0m -----------------------
Result for PPO_WaveAttenuationPOEnv-v0_0:
  custom_metrics: {}
  date: 2020-03-24_15-08-30
  done: false
  episode_len_mean: 2000.0
  episode_reward_max: 3874.991846196366
  episode_reward_mean: 2984.012347131147
  episode_reward_min: 1887.2217992360993
  episodes_this_iter: 5
  episodes_total: 160
  experiment_id: 3169a4f824ed4a02b4b42d55753086c5
  hostname: p0056.ten.osc.edu
  info:
    grad_time_ms: 217.564
    learner:
      default_policy:
        cur_kl_coeff: 9.313225884932663e-11
        cur_lr: 4.999999873689376e-05
        entropy: 0.5244960188865662
        entropy_coeff: 0.0
        kl: 0.0034147845581173897
        policy_loss: -0.0006767906015738845
        total_loss: 2545.14794921875
        vf_explained_var: 3.224611282348633e-05
        vf_loss: 2545.148681640625
    load_time_ms: 2.065
    num_steps_sampled: 320000
    num_steps_trained: 320000
    sample_time_ms: 60696.042
    update_time_ms: 2.071
  iterations_since_restore: 32
  node_ip: 10.4.1.55
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 2.7816091954022992
    ram_util_percent: 6.0
  pid: 143796
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 3.8597711270100192
    mean_inference_ms: 0.531791239803874
    mean_processing_ms: 1.6816257348078472
  time_since_restore: 1957.8247919082642
  time_this_iter_s: 60.72547173500061
  time_total_s: 1957.8247919082642
  timestamp: 1585076910
  timesteps_since_restore: 320000
  timesteps_this_iter: 10000
  timesteps_total: 320000
  training_iteration: 32
  trial_id: 44d516d6
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2/2 CPUs, 0/0 GPUs
Memory usage on this node: 12.1/201.2 GB
Result logdir: /users/PYS1027/chnrhughes/ray_results/simple_training_example_ring_v1
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - PPO_WaveAttenuationPOEnv-v0_0:	RUNNING, [2 CPUs, 0 GPUs], [pid=143796], 1957 s, 32 iter, 320000 ts, 2.98e+03 rew

[2m[36m(pid=143796)[0m 2020-03-24 15:08:30,489	WARNING ppo.py:121 -- The magnitude of your environment rewards are more than 298.0x the scale of `vf_clip_param`. This means that it will take more than 298.0 iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.
[2m[36m(pid=143797)[0m 
[2m[36m(pid=143797)[0m -----------------------
[2m[36m(pid=143797)[0m ring length: 517
[2m[36m(pid=143797)[0m v_max: 13.188184171646189
[2m[36m(pid=143797)[0m -----------------------
[2m[36m(pid=143797)[0m 
[2m[36m(pid=143797)[0m -----------------------
[2m[36m(pid=143797)[0m ring length: 494
[2m[36m(pid=143797)[0m v_max: 12.34943486433356
[2m[36m(pid=143797)[0m -----------------------
[2m[36m(pid=143797)[0m 
[2m[36m(pid=143797)[0m -----------------------
[2m[36m(pid=143797)[0m ring length: 519
[2m[36m(pid=143797)[0m v_max: 13.260156955398273
[2m[36m(pid=143797)[0m -----------------------
[2m[36m(pid=143797)[0m 
[2m[36m(pid=143797)[0m -----------------------
[2m[36m(pid=143797)[0m ring length: 499
[2m[36m(pid=143797)[0m v_max: 12.533432536501882
[2m[36m(pid=143797)[0m -----------------------
[2m[36m(pid=143797)[0m 
[2m[36m(pid=143797)[0m -----------------------
[2m[36m(pid=143797)[0m ring length: 491
[2m[36m(pid=143797)[0m v_max: 12.238617992673053
[2m[36m(pid=143797)[0m -----------------------
Result for PPO_WaveAttenuationPOEnv-v0_0:
  custom_metrics: {}
  date: 2020-03-24_15-09-30
  done: false
  episode_len_mean: 2000.0
  episode_reward_max: 3874.991846196366
  episode_reward_mean: 3048.2795084172726
  episode_reward_min: 1918.258317507373
  episodes_this_iter: 5
  episodes_total: 165
  experiment_id: 3169a4f824ed4a02b4b42d55753086c5
  hostname: p0056.ten.osc.edu
  info:
    grad_time_ms: 217.575
    learner:
      default_policy:
        cur_kl_coeff: 4.6566129424663316e-11
        cur_lr: 4.999999873689376e-05
        entropy: 0.5185378193855286
        entropy_coeff: 0.0
        kl: 0.007733718957751989
        policy_loss: -0.0018104652408510447
        total_loss: 2189.994140625
        vf_explained_var: 0.00027686357498168945
        vf_loss: 2189.99609375
    load_time_ms: 2.125
    num_steps_sampled: 330000
    num_steps_trained: 330000
    sample_time_ms: 60651.787
    update_time_ms: 2.169
  iterations_since_restore: 33
  node_ip: 10.4.1.55
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 2.6965116279069763
    ram_util_percent: 6.0
  pid: 143796
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 3.8592664571438164
    mean_inference_ms: 0.5316437952200114
    mean_processing_ms: 1.6815902457801377
  time_since_restore: 2018.2420191764832
  time_this_iter_s: 60.417227268218994
  time_total_s: 2018.2420191764832
  timestamp: 1585076970
  timesteps_since_restore: 330000
  timesteps_this_iter: 10000
  timesteps_total: 330000
  training_iteration: 33
  trial_id: 44d516d6
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2/2 CPUs, 0/0 GPUs
Memory usage on this node: 12.1/201.2 GB
Result logdir: /users/PYS1027/chnrhughes/ray_results/simple_training_example_ring_v1
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - PPO_WaveAttenuationPOEnv-v0_0:	RUNNING, [2 CPUs, 0 GPUs], [pid=143796], 2018 s, 33 iter, 330000 ts, 3.05e+03 rew

[2m[36m(pid=143796)[0m 2020-03-24 15:09:30,915	WARNING ppo.py:121 -- The magnitude of your environment rewards are more than 305.0x the scale of `vf_clip_param`. This means that it will take more than 305.0 iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.
[2m[36m(pid=143797)[0m 
[2m[36m(pid=143797)[0m -----------------------
[2m[36m(pid=143797)[0m ring length: 495
[2m[36m(pid=143797)[0m v_max: 12.386304743340318
[2m[36m(pid=143797)[0m -----------------------
[2m[36m(pid=143797)[0m 
[2m[36m(pid=143797)[0m -----------------------
[2m[36m(pid=143797)[0m ring length: 504
[2m[36m(pid=143797)[0m v_max: 12.716533109302146
[2m[36m(pid=143797)[0m -----------------------
[2m[36m(pid=143797)[0m 
[2m[36m(pid=143797)[0m -----------------------
[2m[36m(pid=143797)[0m ring length: 501
[2m[36m(pid=143797)[0m v_max: 12.606782077081403
[2m[36m(pid=143797)[0m -----------------------
[2m[36m(pid=143797)[0m 
[2m[36m(pid=143797)[0m -----------------------
[2m[36m(pid=143797)[0m ring length: 515
[2m[36m(pid=143797)[0m v_max: 13.116050918675148
[2m[36m(pid=143797)[0m -----------------------
[2m[36m(pid=143797)[0m 
[2m[36m(pid=143797)[0m -----------------------
[2m[36m(pid=143797)[0m ring length: 517
[2m[36m(pid=143797)[0m v_max: 13.188184171646189
[2m[36m(pid=143797)[0m -----------------------
Result for PPO_WaveAttenuationPOEnv-v0_0:
  custom_metrics: {}
  date: 2020-03-24_15-10-32
  done: false
  episode_len_mean: 2000.0
  episode_reward_max: 3943.369443809236
  episode_reward_mean: 3113.0467037752824
  episode_reward_min: 1918.258317507373
  episodes_this_iter: 5
  episodes_total: 170
  experiment_id: 3169a4f824ed4a02b4b42d55753086c5
  hostname: p0056.ten.osc.edu
  info:
    grad_time_ms: 216.875
    learner:
      default_policy:
        cur_kl_coeff: 2.3283064712331658e-11
        cur_lr: 4.999999873689376e-05
        entropy: 0.5041742324829102
        entropy_coeff: 0.0
        kl: 0.004295493476092815
        policy_loss: -0.0008868884760886431
        total_loss: 2708.43603515625
        vf_explained_var: 2.968311309814453e-05
        vf_loss: 2708.436767578125
    load_time_ms: 2.128
    num_steps_sampled: 340000
    num_steps_trained: 340000
    sample_time_ms: 60684.605
    update_time_ms: 2.2
  iterations_since_restore: 34
  node_ip: 10.4.1.55
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 2.705747126436781
    ram_util_percent: 6.0
  pid: 143796
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 3.858811826178826
    mean_inference_ms: 0.5315415534068139
    mean_processing_ms: 1.6815569916502133
  time_since_restore: 2079.555609703064
  time_this_iter_s: 61.31359052658081
  time_total_s: 2079.555609703064
  timestamp: 1585077032
  timesteps_since_restore: 340000
  timesteps_this_iter: 10000
  timesteps_total: 340000
  training_iteration: 34
  trial_id: 44d516d6
  
[2m[36m(pid=143796)[0m 2020-03-24 15:10:32,239	WARNING ppo.py:121 -- The magnitude of your environment rewards are more than 311.0x the scale of `vf_clip_param`. This means that it will take more than 311.0 iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2/2 CPUs, 0/0 GPUs
Memory usage on this node: 12.1/201.2 GB
Result logdir: /users/PYS1027/chnrhughes/ray_results/simple_training_example_ring_v1
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - PPO_WaveAttenuationPOEnv-v0_0:	RUNNING, [2 CPUs, 0 GPUs], [pid=143796], 2079 s, 34 iter, 340000 ts, 3.11e+03 rew

[2m[36m(pid=143797)[0m 
[2m[36m(pid=143797)[0m -----------------------
[2m[36m(pid=143797)[0m ring length: 516
[2m[36m(pid=143797)[0m v_max: 13.152137487657606
[2m[36m(pid=143797)[0m -----------------------
[2m[36m(pid=143797)[0m 
[2m[36m(pid=143797)[0m -----------------------
[2m[36m(pid=143797)[0m ring length: 505
[2m[36m(pid=143797)[0m v_max: 12.753042965621004
[2m[36m(pid=143797)[0m -----------------------
[2m[36m(pid=143797)[0m 
[2m[36m(pid=143797)[0m -----------------------
[2m[36m(pid=143797)[0m ring length: 503
[2m[36m(pid=143797)[0m v_max: 12.679986184756686
[2m[36m(pid=143797)[0m -----------------------
[2m[36m(pid=143797)[0m 
[2m[36m(pid=143797)[0m -----------------------
[2m[36m(pid=143797)[0m ring length: 504
[2m[36m(pid=143797)[0m v_max: 12.716533109302146
[2m[36m(pid=143797)[0m -----------------------
[2m[36m(pid=143797)[0m 
[2m[36m(pid=143797)[0m -----------------------
[2m[36m(pid=143797)[0m ring length: 518
[2m[36m(pid=143797)[0m v_max: 13.22419073821961
[2m[36m(pid=143797)[0m -----------------------
Result for PPO_WaveAttenuationPOEnv-v0_0:
  custom_metrics: {}
  date: 2020-03-24_15-11-33
  done: false
  episode_len_mean: 2000.0
  episode_reward_max: 3943.369443809236
  episode_reward_mean: 3171.49708786835
  episode_reward_min: 1918.258317507373
  episodes_this_iter: 5
  episodes_total: 175
  experiment_id: 3169a4f824ed4a02b4b42d55753086c5
  hostname: p0056.ten.osc.edu
  info:
    grad_time_ms: 215.672
    learner:
      default_policy:
        cur_kl_coeff: 1.1641532356165829e-11
        cur_lr: 4.999999873689376e-05
        entropy: 0.4893883764743805
        entropy_coeff: 0.0
        kl: 0.009630190208554268
        policy_loss: -0.0032510405872017145
        total_loss: 2597.43896484375
        vf_explained_var: 9.971857070922852e-05
        vf_loss: 2597.4423828125
    load_time_ms: 2.086
    num_steps_sampled: 350000
    num_steps_trained: 350000
    sample_time_ms: 60721.164
    update_time_ms: 2.171
  iterations_since_restore: 35
  node_ip: 10.4.1.55
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 2.6862068965517243
    ram_util_percent: 6.0
  pid: 143796
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 3.8583950267203035
    mean_inference_ms: 0.5314788448232314
    mean_processing_ms: 1.6815405454791659
  time_since_restore: 2140.750823736191
  time_this_iter_s: 61.19521403312683
  time_total_s: 2140.750823736191
  timestamp: 1585077093
  timesteps_since_restore: 350000
  timesteps_this_iter: 10000
  timesteps_total: 350000
  training_iteration: 35
  trial_id: 44d516d6
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2/2 CPUs, 0/0 GPUs
Memory usage on this node: 12.1/201.2 GB
Result logdir: /users/PYS1027/chnrhughes/ray_results/simple_training_example_ring_v1
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - PPO_WaveAttenuationPOEnv-v0_0:	RUNNING, [2 CPUs, 0 GPUs], [pid=143796], 2140 s, 35 iter, 350000 ts, 3.17e+03 rew

[2m[36m(pid=143796)[0m 2020-03-24 15:11:33,443	WARNING ppo.py:121 -- The magnitude of your environment rewards are more than 317.0x the scale of `vf_clip_param`. This means that it will take more than 317.0 iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.
[2m[36m(pid=143797)[0m 
[2m[36m(pid=143797)[0m -----------------------
[2m[36m(pid=143797)[0m ring length: 516
[2m[36m(pid=143797)[0m v_max: 13.152137487657606
[2m[36m(pid=143797)[0m -----------------------
[2m[36m(pid=143797)[0m 
[2m[36m(pid=143797)[0m -----------------------
[2m[36m(pid=143797)[0m ring length: 504
[2m[36m(pid=143797)[0m v_max: 12.716533109302146
[2m[36m(pid=143797)[0m -----------------------
[2m[36m(pid=143797)[0m 
[2m[36m(pid=143797)[0m -----------------------
[2m[36m(pid=143797)[0m ring length: 500
[2m[36m(pid=143797)[0m v_max: 12.570125367437457
[2m[36m(pid=143797)[0m -----------------------
[2m[36m(pid=143797)[0m 
[2m[36m(pid=143797)[0m -----------------------
[2m[36m(pid=143797)[0m ring length: 520
[2m[36m(pid=143797)[0m v_max: 13.296082591662728
[2m[36m(pid=143797)[0m -----------------------
[2m[36m(pid=143797)[0m 
[2m[36m(pid=143797)[0m -----------------------
[2m[36m(pid=143797)[0m ring length: 508
[2m[36m(pid=143797)[0m v_max: 12.862347763562411
[2m[36m(pid=143797)[0m -----------------------
Result for PPO_WaveAttenuationPOEnv-v0_0:
  custom_metrics: {}
  date: 2020-03-24_15-12-34
  done: false
  episode_len_mean: 2000.0
  episode_reward_max: 3943.369443809236
  episode_reward_mean: 3190.7811364266295
  episode_reward_min: 1918.258317507373
  episodes_this_iter: 5
  episodes_total: 180
  experiment_id: 3169a4f824ed4a02b4b42d55753086c5
  hostname: p0056.ten.osc.edu
  info:
    grad_time_ms: 214.47
    learner:
      default_policy:
        cur_kl_coeff: 5.8207661780829145e-12
        cur_lr: 4.999999873689376e-05
        entropy: 0.47696924209594727
        entropy_coeff: 0.0
        kl: 0.0018599879695102572
        policy_loss: -0.0016182452673092484
        total_loss: 1886.527587890625
        vf_explained_var: 0.0007266998291015625
        vf_loss: 1886.528564453125
    load_time_ms: 2.083
    num_steps_sampled: 360000
    num_steps_trained: 360000
    sample_time_ms: 60680.675
    update_time_ms: 2.175
  iterations_since_restore: 36
  node_ip: 10.4.1.55
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 2.785057471264368
    ram_util_percent: 6.0
  pid: 143796
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 3.8580016980353253
    mean_inference_ms: 0.5315173457156857
    mean_processing_ms: 1.681499631383791
  time_since_restore: 2201.5409450531006
  time_this_iter_s: 60.79012131690979
  time_total_s: 2201.5409450531006
  timestamp: 1585077154
  timesteps_since_restore: 360000
  timesteps_this_iter: 10000
  timesteps_total: 360000
  training_iteration: 36
  trial_id: 44d516d6
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2/2 CPUs, 0/0 GPUs
Memory usage on this node: 12.1/201.2 GB
Result logdir: /users/PYS1027/chnrhughes/ray_results/simple_training_example_ring_v1
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - PPO_WaveAttenuationPOEnv-v0_0:	RUNNING, [2 CPUs, 0 GPUs], [pid=143796], 2201 s, 36 iter, 360000 ts, 3.19e+03 rew

[2m[36m(pid=143796)[0m 2020-03-24 15:12:34,252	WARNING ppo.py:121 -- The magnitude of your environment rewards are more than 319.0x the scale of `vf_clip_param`. This means that it will take more than 319.0 iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.
[2m[36m(pid=143797)[0m 
[2m[36m(pid=143797)[0m -----------------------
[2m[36m(pid=143797)[0m ring length: 502
[2m[36m(pid=143797)[0m v_max: 12.64340242846283
[2m[36m(pid=143797)[0m -----------------------
[2m[36m(pid=143797)[0m 
[2m[36m(pid=143797)[0m -----------------------
[2m[36m(pid=143797)[0m ring length: 507
[2m[36m(pid=143797)[0m v_max: 12.825950528689797
[2m[36m(pid=143797)[0m -----------------------
[2m[36m(pid=143797)[0m 
[2m[36m(pid=143797)[0m -----------------------
[2m[36m(pid=143797)[0m ring length: 502
[2m[36m(pid=143797)[0m v_max: 12.64340242846283
[2m[36m(pid=143797)[0m -----------------------
[2m[36m(pid=143797)[0m 
[2m[36m(pid=143797)[0m -----------------------
[2m[36m(pid=143797)[0m ring length: 516
[2m[36m(pid=143797)[0m v_max: 13.152137487657606
[2m[36m(pid=143797)[0m -----------------------
[2m[36m(pid=143797)[0m 
[2m[36m(pid=143797)[0m -----------------------
[2m[36m(pid=143797)[0m ring length: 511
[2m[36m(pid=143797)[0m v_max: 12.97131045565535
[2m[36m(pid=143797)[0m -----------------------
Result for PPO_WaveAttenuationPOEnv-v0_0:
  custom_metrics: {}
  date: 2020-03-24_15-13-35
  done: false
  episode_len_mean: 2000.0
  episode_reward_max: 3943.369443809236
  episode_reward_mean: 3213.8897732678943
  episode_reward_min: 1918.258317507373
  episodes_this_iter: 5
  episodes_total: 185
  experiment_id: 3169a4f824ed4a02b4b42d55753086c5
  hostname: p0056.ten.osc.edu
  info:
    grad_time_ms: 214.284
    learner:
      default_policy:
        cur_kl_coeff: 2.9103830890414573e-12
        cur_lr: 4.999999873689376e-05
        entropy: 0.45661112666130066
        entropy_coeff: 0.0
        kl: 0.0022843503393232822
        policy_loss: -0.0015702274395152926
        total_loss: 2045.1888427734375
        vf_explained_var: 0.0004845261573791504
        vf_loss: 2045.1904296875
    load_time_ms: 2.082
    num_steps_sampled: 370000
    num_steps_trained: 370000
    sample_time_ms: 60656.396
    update_time_ms: 2.179
  iterations_since_restore: 37
  node_ip: 10.4.1.55
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 2.689655172413793
    ram_util_percent: 6.0
  pid: 143796
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 3.8575944972870735
    mean_inference_ms: 0.5315665895184079
    mean_processing_ms: 1.6814698602936289
  time_since_restore: 2262.612539768219
  time_this_iter_s: 61.07159471511841
  time_total_s: 2262.612539768219
  timestamp: 1585077215
  timesteps_since_restore: 370000
  timesteps_this_iter: 10000
  timesteps_total: 370000
  training_iteration: 37
  trial_id: 44d516d6
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2/2 CPUs, 0/0 GPUs
Memory usage on this node: 12.1/201.2 GB
Result logdir: /users/PYS1027/chnrhughes/ray_results/simple_training_example_ring_v1
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - PPO_WaveAttenuationPOEnv-v0_0:	RUNNING, [2 CPUs, 0 GPUs], [pid=143796], 2262 s, 37 iter, 370000 ts, 3.21e+03 rew

[2m[36m(pid=143796)[0m 2020-03-24 15:13:35,332	WARNING ppo.py:121 -- The magnitude of your environment rewards are more than 321.0x the scale of `vf_clip_param`. This means that it will take more than 321.0 iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.
[2m[36m(pid=143797)[0m 
[2m[36m(pid=143797)[0m -----------------------
[2m[36m(pid=143797)[0m ring length: 497
[2m[36m(pid=143797)[0m v_max: 12.45993945925872
[2m[36m(pid=143797)[0m -----------------------
[2m[36m(pid=143797)[0m 
[2m[36m(pid=143797)[0m -----------------------
[2m[36m(pid=143797)[0m ring length: 503
[2m[36m(pid=143797)[0m v_max: 12.679986184756686
[2m[36m(pid=143797)[0m -----------------------
[2m[36m(pid=143797)[0m 
[2m[36m(pid=143797)[0m -----------------------
[2m[36m(pid=143797)[0m ring length: 496
[2m[36m(pid=143797)[0m v_max: 12.423139687457347
[2m[36m(pid=143797)[0m -----------------------
[2m[36m(pid=143797)[0m 
[2m[36m(pid=143797)[0m -----------------------
[2m[36m(pid=143797)[0m ring length: 494
[2m[36m(pid=143797)[0m v_max: 12.34943486433356
[2m[36m(pid=143797)[0m -----------------------
[2m[36m(pid=143797)[0m 
[2m[36m(pid=143797)[0m -----------------------
[2m[36m(pid=143797)[0m ring length: 495
[2m[36m(pid=143797)[0m v_max: 12.386304743340318
[2m[36m(pid=143797)[0m -----------------------
Result for PPO_WaveAttenuationPOEnv-v0_0:
  custom_metrics: {}
  date: 2020-03-24_15-14-36
  done: false
  episode_len_mean: 2000.0
  episode_reward_max: 3943.369443809236
  episode_reward_mean: 3238.5996220474767
  episode_reward_min: 1918.258317507373
  episodes_this_iter: 5
  episodes_total: 190
  experiment_id: 3169a4f824ed4a02b4b42d55753086c5
  hostname: p0056.ten.osc.edu
  info:
    grad_time_ms: 216.099
    learner:
      default_policy:
        cur_kl_coeff: 1.4551915445207286e-12
        cur_lr: 4.999999873689376e-05
        entropy: 0.4421674907207489
        entropy_coeff: 0.0
        kl: 0.00591239845380187
        policy_loss: -0.0016399932792410254
        total_loss: 2239.752197265625
        vf_explained_var: 0.00023537874221801758
        vf_loss: 2239.754150390625
    load_time_ms: 2.045
    num_steps_sampled: 380000
    num_steps_trained: 380000
    sample_time_ms: 60600.218
    update_time_ms: 2.165
  iterations_since_restore: 38
  node_ip: 10.4.1.55
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 2.6883720930232555
    ram_util_percent: 6.0
  pid: 143796
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 3.856967535064176
    mean_inference_ms: 0.5316476165215175
    mean_processing_ms: 1.6814372370763244
  time_since_restore: 2323.339640378952
  time_this_iter_s: 60.72710061073303
  time_total_s: 2323.339640378952
  timestamp: 1585077276
  timesteps_since_restore: 380000
  timesteps_this_iter: 10000
  timesteps_total: 380000
  training_iteration: 38
  trial_id: 44d516d6
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2/2 CPUs, 0/0 GPUs
Memory usage on this node: 12.1/201.2 GB
Result logdir: /users/PYS1027/chnrhughes/ray_results/simple_training_example_ring_v1
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - PPO_WaveAttenuationPOEnv-v0_0:	RUNNING, [2 CPUs, 0 GPUs], [pid=143796], 2323 s, 38 iter, 380000 ts, 3.24e+03 rew

[2m[36m(pid=143796)[0m 2020-03-24 15:14:36,070	WARNING ppo.py:121 -- The magnitude of your environment rewards are more than 324.0x the scale of `vf_clip_param`. This means that it will take more than 324.0 iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.
[2m[36m(pid=143797)[0m 
[2m[36m(pid=143797)[0m -----------------------
[2m[36m(pid=143797)[0m ring length: 511
[2m[36m(pid=143797)[0m v_max: 12.97131045565535
[2m[36m(pid=143797)[0m -----------------------
[2m[36m(pid=143797)[0m 
[2m[36m(pid=143797)[0m -----------------------
[2m[36m(pid=143797)[0m ring length: 512
[2m[36m(pid=143797)[0m v_max: 13.007554232214234
[2m[36m(pid=143797)[0m -----------------------
[2m[36m(pid=143797)[0m 
[2m[36m(pid=143797)[0m -----------------------
[2m[36m(pid=143797)[0m ring length: 516
[2m[36m(pid=143797)[0m v_max: 13.152137487657606
[2m[36m(pid=143797)[0m -----------------------
[2m[36m(pid=143797)[0m 
[2m[36m(pid=143797)[0m -----------------------
[2m[36m(pid=143797)[0m ring length: 492
[2m[36m(pid=143797)[0m v_max: 12.275591251518899
[2m[36m(pid=143797)[0m -----------------------
[2m[36m(pid=143797)[0m 
[2m[36m(pid=143797)[0m -----------------------
[2m[36m(pid=143797)[0m ring length: 502
[2m[36m(pid=143797)[0m v_max: 12.64340242846283
[2m[36m(pid=143797)[0m -----------------------
Result for PPO_WaveAttenuationPOEnv-v0_0:
  custom_metrics: {}
  date: 2020-03-24_15-15-36
  done: false
  episode_len_mean: 2000.0
  episode_reward_max: 3943.369443809236
  episode_reward_mean: 3262.899752051229
  episode_reward_min: 2017.8823114684565
  episodes_this_iter: 5
  episodes_total: 195
  experiment_id: 3169a4f824ed4a02b4b42d55753086c5
  hostname: p0056.ten.osc.edu
  info:
    grad_time_ms: 218.94
    learner:
      default_policy:
        cur_kl_coeff: 7.275957722603643e-13
        cur_lr: 4.999999873689376e-05
        entropy: 0.4291764795780182
        entropy_coeff: 0.0
        kl: 0.0030168520752340555
        policy_loss: -0.0020348504185676575
        total_loss: 1813.7437744140625
        vf_explained_var: 0.0008009076118469238
        vf_loss: 1813.745849609375
    load_time_ms: 2.032
    num_steps_sampled: 390000
    num_steps_trained: 390000
    sample_time_ms: 60538.23
    update_time_ms: 2.173
  iterations_since_restore: 39
  node_ip: 10.4.1.55
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 2.684883720930233
    ram_util_percent: 6.0
  pid: 143796
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 3.8563884625395257
    mean_inference_ms: 0.5317130377779258
    mean_processing_ms: 1.681405213731065
  time_since_restore: 2383.5671303272247
  time_this_iter_s: 60.227489948272705
  time_total_s: 2383.5671303272247
  timestamp: 1585077336
  timesteps_since_restore: 390000
  timesteps_this_iter: 10000
  timesteps_total: 390000
  training_iteration: 39
  trial_id: 44d516d6
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2/2 CPUs, 0/0 GPUs
Memory usage on this node: 12.1/201.2 GB
Result logdir: /users/PYS1027/chnrhughes/ray_results/simple_training_example_ring_v1
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - PPO_WaveAttenuationPOEnv-v0_0:	RUNNING, [2 CPUs, 0 GPUs], [pid=143796], 2383 s, 39 iter, 390000 ts, 3.26e+03 rew

[2m[36m(pid=143796)[0m 2020-03-24 15:15:36,306	WARNING ppo.py:121 -- The magnitude of your environment rewards are more than 326.0x the scale of `vf_clip_param`. This means that it will take more than 326.0 iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.
[2m[36m(pid=143797)[0m 
[2m[36m(pid=143797)[0m -----------------------
[2m[36m(pid=143797)[0m ring length: 509
[2m[36m(pid=143797)[0m v_max: 12.89870698649076
[2m[36m(pid=143797)[0m -----------------------
[2m[36m(pid=143797)[0m 
[2m[36m(pid=143797)[0m -----------------------
[2m[36m(pid=143797)[0m ring length: 515
[2m[36m(pid=143797)[0m v_max: 13.116050918675148
[2m[36m(pid=143797)[0m -----------------------
[2m[36m(pid=143797)[0m 
[2m[36m(pid=143797)[0m -----------------------
[2m[36m(pid=143797)[0m ring length: 517
[2m[36m(pid=143797)[0m v_max: 13.188184171646189
[2m[36m(pid=143797)[0m -----------------------
[2m[36m(pid=143797)[0m 
[2m[36m(pid=143797)[0m -----------------------
[2m[36m(pid=143797)[0m ring length: 493
[2m[36m(pid=143797)[0m v_max: 12.31253028789948
[2m[36m(pid=143797)[0m -----------------------
[2m[36m(pid=143797)[0m 
[2m[36m(pid=143797)[0m -----------------------
[2m[36m(pid=143797)[0m ring length: 513
[2m[36m(pid=143797)[0m v_max: 13.043759057511211
[2m[36m(pid=143797)[0m -----------------------
Result for PPO_WaveAttenuationPOEnv-v0_0:
  custom_metrics: {}
  date: 2020-03-24_15-16-36
  done: false
  episode_len_mean: 2000.0
  episode_reward_max: 3943.369443809236
  episode_reward_mean: 3249.3532634226653
  episode_reward_min: 2017.8823114684565
  episodes_this_iter: 5
  episodes_total: 200
  experiment_id: 3169a4f824ed4a02b4b42d55753086c5
  hostname: p0056.ten.osc.edu
  info:
    grad_time_ms: 219.853
    learner:
      default_policy:
        cur_kl_coeff: 3.6379788613018216e-13
        cur_lr: 4.999999873689376e-05
        entropy: 0.42184510827064514
        entropy_coeff: 0.0
        kl: 0.0097389230504632
        policy_loss: -0.002343611791729927
        total_loss: 1614.3397216796875
        vf_explained_var: 0.0014530420303344727
        vf_loss: 1614.3424072265625
    load_time_ms: 2.025
    num_steps_sampled: 400000
    num_steps_trained: 400000
    sample_time_ms: 60431.219
    update_time_ms: 2.144
  iterations_since_restore: 40
  node_ip: 10.4.1.55
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 2.7070588235294117
    ram_util_percent: 6.0
  pid: 143796
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 3.855772512064688
    mean_inference_ms: 0.5316844764134275
    mean_processing_ms: 1.681366076770647
  time_since_restore: 2443.268819093704
  time_this_iter_s: 59.70168876647949
  time_total_s: 2443.268819093704
  timestamp: 1585077396
  timesteps_since_restore: 400000
  timesteps_this_iter: 10000
  timesteps_total: 400000
  training_iteration: 40
  trial_id: 44d516d6
  
[2m[36m(pid=143796)[0m 2020-03-24 15:16:36,017	WARNING ppo.py:121 -- The magnitude of your environment rewards are more than 325.0x the scale of `vf_clip_param`. This means that it will take more than 325.0 iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2/2 CPUs, 0/0 GPUs
Memory usage on this node: 12.1/201.2 GB
Result logdir: /users/PYS1027/chnrhughes/ray_results/simple_training_example_ring_v1
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - PPO_WaveAttenuationPOEnv-v0_0:	RUNNING, [2 CPUs, 0 GPUs], [pid=143796], 2443 s, 40 iter, 400000 ts, 3.25e+03 rew

[2m[36m(pid=143797)[0m 
[2m[36m(pid=143797)[0m -----------------------
[2m[36m(pid=143797)[0m ring length: 500
[2m[36m(pid=143797)[0m v_max: 12.570125367437457
[2m[36m(pid=143797)[0m -----------------------
[2m[36m(pid=143797)[0m 
[2m[36m(pid=143797)[0m -----------------------
[2m[36m(pid=143797)[0m ring length: 518
[2m[36m(pid=143797)[0m v_max: 13.22419073821961
[2m[36m(pid=143797)[0m -----------------------
[2m[36m(pid=143797)[0m 
[2m[36m(pid=143797)[0m -----------------------
[2m[36m(pid=143797)[0m ring length: 503
[2m[36m(pid=143797)[0m v_max: 12.679986184756686
[2m[36m(pid=143797)[0m -----------------------
[2m[36m(pid=143797)[0m 
[2m[36m(pid=143797)[0m -----------------------
[2m[36m(pid=143797)[0m ring length: 500
[2m[36m(pid=143797)[0m v_max: 12.570125367437457
[2m[36m(pid=143797)[0m -----------------------
[2m[36m(pid=143797)[0m 
[2m[36m(pid=143797)[0m -----------------------
[2m[36m(pid=143797)[0m ring length: 515
[2m[36m(pid=143797)[0m v_max: 13.116050918675148
[2m[36m(pid=143797)[0m -----------------------
Result for PPO_WaveAttenuationPOEnv-v0_0:
  custom_metrics: {}
  date: 2020-03-24_15-17-36
  done: false
  episode_len_mean: 2000.0
  episode_reward_max: 3943.369443809236
  episode_reward_mean: 3271.6235822649865
  episode_reward_min: 2017.8823114684565
  episodes_this_iter: 5
  episodes_total: 205
  experiment_id: 3169a4f824ed4a02b4b42d55753086c5
  hostname: p0056.ten.osc.edu
  info:
    grad_time_ms: 221.419
    learner:
      default_policy:
        cur_kl_coeff: 1.8189894306509108e-13
        cur_lr: 4.999999873689376e-05
        entropy: 0.39578181505203247
        entropy_coeff: 0.0
        kl: 0.0017525235889479518
        policy_loss: -0.0010776474373415112
        total_loss: 2412.152099609375
        vf_explained_var: 0.00021851062774658203
        vf_loss: 2412.153564453125
    load_time_ms: 2.023
    num_steps_sampled: 410000
    num_steps_trained: 410000
    sample_time_ms: 60396.426
    update_time_ms: 2.179
  iterations_since_restore: 41
  node_ip: 10.4.1.55
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 2.687209302325581
    ram_util_percent: 6.0
  pid: 143796
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 3.8551581823378966
    mean_inference_ms: 0.5315726180614015
    mean_processing_ms: 1.6813221062356833
  time_since_restore: 2503.3812441825867
  time_this_iter_s: 60.112425088882446
  time_total_s: 2503.3812441825867
  timestamp: 1585077456
  timesteps_since_restore: 410000
  timesteps_this_iter: 10000
  timesteps_total: 410000
  training_iteration: 41
  trial_id: 44d516d6
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2/2 CPUs, 0/0 GPUs
Memory usage on this node: 12.1/201.2 GB
Result logdir: /users/PYS1027/chnrhughes/ray_results/simple_training_example_ring_v1
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - PPO_WaveAttenuationPOEnv-v0_0:	RUNNING, [2 CPUs, 0 GPUs], [pid=143796], 2503 s, 41 iter, 410000 ts, 3.27e+03 rew

[2m[36m(pid=143796)[0m 2020-03-24 15:17:36,167	WARNING ppo.py:121 -- The magnitude of your environment rewards are more than 327.0x the scale of `vf_clip_param`. This means that it will take more than 327.0 iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.
[2m[36m(pid=143797)[0m 
[2m[36m(pid=143797)[0m -----------------------
[2m[36m(pid=143797)[0m ring length: 490
[2m[36m(pid=143797)[0m v_max: 12.201610748825663
[2m[36m(pid=143797)[0m -----------------------
[2m[36m(pid=143797)[0m 
[2m[36m(pid=143797)[0m -----------------------
[2m[36m(pid=143797)[0m ring length: 494
[2m[36m(pid=143797)[0m v_max: 12.34943486433356
[2m[36m(pid=143797)[0m -----------------------
[2m[36m(pid=143797)[0m 
[2m[36m(pid=143797)[0m -----------------------
[2m[36m(pid=143797)[0m ring length: 504
[2m[36m(pid=143797)[0m v_max: 12.716533109302146
[2m[36m(pid=143797)[0m -----------------------
[2m[36m(pid=143797)[0m 
[2m[36m(pid=143797)[0m -----------------------
[2m[36m(pid=143797)[0m ring length: 500
[2m[36m(pid=143797)[0m v_max: 12.570125367437457
[2m[36m(pid=143797)[0m -----------------------
[2m[36m(pid=143797)[0m 
[2m[36m(pid=143797)[0m -----------------------
[2m[36m(pid=143797)[0m ring length: 490
[2m[36m(pid=143797)[0m v_max: 12.201610748825663
[2m[36m(pid=143797)[0m -----------------------
Result for PPO_WaveAttenuationPOEnv-v0_0:
  custom_metrics: {}
  date: 2020-03-24_15-18-36
  done: false
  episode_len_mean: 2000.0
  episode_reward_max: 3943.369443809236
  episode_reward_mean: 3293.3076905689045
  episode_reward_min: 2017.8823114684565
  episodes_this_iter: 5
  episodes_total: 210
  experiment_id: 3169a4f824ed4a02b4b42d55753086c5
  hostname: p0056.ten.osc.edu
  info:
    grad_time_ms: 221.592
    learner:
      default_policy:
        cur_kl_coeff: 9.094947153254554e-14
        cur_lr: 4.999999873689376e-05
        entropy: 0.3840964734554291
        entropy_coeff: 0.0
        kl: 0.0016471717972308397
        policy_loss: -0.0004887565737590194
        total_loss: 2358.074462890625
        vf_explained_var: 0.00016289949417114258
        vf_loss: 2358.075439453125
    load_time_ms: 2.02
    num_steps_sampled: 420000
    num_steps_trained: 420000
    sample_time_ms: 60315.394
    update_time_ms: 2.17
  iterations_since_restore: 42
  node_ip: 10.4.1.55
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 2.7988235294117643
    ram_util_percent: 6.0
  pid: 143796
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 3.8545176433197526
    mean_inference_ms: 0.5314035180309833
    mean_processing_ms: 1.6812783644957165
  time_since_restore: 2563.296308040619
  time_this_iter_s: 59.91506385803223
  time_total_s: 2563.296308040619
  timestamp: 1585077516
  timesteps_since_restore: 420000
  timesteps_this_iter: 10000
  timesteps_total: 420000
  training_iteration: 42
  trial_id: 44d516d6
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2/2 CPUs, 0/0 GPUs
Memory usage on this node: 12.1/201.2 GB
Result logdir: /users/PYS1027/chnrhughes/ray_results/simple_training_example_ring_v1
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - PPO_WaveAttenuationPOEnv-v0_0:	RUNNING, [2 CPUs, 0 GPUs], [pid=143796], 2563 s, 42 iter, 420000 ts, 3.29e+03 rew

[2m[36m(pid=143796)[0m 2020-03-24 15:18:36,091	WARNING ppo.py:121 -- The magnitude of your environment rewards are more than 329.0x the scale of `vf_clip_param`. This means that it will take more than 329.0 iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.
[2m[36m(pid=143797)[0m 
[2m[36m(pid=143797)[0m -----------------------
[2m[36m(pid=143797)[0m ring length: 492
[2m[36m(pid=143797)[0m v_max: 12.275591251518899
[2m[36m(pid=143797)[0m -----------------------
[2m[36m(pid=143797)[0m 
[2m[36m(pid=143797)[0m -----------------------
[2m[36m(pid=143797)[0m ring length: 491
[2m[36m(pid=143797)[0m v_max: 12.238617992673053
[2m[36m(pid=143797)[0m -----------------------
[2m[36m(pid=143797)[0m 
[2m[36m(pid=143797)[0m -----------------------
[2m[36m(pid=143797)[0m ring length: 511
[2m[36m(pid=143797)[0m v_max: 12.97131045565535
[2m[36m(pid=143797)[0m -----------------------
[2m[36m(pid=143797)[0m 
[2m[36m(pid=143797)[0m -----------------------
[2m[36m(pid=143797)[0m ring length: 506
[2m[36m(pid=143797)[0m v_max: 12.789515517436104
[2m[36m(pid=143797)[0m -----------------------
[2m[36m(pid=143797)[0m 
[2m[36m(pid=143797)[0m -----------------------
[2m[36m(pid=143797)[0m ring length: 494
[2m[36m(pid=143797)[0m v_max: 12.34943486433356
[2m[36m(pid=143797)[0m -----------------------
Result for PPO_WaveAttenuationPOEnv-v0_0:
  custom_metrics: {}
  date: 2020-03-24_15-19-35
  done: false
  episode_len_mean: 2000.0
  episode_reward_max: 3943.369443809236
  episode_reward_mean: 3312.883125280032
  episode_reward_min: 2017.8823114684565
  episodes_this_iter: 5
  episodes_total: 215
  experiment_id: 3169a4f824ed4a02b4b42d55753086c5
  hostname: p0056.ten.osc.edu
  info:
    grad_time_ms: 221.699
    learner:
      default_policy:
        cur_kl_coeff: 4.547473576627277e-14
        cur_lr: 4.999999873689376e-05
        entropy: 0.37264835834503174
        entropy_coeff: 0.0
        kl: 0.0023168642073869705
        policy_loss: -0.0010261260904371738
        total_loss: 2125.1943359375
        vf_explained_var: 0.00037920475006103516
        vf_loss: 2125.195556640625
    load_time_ms: 1.957
    num_steps_sampled: 430000
    num_steps_trained: 430000
    sample_time_ms: 60257.0
    update_time_ms: 2.058
  iterations_since_restore: 43
  node_ip: 10.4.1.55
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 2.7302325581395355
    ram_util_percent: 6.0
  pid: 143796
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 3.853877951676395
    mean_inference_ms: 0.5311474377057028
    mean_processing_ms: 1.6812456978617347
  time_since_restore: 2623.1273992061615
  time_this_iter_s: 59.8310911655426
  time_total_s: 2623.1273992061615
  timestamp: 1585077575
  timesteps_since_restore: 430000
  timesteps_this_iter: 10000
  timesteps_total: 430000
  training_iteration: 43
  trial_id: 44d516d6
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2/2 CPUs, 0/0 GPUs
Memory usage on this node: 12.1/201.2 GB
Result logdir: /users/PYS1027/chnrhughes/ray_results/simple_training_example_ring_v1
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - PPO_WaveAttenuationPOEnv-v0_0:	RUNNING, [2 CPUs, 0 GPUs], [pid=143796], 2623 s, 43 iter, 430000 ts, 3.31e+03 rew

[2m[36m(pid=143796)[0m 2020-03-24 15:19:35,931	WARNING ppo.py:121 -- The magnitude of your environment rewards are more than 331.0x the scale of `vf_clip_param`. This means that it will take more than 331.0 iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.
[2m[36m(pid=143797)[0m 
[2m[36m(pid=143797)[0m -----------------------
[2m[36m(pid=143797)[0m ring length: 503
[2m[36m(pid=143797)[0m v_max: 12.679986184756686
[2m[36m(pid=143797)[0m -----------------------
[2m[36m(pid=143797)[0m 
[2m[36m(pid=143797)[0m -----------------------
[2m[36m(pid=143797)[0m ring length: 512
[2m[36m(pid=143797)[0m v_max: 13.007554232214234
[2m[36m(pid=143797)[0m -----------------------
[2m[36m(pid=143797)[0m 
[2m[36m(pid=143797)[0m -----------------------
[2m[36m(pid=143797)[0m ring length: 490
[2m[36m(pid=143797)[0m v_max: 12.201610748825663
[2m[36m(pid=143797)[0m -----------------------
[2m[36m(pid=143797)[0m 
[2m[36m(pid=143797)[0m -----------------------
[2m[36m(pid=143797)[0m ring length: 497
[2m[36m(pid=143797)[0m v_max: 12.45993945925872
[2m[36m(pid=143797)[0m -----------------------
[2m[36m(pid=143797)[0m 
[2m[36m(pid=143797)[0m -----------------------
[2m[36m(pid=143797)[0m ring length: 510
[2m[36m(pid=143797)[0m v_max: 12.93502796218664
[2m[36m(pid=143797)[0m -----------------------
Result for PPO_WaveAttenuationPOEnv-v0_0:
  custom_metrics: {}
  date: 2020-03-24_15-20-36
  done: false
  episode_len_mean: 2000.0
  episode_reward_max: 3943.369443809236
  episode_reward_mean: 3309.595074364377
  episode_reward_min: 2017.8823114684565
  episodes_this_iter: 5
  episodes_total: 220
  experiment_id: 3169a4f824ed4a02b4b42d55753086c5
  hostname: p0056.ten.osc.edu
  info:
    grad_time_ms: 222.779
    learner:
      default_policy:
        cur_kl_coeff: 2.2737367883136385e-14
        cur_lr: 4.999999873689376e-05
        entropy: 0.36192587018013
        entropy_coeff: 0.0
        kl: 0.01164616085588932
        policy_loss: -0.00451384112238884
        total_loss: 1975.6221923828125
        vf_explained_var: 0.0004742145538330078
        vf_loss: 1975.627197265625
    load_time_ms: 1.951
    num_steps_sampled: 440000
    num_steps_trained: 440000
    sample_time_ms: 60131.049
    update_time_ms: 2.028
  iterations_since_restore: 44
  node_ip: 10.4.1.55
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 2.6800000000000006
    ram_util_percent: 6.0
  pid: 143796
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 3.853209038042242
    mean_inference_ms: 0.5308357818332854
    mean_processing_ms: 1.6812257019842605
  time_since_restore: 2683.191970348358
  time_this_iter_s: 60.064571142196655
  time_total_s: 2683.191970348358
  timestamp: 1585077636
  timesteps_since_restore: 440000
  timesteps_this_iter: 10000
  timesteps_total: 440000
  training_iteration: 44
  trial_id: 44d516d6
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2/2 CPUs, 0/0 GPUs
Memory usage on this node: 12.1/201.2 GB
Result logdir: /users/PYS1027/chnrhughes/ray_results/simple_training_example_ring_v1
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - PPO_WaveAttenuationPOEnv-v0_0:	RUNNING, [2 CPUs, 0 GPUs], [pid=143796], 2683 s, 44 iter, 440000 ts, 3.31e+03 rew

[2m[36m(pid=143796)[0m 2020-03-24 15:20:36,005	WARNING ppo.py:121 -- The magnitude of your environment rewards are more than 331.0x the scale of `vf_clip_param`. This means that it will take more than 331.0 iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.
[2m[36m(pid=143797)[0m 
[2m[36m(pid=143797)[0m -----------------------
[2m[36m(pid=143797)[0m ring length: 490
[2m[36m(pid=143797)[0m v_max: 12.201610748825663
[2m[36m(pid=143797)[0m -----------------------
[2m[36m(pid=143797)[0m 
[2m[36m(pid=143797)[0m -----------------------
[2m[36m(pid=143797)[0m ring length: 496
[2m[36m(pid=143797)[0m v_max: 12.423139687457347
[2m[36m(pid=143797)[0m -----------------------
[2m[36m(pid=143797)[0m 
[2m[36m(pid=143797)[0m -----------------------
[2m[36m(pid=143797)[0m ring length: 509
[2m[36m(pid=143797)[0m v_max: 12.89870698649076
[2m[36m(pid=143797)[0m -----------------------
[2m[36m(pid=143797)[0m 
[2m[36m(pid=143797)[0m -----------------------
[2m[36m(pid=143797)[0m ring length: 500
[2m[36m(pid=143797)[0m v_max: 12.570125367437457
[2m[36m(pid=143797)[0m -----------------------
[2m[36m(pid=143797)[0m 
[2m[36m(pid=143797)[0m -----------------------
[2m[36m(pid=143797)[0m ring length: 495
[2m[36m(pid=143797)[0m v_max: 12.386304743340318
[2m[36m(pid=143797)[0m -----------------------
Result for PPO_WaveAttenuationPOEnv-v0_0:
  custom_metrics: {}
  date: 2020-03-24_15-21-36
  done: false
  episode_len_mean: 2000.0
  episode_reward_max: 3943.369443809236
  episode_reward_mean: 3372.5942862476345
  episode_reward_min: 2515.787144917711
  episodes_this_iter: 5
  episodes_total: 225
  experiment_id: 3169a4f824ed4a02b4b42d55753086c5
  hostname: p0056.ten.osc.edu
  info:
    grad_time_ms: 222.827
    learner:
      default_policy:
        cur_kl_coeff: 2.2737367883136385e-14
        cur_lr: 4.999999873689376e-05
        entropy: 0.34514954686164856
        entropy_coeff: 0.0
        kl: 0.00483272410929203
        policy_loss: -0.0010996948694810271
        total_loss: 2821.163818359375
        vf_explained_var: 4.1484832763671875e-05
        vf_loss: 2821.165283203125
    load_time_ms: 2.027
    num_steps_sampled: 450000
    num_steps_trained: 450000
    sample_time_ms: 60059.264
    update_time_ms: 2.003
  iterations_since_restore: 45
  node_ip: 10.4.1.55
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 2.698837209302326
    ram_util_percent: 6.0
  pid: 143796
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 3.8526437205389663
    mean_inference_ms: 0.5304147027972513
    mean_processing_ms: 1.6812191260879872
  time_since_restore: 2743.670088291168
  time_this_iter_s: 60.47811794281006
  time_total_s: 2743.670088291168
  timestamp: 1585077696
  timesteps_since_restore: 450000
  timesteps_this_iter: 10000
  timesteps_total: 450000
  training_iteration: 45
  trial_id: 44d516d6
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2/2 CPUs, 0/0 GPUs
Memory usage on this node: 12.1/201.2 GB
Result logdir: /users/PYS1027/chnrhughes/ray_results/simple_training_example_ring_v1
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - PPO_WaveAttenuationPOEnv-v0_0:	RUNNING, [2 CPUs, 0 GPUs], [pid=143796], 2743 s, 45 iter, 450000 ts, 3.37e+03 rew

[2m[36m(pid=143796)[0m 2020-03-24 15:21:36,492	WARNING ppo.py:121 -- The magnitude of your environment rewards are more than 337.0x the scale of `vf_clip_param`. This means that it will take more than 337.0 iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.
[2m[36m(pid=143797)[0m 
[2m[36m(pid=143797)[0m -----------------------
[2m[36m(pid=143797)[0m ring length: 500
[2m[36m(pid=143797)[0m v_max: 12.570125367437457
[2m[36m(pid=143797)[0m -----------------------
[2m[36m(pid=143797)[0m 
[2m[36m(pid=143797)[0m -----------------------
[2m[36m(pid=143797)[0m ring length: 503
[2m[36m(pid=143797)[0m v_max: 12.679986184756686
[2m[36m(pid=143797)[0m -----------------------
[2m[36m(pid=143797)[0m 
[2m[36m(pid=143797)[0m -----------------------
[2m[36m(pid=143797)[0m ring length: 519
[2m[36m(pid=143797)[0m v_max: 13.260156955398273
[2m[36m(pid=143797)[0m -----------------------
[2m[36m(pid=143797)[0m 
[2m[36m(pid=143797)[0m -----------------------
[2m[36m(pid=143797)[0m ring length: 498
[2m[36m(pid=143797)[0m v_max: 12.496703821373096
[2m[36m(pid=143797)[0m -----------------------
[2m[36m(pid=143797)[0m 
[2m[36m(pid=143797)[0m -----------------------
[2m[36m(pid=143797)[0m ring length: 490
[2m[36m(pid=143797)[0m v_max: 12.201610748825663
[2m[36m(pid=143797)[0m -----------------------
Result for PPO_WaveAttenuationPOEnv-v0_0:
  custom_metrics: {}
  date: 2020-03-24_15-22-37
  done: false
  episode_len_mean: 2000.0
  episode_reward_max: 4089.605739023453
  episode_reward_mean: 3409.5992870963387
  episode_reward_min: 2515.787144917711
  episodes_this_iter: 5
  episodes_total: 230
  experiment_id: 3169a4f824ed4a02b4b42d55753086c5
  hostname: p0056.ten.osc.edu
  info:
    grad_time_ms: 223.277
    learner:
      default_policy:
        cur_kl_coeff: 1.1368683941568192e-14
        cur_lr: 4.999999873689376e-05
        entropy: 0.33529236912727356
        entropy_coeff: 0.0
        kl: 0.008120751939713955
        policy_loss: -0.0014263236662372947
        total_loss: 3181.3583984375
        vf_explained_var: 5.125999450683594e-06
        vf_loss: 3181.359619140625
    load_time_ms: 2.023
    num_steps_sampled: 460000
    num_steps_trained: 460000
    sample_time_ms: 60071.037
    update_time_ms: 2.008
  iterations_since_restore: 46
  node_ip: 10.4.1.55
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 2.6965517241379313
    ram_util_percent: 6.0
  pid: 143796
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 3.852127685709718
    mean_inference_ms: 0.5299095943845196
    mean_processing_ms: 1.6812276072849404
  time_since_restore: 2804.582330942154
  time_this_iter_s: 60.91224265098572
  time_total_s: 2804.582330942154
  timestamp: 1585077757
  timesteps_since_restore: 460000
  timesteps_this_iter: 10000
  timesteps_total: 460000
  training_iteration: 46
  trial_id: 44d516d6
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2/2 CPUs, 0/0 GPUs
Memory usage on this node: 12.1/201.2 GB
Result logdir: /users/PYS1027/chnrhughes/ray_results/simple_training_example_ring_v1
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - PPO_WaveAttenuationPOEnv-v0_0:	RUNNING, [2 CPUs, 0 GPUs], [pid=143796], 2804 s, 46 iter, 460000 ts, 3.41e+03 rew

[2m[36m(pid=143796)[0m 2020-03-24 15:22:37,426	WARNING ppo.py:121 -- The magnitude of your environment rewards are more than 341.0x the scale of `vf_clip_param`. This means that it will take more than 341.0 iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.
[2m[36m(pid=143797)[0m 
[2m[36m(pid=143797)[0m -----------------------
[2m[36m(pid=143797)[0m ring length: 492
[2m[36m(pid=143797)[0m v_max: 12.275591251518899
[2m[36m(pid=143797)[0m -----------------------
[2m[36m(pid=143797)[0m 
[2m[36m(pid=143797)[0m -----------------------
[2m[36m(pid=143797)[0m ring length: 498
[2m[36m(pid=143797)[0m v_max: 12.496703821373096
[2m[36m(pid=143797)[0m -----------------------
[2m[36m(pid=143797)[0m 
[2m[36m(pid=143797)[0m -----------------------
[2m[36m(pid=143797)[0m ring length: 511
[2m[36m(pid=143797)[0m v_max: 12.97131045565535
[2m[36m(pid=143797)[0m -----------------------
[2m[36m(pid=143797)[0m 
[2m[36m(pid=143797)[0m -----------------------
[2m[36m(pid=143797)[0m ring length: 498
[2m[36m(pid=143797)[0m v_max: 12.496703821373096
[2m[36m(pid=143797)[0m -----------------------
[2m[36m(pid=143797)[0m 
[2m[36m(pid=143797)[0m -----------------------
[2m[36m(pid=143797)[0m ring length: 498
[2m[36m(pid=143797)[0m v_max: 12.496703821373096
[2m[36m(pid=143797)[0m -----------------------
Result for PPO_WaveAttenuationPOEnv-v0_0:
  custom_metrics: {}
  date: 2020-03-24_15-23-37
  done: false
  episode_len_mean: 2000.0
  episode_reward_max: 4089.605739023453
  episode_reward_mean: 3421.3851702616
  episode_reward_min: 2515.787144917711
  episodes_this_iter: 5
  episodes_total: 235
  experiment_id: 3169a4f824ed4a02b4b42d55753086c5
  hostname: p0056.ten.osc.edu
  info:
    grad_time_ms: 223.153
    learner:
      default_policy:
        cur_kl_coeff: 5.684341970784096e-15
        cur_lr: 4.999999873689376e-05
        entropy: 0.32858067750930786
        entropy_coeff: 0.0
        kl: 0.001028374070301652
        policy_loss: -0.0004026023962069303
        total_loss: 2564.035888671875
        vf_explained_var: 0.00010603666305541992
        vf_loss: 2564.035888671875
    load_time_ms: 2.018
    num_steps_sampled: 470000
    num_steps_trained: 470000
    sample_time_ms: 59995.024
    update_time_ms: 2.025
  iterations_since_restore: 47
  node_ip: 10.4.1.55
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 2.6895348837209303
    ram_util_percent: 6.0
  pid: 143796
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 3.8515511118383134
    mean_inference_ms: 0.5293513008220585
    mean_processing_ms: 1.6812465060047739
  time_since_restore: 2864.8915865421295
  time_this_iter_s: 60.309255599975586
  time_total_s: 2864.8915865421295
  timestamp: 1585077817
  timesteps_since_restore: 470000
  timesteps_this_iter: 10000
  timesteps_total: 470000
  training_iteration: 47
  trial_id: 44d516d6
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2/2 CPUs, 0/0 GPUs
Memory usage on this node: 12.1/201.2 GB
Result logdir: /users/PYS1027/chnrhughes/ray_results/simple_training_example_ring_v1
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - PPO_WaveAttenuationPOEnv-v0_0:	RUNNING, [2 CPUs, 0 GPUs], [pid=143796], 2864 s, 47 iter, 470000 ts, 3.42e+03 rew

[2m[36m(pid=143796)[0m 2020-03-24 15:23:37,744	WARNING ppo.py:121 -- The magnitude of your environment rewards are more than 342.0x the scale of `vf_clip_param`. This means that it will take more than 342.0 iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.
[2m[36m(pid=143797)[0m 
[2m[36m(pid=143797)[0m -----------------------
[2m[36m(pid=143797)[0m ring length: 511
[2m[36m(pid=143797)[0m v_max: 12.97131045565535
[2m[36m(pid=143797)[0m -----------------------
[2m[36m(pid=143797)[0m 
[2m[36m(pid=143797)[0m -----------------------
[2m[36m(pid=143797)[0m ring length: 516
[2m[36m(pid=143797)[0m v_max: 13.152137487657606
[2m[36m(pid=143797)[0m -----------------------
[2m[36m(pid=143797)[0m 
[2m[36m(pid=143797)[0m -----------------------
[2m[36m(pid=143797)[0m ring length: 498
[2m[36m(pid=143797)[0m v_max: 12.496703821373096
[2m[36m(pid=143797)[0m -----------------------
[2m[36m(pid=143797)[0m 
[2m[36m(pid=143797)[0m -----------------------
[2m[36m(pid=143797)[0m ring length: 504
[2m[36m(pid=143797)[0m v_max: 12.716533109302146
[2m[36m(pid=143797)[0m -----------------------
[2m[36m(pid=143797)[0m 
[2m[36m(pid=143797)[0m -----------------------
[2m[36m(pid=143797)[0m ring length: 505
[2m[36m(pid=143797)[0m v_max: 12.753042965621004
[2m[36m(pid=143797)[0m -----------------------
Result for PPO_WaveAttenuationPOEnv-v0_0:
  custom_metrics: {}
  date: 2020-03-24_15-24-38
  done: false
  episode_len_mean: 2000.0
  episode_reward_max: 4089.605739023453
  episode_reward_mean: 3439.8512176873587
  episode_reward_min: 2515.787144917711
  episodes_this_iter: 5
  episodes_total: 240
  experiment_id: 3169a4f824ed4a02b4b42d55753086c5
  hostname: p0056.ten.osc.edu
  info:
    grad_time_ms: 222.373
    learner:
      default_policy:
        cur_kl_coeff: 2.842170985392048e-15
        cur_lr: 4.999999873689376e-05
        entropy: 0.3174874782562256
        entropy_coeff: 0.0
        kl: 0.005052916705608368
        policy_loss: -0.00051506282761693
        total_loss: 2868.903564453125
        vf_explained_var: 4.51207160949707e-05
        vf_loss: 2868.904052734375
    load_time_ms: 2.07
    num_steps_sampled: 480000
    num_steps_trained: 480000
    sample_time_ms: 59965.715
    update_time_ms: 2.004
  iterations_since_restore: 48
  node_ip: 10.4.1.55
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 2.7813953488372083
    ram_util_percent: 6.0
  pid: 143796
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 3.850962595111521
    mean_inference_ms: 0.5287308925773558
    mean_processing_ms: 1.6812602159528682
  time_since_restore: 2925.3186638355255
  time_this_iter_s: 60.427077293395996
  time_total_s: 2925.3186638355255
  timestamp: 1585077878
  timesteps_since_restore: 480000
  timesteps_this_iter: 10000
  timesteps_total: 480000
  training_iteration: 48
  trial_id: 44d516d6
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2/2 CPUs, 0/0 GPUs
Memory usage on this node: 12.1/201.2 GB
Result logdir: /users/PYS1027/chnrhughes/ray_results/simple_training_example_ring_v1
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - PPO_WaveAttenuationPOEnv-v0_0:	RUNNING, [2 CPUs, 0 GPUs], [pid=143796], 2925 s, 48 iter, 480000 ts, 3.44e+03 rew

[2m[36m(pid=143796)[0m 2020-03-24 15:24:38,180	WARNING ppo.py:121 -- The magnitude of your environment rewards are more than 344.0x the scale of `vf_clip_param`. This means that it will take more than 344.0 iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.
[2m[36m(pid=143797)[0m 
[2m[36m(pid=143797)[0m -----------------------
[2m[36m(pid=143797)[0m ring length: 518
[2m[36m(pid=143797)[0m v_max: 13.22419073821961
[2m[36m(pid=143797)[0m -----------------------
[2m[36m(pid=143797)[0m 
[2m[36m(pid=143797)[0m -----------------------
[2m[36m(pid=143797)[0m ring length: 510
[2m[36m(pid=143797)[0m v_max: 12.93502796218664
[2m[36m(pid=143797)[0m -----------------------
[2m[36m(pid=143797)[0m 
[2m[36m(pid=143797)[0m -----------------------
[2m[36m(pid=143797)[0m ring length: 490
[2m[36m(pid=143797)[0m v_max: 12.201610748825663
[2m[36m(pid=143797)[0m -----------------------
[2m[36m(pid=143797)[0m 
[2m[36m(pid=143797)[0m -----------------------
[2m[36m(pid=143797)[0m ring length: 503
[2m[36m(pid=143797)[0m v_max: 12.679986184756686
[2m[36m(pid=143797)[0m -----------------------
[2m[36m(pid=143797)[0m 
[2m[36m(pid=143797)[0m -----------------------
[2m[36m(pid=143797)[0m ring length: 495
[2m[36m(pid=143797)[0m v_max: 12.386304743340318
[2m[36m(pid=143797)[0m -----------------------
Result for PPO_WaveAttenuationPOEnv-v0_0:
  custom_metrics: {}
  date: 2020-03-24_15-25-39
  done: false
  episode_len_mean: 2000.0
  episode_reward_max: 4189.843435037966
  episode_reward_mean: 3464.0873688946517
  episode_reward_min: 2515.787144917711
  episodes_this_iter: 5
  episodes_total: 245
  experiment_id: 3169a4f824ed4a02b4b42d55753086c5
  hostname: p0056.ten.osc.edu
  info:
    grad_time_ms: 220.849
    learner:
      default_policy:
        cur_kl_coeff: 1.421085492696024e-15
        cur_lr: 4.999999873689376e-05
        entropy: 0.310590535402298
        entropy_coeff: 0.0
        kl: 0.006567897740751505
        policy_loss: -0.0007652937201783061
        total_loss: 3255.80029296875
        vf_explained_var: 9.655952453613281e-06
        vf_loss: 3255.80126953125
    load_time_ms: 2.075
    num_steps_sampled: 490000
    num_steps_trained: 490000
    sample_time_ms: 60028.514
    update_time_ms: 1.982
  iterations_since_restore: 49
  node_ip: 10.4.1.55
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 2.7091954022988505
    ram_util_percent: 6.0
  pid: 143796
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 3.8503822361481763
    mean_inference_ms: 0.5281295115975152
    mean_processing_ms: 1.6812906403897419
  time_since_restore: 2986.1585710048676
  time_this_iter_s: 60.83990716934204
  time_total_s: 2986.1585710048676
  timestamp: 1585077939
  timesteps_since_restore: 490000
  timesteps_this_iter: 10000
  timesteps_total: 490000
  training_iteration: 49
  trial_id: 44d516d6
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2/2 CPUs, 0/0 GPUs
Memory usage on this node: 12.1/201.2 GB
Result logdir: /users/PYS1027/chnrhughes/ray_results/simple_training_example_ring_v1
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - PPO_WaveAttenuationPOEnv-v0_0:	RUNNING, [2 CPUs, 0 GPUs], [pid=143796], 2986 s, 49 iter, 490000 ts, 3.46e+03 rew

[2m[36m(pid=143796)[0m 2020-03-24 15:25:39,030	WARNING ppo.py:121 -- The magnitude of your environment rewards are more than 346.0x the scale of `vf_clip_param`. This means that it will take more than 346.0 iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.
[2m[36m(pid=143797)[0m 
[2m[36m(pid=143797)[0m -----------------------
[2m[36m(pid=143797)[0m ring length: 513
[2m[36m(pid=143797)[0m v_max: 13.043759057511211
[2m[36m(pid=143797)[0m -----------------------
[2m[36m(pid=143797)[0m 
[2m[36m(pid=143797)[0m -----------------------
[2m[36m(pid=143797)[0m ring length: 507
[2m[36m(pid=143797)[0m v_max: 12.825950528689797
[2m[36m(pid=143797)[0m -----------------------
[2m[36m(pid=143797)[0m 
[2m[36m(pid=143797)[0m -----------------------
[2m[36m(pid=143797)[0m ring length: 495
[2m[36m(pid=143797)[0m v_max: 12.386304743340318
[2m[36m(pid=143797)[0m -----------------------
[2m[36m(pid=143797)[0m 
[2m[36m(pid=143797)[0m -----------------------
[2m[36m(pid=143797)[0m ring length: 500
[2m[36m(pid=143797)[0m v_max: 12.570125367437457
[2m[36m(pid=143797)[0m -----------------------
[2m[36m(pid=143797)[0m 
[2m[36m(pid=143797)[0m -----------------------
[2m[36m(pid=143797)[0m ring length: 503
[2m[36m(pid=143797)[0m v_max: 12.679986184756686
[2m[36m(pid=143797)[0m -----------------------
Result for PPO_WaveAttenuationPOEnv-v0_0:
  custom_metrics: {}
  date: 2020-03-24_15-26-39
  done: false
  episode_len_mean: 2000.0
  episode_reward_max: 4275.368016879382
  episode_reward_mean: 3481.700264691564
  episode_reward_min: 2515.787144917711
  episodes_this_iter: 5
  episodes_total: 250
  experiment_id: 3169a4f824ed4a02b4b42d55753086c5
  hostname: p0056.ten.osc.edu
  info:
    grad_time_ms: 220.346
    learner:
      default_policy:
        cur_kl_coeff: 7.10542746348012e-16
        cur_lr: 4.999999873689376e-05
        entropy: 0.2979567348957062
        entropy_coeff: 0.0
        kl: 0.003357217414304614
        policy_loss: -0.0010410586837679148
        total_loss: 3324.064208984375
        vf_explained_var: 6.377696990966797e-06
        vf_loss: 3324.065185546875
    load_time_ms: 2.068
    num_steps_sampled: 500000
    num_steps_trained: 500000
    sample_time_ms: 60139.935
    update_time_ms: 1.975
  iterations_since_restore: 50
  node_ip: 10.4.1.55
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 2.7267441860465125
    ram_util_percent: 6.0
  pid: 143796
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 3.8498158013969466
    mean_inference_ms: 0.5275580388973541
    mean_processing_ms: 1.6813255020040427
  time_since_restore: 3046.9694225788116
  time_this_iter_s: 60.81085157394409
  time_total_s: 3046.9694225788116
  timestamp: 1585077999
  timesteps_since_restore: 500000
  timesteps_this_iter: 10000
  timesteps_total: 500000
  training_iteration: 50
  trial_id: 44d516d6
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2/2 CPUs, 0/0 GPUs
Memory usage on this node: 12.1/201.2 GB
Result logdir: /users/PYS1027/chnrhughes/ray_results/simple_training_example_ring_v1
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - PPO_WaveAttenuationPOEnv-v0_0:	RUNNING, [2 CPUs, 0 GPUs], [pid=143796], 3046 s, 50 iter, 500000 ts, 3.48e+03 rew

[2m[36m(pid=143796)[0m 2020-03-24 15:26:39,850	WARNING ppo.py:121 -- The magnitude of your environment rewards are more than 348.0x the scale of `vf_clip_param`. This means that it will take more than 348.0 iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.
[2m[36m(pid=143797)[0m 
[2m[36m(pid=143797)[0m -----------------------
[2m[36m(pid=143797)[0m ring length: 500
[2m[36m(pid=143797)[0m v_max: 12.570125367437457
[2m[36m(pid=143797)[0m -----------------------
[2m[36m(pid=143797)[0m 
[2m[36m(pid=143797)[0m -----------------------
[2m[36m(pid=143797)[0m ring length: 502
[2m[36m(pid=143797)[0m v_max: 12.64340242846283
[2m[36m(pid=143797)[0m -----------------------
[2m[36m(pid=143797)[0m 
[2m[36m(pid=143797)[0m -----------------------
[2m[36m(pid=143797)[0m ring length: 497
[2m[36m(pid=143797)[0m v_max: 12.45993945925872
[2m[36m(pid=143797)[0m -----------------------
[2m[36m(pid=143797)[0m 
[2m[36m(pid=143797)[0m -----------------------
[2m[36m(pid=143797)[0m ring length: 490
[2m[36m(pid=143797)[0m v_max: 12.201610748825663
[2m[36m(pid=143797)[0m -----------------------
[2m[36m(pid=143797)[0m 
[2m[36m(pid=143797)[0m -----------------------
[2m[36m(pid=143797)[0m ring length: 501
[2m[36m(pid=143797)[0m v_max: 12.606782077081403
[2m[36m(pid=143797)[0m -----------------------
Result for PPO_WaveAttenuationPOEnv-v0_0:
  custom_metrics: {}
  date: 2020-03-24_15-27-40
  done: false
  episode_len_mean: 2000.0
  episode_reward_max: 4275.368016879382
  episode_reward_mean: 3501.8048867832877
  episode_reward_min: 2515.787144917711
  episodes_this_iter: 5
  episodes_total: 255
  experiment_id: 3169a4f824ed4a02b4b42d55753086c5
  hostname: p0056.ten.osc.edu
  info:
    grad_time_ms: 219.626
    learner:
      default_policy:
        cur_kl_coeff: 3.55271373174006e-16
        cur_lr: 4.999999873689376e-05
        entropy: 0.2884751856327057
        entropy_coeff: 0.0
        kl: 0.002131314715370536
        policy_loss: -0.00033010501647368073
        total_loss: 3276.162353515625
        vf_explained_var: -8.344650268554688e-07
        vf_loss: 3276.1630859375
    load_time_ms: 2.061
    num_steps_sampled: 510000
    num_steps_trained: 510000
    sample_time_ms: 60234.948
    update_time_ms: 1.931
  iterations_since_restore: 51
  node_ip: 10.4.1.55
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 2.68735632183908
    ram_util_percent: 6.0
  pid: 143796
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 3.849287761963219
    mean_inference_ms: 0.5270781629927344
    mean_processing_ms: 1.6813496613274486
  time_since_restore: 3108.0243787765503
  time_this_iter_s: 61.05495619773865
  time_total_s: 3108.0243787765503
  timestamp: 1585078060
  timesteps_since_restore: 510000
  timesteps_this_iter: 10000
  timesteps_total: 510000
  training_iteration: 51
  trial_id: 44d516d6
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2/2 CPUs, 0/0 GPUs
Memory usage on this node: 12.1/201.2 GB
Result logdir: /users/PYS1027/chnrhughes/ray_results/simple_training_example_ring_v1
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - PPO_WaveAttenuationPOEnv-v0_0:	RUNNING, [2 CPUs, 0 GPUs], [pid=143796], 3108 s, 51 iter, 510000 ts, 3.5e+03 rew

[2m[36m(pid=143796)[0m 2020-03-24 15:27:40,923	WARNING ppo.py:121 -- The magnitude of your environment rewards are more than 350.0x the scale of `vf_clip_param`. This means that it will take more than 350.0 iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.
[2m[36m(pid=143797)[0m 
[2m[36m(pid=143797)[0m -----------------------
[2m[36m(pid=143797)[0m ring length: 494
[2m[36m(pid=143797)[0m v_max: 12.34943486433356
[2m[36m(pid=143797)[0m -----------------------
[2m[36m(pid=143797)[0m 
[2m[36m(pid=143797)[0m -----------------------
[2m[36m(pid=143797)[0m ring length: 510
[2m[36m(pid=143797)[0m v_max: 12.93502796218664
[2m[36m(pid=143797)[0m -----------------------
[2m[36m(pid=143797)[0m 
[2m[36m(pid=143797)[0m -----------------------
[2m[36m(pid=143797)[0m ring length: 496
[2m[36m(pid=143797)[0m v_max: 12.423139687457347
[2m[36m(pid=143797)[0m -----------------------
[2m[36m(pid=143797)[0m 
[2m[36m(pid=143797)[0m -----------------------
[2m[36m(pid=143797)[0m ring length: 495
[2m[36m(pid=143797)[0m v_max: 12.386304743340318
[2m[36m(pid=143797)[0m -----------------------
[2m[36m(pid=143797)[0m 
[2m[36m(pid=143797)[0m -----------------------
[2m[36m(pid=143797)[0m ring length: 518
[2m[36m(pid=143797)[0m v_max: 13.22419073821961
[2m[36m(pid=143797)[0m -----------------------
Result for PPO_WaveAttenuationPOEnv-v0_0:
  custom_metrics: {}
  date: 2020-03-24_15-28-41
  done: false
  episode_len_mean: 2000.0
  episode_reward_max: 4275.368016879382
  episode_reward_mean: 3526.015108325405
  episode_reward_min: 2515.787144917711
  episodes_this_iter: 5
  episodes_total: 260
  experiment_id: 3169a4f824ed4a02b4b42d55753086c5
  hostname: p0056.ten.osc.edu
  info:
    grad_time_ms: 217.92
    learner:
      default_policy:
        cur_kl_coeff: 1.77635686587003e-16
        cur_lr: 4.999999873689376e-05
        entropy: 0.2767166495323181
        entropy_coeff: 0.0
        kl: 0.004976785741746426
        policy_loss: -0.0014365639071911573
        total_loss: 3271.2119140625
        vf_explained_var: 4.0531158447265625e-06
        vf_loss: 3271.213134765625
    load_time_ms: 2.06
    num_steps_sampled: 520000
    num_steps_trained: 520000
    sample_time_ms: 60282.891
    update_time_ms: 1.935
  iterations_since_restore: 52
  node_ip: 10.4.1.55
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 2.7081395348837205
    ram_util_percent: 6.0
  pid: 143796
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 3.848793307523763
    mean_inference_ms: 0.5265678867506897
    mean_processing_ms: 1.6813773814059965
  time_since_restore: 3168.4012718200684
  time_this_iter_s: 60.376893043518066
  time_total_s: 3168.4012718200684
  timestamp: 1585078121
  timesteps_since_restore: 520000
  timesteps_this_iter: 10000
  timesteps_total: 520000
  training_iteration: 52
  trial_id: 44d516d6
  
[2m[36m(pid=143796)[0m 2020-03-24 15:28:41,310	WARNING ppo.py:121 -- The magnitude of your environment rewards are more than 353.0x the scale of `vf_clip_param`. This means that it will take more than 353.0 iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2/2 CPUs, 0/0 GPUs
Memory usage on this node: 12.1/201.2 GB
Result logdir: /users/PYS1027/chnrhughes/ray_results/simple_training_example_ring_v1
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - PPO_WaveAttenuationPOEnv-v0_0:	RUNNING, [2 CPUs, 0 GPUs], [pid=143796], 3168 s, 52 iter, 520000 ts, 3.53e+03 rew

[2m[36m(pid=143797)[0m 
[2m[36m(pid=143797)[0m -----------------------
[2m[36m(pid=143797)[0m ring length: 504
[2m[36m(pid=143797)[0m v_max: 12.716533109302146
[2m[36m(pid=143797)[0m -----------------------
[2m[36m(pid=143797)[0m 
[2m[36m(pid=143797)[0m -----------------------
[2m[36m(pid=143797)[0m ring length: 506
[2m[36m(pid=143797)[0m v_max: 12.789515517436104
[2m[36m(pid=143797)[0m -----------------------
[2m[36m(pid=143797)[0m 
[2m[36m(pid=143797)[0m -----------------------
[2m[36m(pid=143797)[0m ring length: 495
[2m[36m(pid=143797)[0m v_max: 12.386304743340318
[2m[36m(pid=143797)[0m -----------------------
[2m[36m(pid=143797)[0m 
[2m[36m(pid=143797)[0m -----------------------
[2m[36m(pid=143797)[0m ring length: 504
[2m[36m(pid=143797)[0m v_max: 12.716533109302146
[2m[36m(pid=143797)[0m -----------------------
[2m[36m(pid=143797)[0m 
[2m[36m(pid=143797)[0m -----------------------
[2m[36m(pid=143797)[0m ring length: 516
[2m[36m(pid=143797)[0m v_max: 13.152137487657606
[2m[36m(pid=143797)[0m -----------------------
Result for PPO_WaveAttenuationPOEnv-v0_0:
  custom_metrics: {}
  date: 2020-03-24_15-29-41
  done: false
  episode_len_mean: 2000.0
  episode_reward_max: 4372.788724108178
  episode_reward_mean: 3570.3598410212976
  episode_reward_min: 2515.787144917711
  episodes_this_iter: 5
  episodes_total: 265
  experiment_id: 3169a4f824ed4a02b4b42d55753086c5
  hostname: p0056.ten.osc.edu
  info:
    grad_time_ms: 216.635
    learner:
      default_policy:
        cur_kl_coeff: 8.88178432935015e-17
        cur_lr: 4.999999873689376e-05
        entropy: 0.26955804228782654
        entropy_coeff: 0.0
        kl: 0.00783540029078722
        policy_loss: -0.0005977775435894728
        total_loss: 3486.23828125
        vf_explained_var: 5.304813385009766e-06
        vf_loss: 3486.23828125
    load_time_ms: 2.061
    num_steps_sampled: 530000
    num_steps_trained: 530000
    sample_time_ms: 60347.882
    update_time_ms: 1.932
  iterations_since_restore: 53
  node_ip: 10.4.1.55
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 2.709195402298851
    ram_util_percent: 6.0
  pid: 143796
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 3.848347471935302
    mean_inference_ms: 0.5260738317632887
    mean_processing_ms: 1.6814024237535892
  time_since_restore: 3228.8687739372253
  time_this_iter_s: 60.46750211715698
  time_total_s: 3228.8687739372253
  timestamp: 1585078181
  timesteps_since_restore: 530000
  timesteps_this_iter: 10000
  timesteps_total: 530000
  training_iteration: 53
  trial_id: 44d516d6
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2/2 CPUs, 0/0 GPUs
Memory usage on this node: 12.1/201.2 GB
Result logdir: /users/PYS1027/chnrhughes/ray_results/simple_training_example_ring_v1
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - PPO_WaveAttenuationPOEnv-v0_0:	RUNNING, [2 CPUs, 0 GPUs], [pid=143796], 3228 s, 53 iter, 530000 ts, 3.57e+03 rew

[2m[36m(pid=143796)[0m 2020-03-24 15:29:41,787	WARNING ppo.py:121 -- The magnitude of your environment rewards are more than 357.0x the scale of `vf_clip_param`. This means that it will take more than 357.0 iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.
[2m[36m(pid=143797)[0m 
[2m[36m(pid=143797)[0m -----------------------
[2m[36m(pid=143797)[0m ring length: 501
[2m[36m(pid=143797)[0m v_max: 12.606782077081403
[2m[36m(pid=143797)[0m -----------------------
[2m[36m(pid=143797)[0m 
[2m[36m(pid=143797)[0m -----------------------
[2m[36m(pid=143797)[0m ring length: 506
[2m[36m(pid=143797)[0m v_max: 12.789515517436104
[2m[36m(pid=143797)[0m -----------------------
[2m[36m(pid=143797)[0m 
[2m[36m(pid=143797)[0m -----------------------
[2m[36m(pid=143797)[0m ring length: 519
[2m[36m(pid=143797)[0m v_max: 13.260156955398273
[2m[36m(pid=143797)[0m -----------------------
[2m[36m(pid=143797)[0m 
[2m[36m(pid=143797)[0m -----------------------
[2m[36m(pid=143797)[0m ring length: 508
[2m[36m(pid=143797)[0m v_max: 12.862347763562411
[2m[36m(pid=143797)[0m -----------------------
[2m[36m(pid=143797)[0m 
[2m[36m(pid=143797)[0m -----------------------
[2m[36m(pid=143797)[0m ring length: 505
[2m[36m(pid=143797)[0m v_max: 12.753042965621004
[2m[36m(pid=143797)[0m -----------------------
Result for PPO_WaveAttenuationPOEnv-v0_0:
  custom_metrics: {}
  date: 2020-03-24_15-30-42
  done: false
  episode_len_mean: 2000.0
  episode_reward_max: 4372.788724108178
  episode_reward_mean: 3586.4390260761675
  episode_reward_min: 2515.787144917711
  episodes_this_iter: 5
  episodes_total: 270
  experiment_id: 3169a4f824ed4a02b4b42d55753086c5
  hostname: p0056.ten.osc.edu
  info:
    grad_time_ms: 214.455
    learner:
      default_policy:
        cur_kl_coeff: 4.440892164675075e-17
        cur_lr: 4.999999873689376e-05
        entropy: 0.25622430443763733
        entropy_coeff: 0.0
        kl: 0.0034398501738905907
        policy_loss: -0.001123512047342956
        total_loss: 3195.894775390625
        vf_explained_var: 1.52587890625e-05
        vf_loss: 3195.895263671875
    load_time_ms: 2.074
    num_steps_sampled: 540000
    num_steps_trained: 540000
    sample_time_ms: 60418.214
    update_time_ms: 1.928
  iterations_since_restore: 54
  node_ip: 10.4.1.55
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 2.769767441860465
    ram_util_percent: 6.0
  pid: 143796
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 3.8479205846690796
    mean_inference_ms: 0.5255021975079174
    mean_processing_ms: 1.6814388764741102
  time_since_restore: 3289.6143901348114
  time_this_iter_s: 60.74561619758606
  time_total_s: 3289.6143901348114
  timestamp: 1585078242
  timesteps_since_restore: 540000
  timesteps_this_iter: 10000
  timesteps_total: 540000
  training_iteration: 54
  trial_id: 44d516d6
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2/2 CPUs, 0/0 GPUs
Memory usage on this node: 12.1/201.2 GB
Result logdir: /users/PYS1027/chnrhughes/ray_results/simple_training_example_ring_v1
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - PPO_WaveAttenuationPOEnv-v0_0:	RUNNING, [2 CPUs, 0 GPUs], [pid=143796], 3289 s, 54 iter, 540000 ts, 3.59e+03 rew

[2m[36m(pid=143796)[0m 2020-03-24 15:30:42,543	WARNING ppo.py:121 -- The magnitude of your environment rewards are more than 359.0x the scale of `vf_clip_param`. This means that it will take more than 359.0 iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.
[2m[36m(pid=143797)[0m 
[2m[36m(pid=143797)[0m -----------------------
[2m[36m(pid=143797)[0m ring length: 517
[2m[36m(pid=143797)[0m v_max: 13.188184171646189
[2m[36m(pid=143797)[0m -----------------------
[2m[36m(pid=143797)[0m 
[2m[36m(pid=143797)[0m -----------------------
[2m[36m(pid=143797)[0m ring length: 520
[2m[36m(pid=143797)[0m v_max: 13.296082591662728
[2m[36m(pid=143797)[0m -----------------------
[2m[36m(pid=143797)[0m 
[2m[36m(pid=143797)[0m -----------------------
[2m[36m(pid=143797)[0m ring length: 513
[2m[36m(pid=143797)[0m v_max: 13.043759057511211
[2m[36m(pid=143797)[0m -----------------------
[2m[36m(pid=143797)[0m 
[2m[36m(pid=143797)[0m -----------------------
[2m[36m(pid=143797)[0m ring length: 494
[2m[36m(pid=143797)[0m v_max: 12.34943486433356
[2m[36m(pid=143797)[0m -----------------------
[2m[36m(pid=143797)[0m 
[2m[36m(pid=143797)[0m -----------------------
[2m[36m(pid=143797)[0m ring length: 497
[2m[36m(pid=143797)[0m v_max: 12.45993945925872
[2m[36m(pid=143797)[0m -----------------------
Result for PPO_WaveAttenuationPOEnv-v0_0:
  custom_metrics: {}
  date: 2020-03-24_15-31-43
  done: false
  episode_len_mean: 2000.0
  episode_reward_max: 4381.806995637801
  episode_reward_mean: 3618.539843343913
  episode_reward_min: 2515.787144917711
  episodes_this_iter: 5
  episodes_total: 275
  experiment_id: 3169a4f824ed4a02b4b42d55753086c5
  hostname: p0056.ten.osc.edu
  info:
    grad_time_ms: 214.071
    learner:
      default_policy:
        cur_kl_coeff: 2.2204460823375376e-17
        cur_lr: 4.999999873689376e-05
        entropy: 0.2483689934015274
        entropy_coeff: 0.0
        kl: 0.01129316259175539
        policy_loss: -0.0019834483973681927
        total_loss: 3588.91845703125
        vf_explained_var: 4.291534423828125e-06
        vf_loss: 3588.92041015625
    load_time_ms: 1.998
    num_steps_sampled: 550000
    num_steps_trained: 550000
    sample_time_ms: 60417.539
    update_time_ms: 1.922
  iterations_since_restore: 55
  node_ip: 10.4.1.55
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 2.6825581395348834
    ram_util_percent: 6.0
  pid: 143796
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 3.8475220475222476
    mean_inference_ms: 0.524871038096059
    mean_processing_ms: 1.6814504892562252
  time_since_restore: 3350.0803813934326
  time_this_iter_s: 60.465991258621216
  time_total_s: 3350.0803813934326
  timestamp: 1585078303
  timesteps_since_restore: 550000
  timesteps_this_iter: 10000
  timesteps_total: 550000
  training_iteration: 55
  trial_id: 44d516d6
  
[2m[36m(pid=143796)[0m 2020-03-24 15:31:43,018	WARNING ppo.py:121 -- The magnitude of your environment rewards are more than 362.0x the scale of `vf_clip_param`. This means that it will take more than 362.0 iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2/2 CPUs, 0/0 GPUs
Memory usage on this node: 12.1/201.2 GB
Result logdir: /users/PYS1027/chnrhughes/ray_results/simple_training_example_ring_v1
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - PPO_WaveAttenuationPOEnv-v0_0:	RUNNING, [2 CPUs, 0 GPUs], [pid=143796], 3350 s, 55 iter, 550000 ts, 3.62e+03 rew

[2m[36m(pid=143797)[0m 
[2m[36m(pid=143797)[0m -----------------------
[2m[36m(pid=143797)[0m ring length: 505
[2m[36m(pid=143797)[0m v_max: 12.753042965621004
[2m[36m(pid=143797)[0m -----------------------
[2m[36m(pid=143797)[0m 
[2m[36m(pid=143797)[0m -----------------------
[2m[36m(pid=143797)[0m ring length: 499
[2m[36m(pid=143797)[0m v_max: 12.533432536501882
[2m[36m(pid=143797)[0m -----------------------
[2m[36m(pid=143797)[0m 
[2m[36m(pid=143797)[0m -----------------------
[2m[36m(pid=143797)[0m ring length: 501
[2m[36m(pid=143797)[0m v_max: 12.606782077081403
[2m[36m(pid=143797)[0m -----------------------
[2m[36m(pid=143797)[0m 
[2m[36m(pid=143797)[0m -----------------------
[2m[36m(pid=143797)[0m ring length: 498
[2m[36m(pid=143797)[0m v_max: 12.496703821373096
[2m[36m(pid=143797)[0m -----------------------
[2m[36m(pid=143797)[0m 
[2m[36m(pid=143797)[0m -----------------------
[2m[36m(pid=143797)[0m ring length: 497
[2m[36m(pid=143797)[0m v_max: 12.45993945925872
[2m[36m(pid=143797)[0m -----------------------
Result for PPO_WaveAttenuationPOEnv-v0_0:
  custom_metrics: {}
  date: 2020-03-24_15-32-43
  done: false
  episode_len_mean: 2000.0
  episode_reward_max: 4381.806995637801
  episode_reward_mean: 3649.374633087153
  episode_reward_min: 2515.787144917711
  episodes_this_iter: 5
  episodes_total: 280
  experiment_id: 3169a4f824ed4a02b4b42d55753086c5
  hostname: p0056.ten.osc.edu
  info:
    grad_time_ms: 213.721
    learner:
      default_policy:
        cur_kl_coeff: 2.2204460823375376e-17
        cur_lr: 4.999999873689376e-05
        entropy: 0.24375644326210022
        entropy_coeff: 0.0
        kl: 0.009526565670967102
        policy_loss: -0.0021556129213422537
        total_loss: 2642.301513671875
        vf_explained_var: 5.751848220825195e-05
        vf_loss: 2642.303466796875
    load_time_ms: 1.996
    num_steps_sampled: 560000
    num_steps_trained: 560000
    sample_time_ms: 60331.297
    update_time_ms: 1.925
  iterations_since_restore: 56
  node_ip: 10.4.1.55
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 2.691860465116279
    ram_util_percent: 6.0
  pid: 143796
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 3.847144750086964
    mean_inference_ms: 0.5241885109438299
    mean_processing_ms: 1.6814583342538987
  time_since_restore: 3410.127274751663
  time_this_iter_s: 60.04689335823059
  time_total_s: 3410.127274751663
  timestamp: 1585078363
  timesteps_since_restore: 560000
  timesteps_this_iter: 10000
  timesteps_total: 560000
  training_iteration: 56
  trial_id: 44d516d6
  
[2m[36m(pid=143796)[0m 2020-03-24 15:32:43,083	WARNING ppo.py:121 -- The magnitude of your environment rewards are more than 365.0x the scale of `vf_clip_param`. This means that it will take more than 365.0 iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2/2 CPUs, 0/0 GPUs
Memory usage on this node: 12.1/201.2 GB
Result logdir: /users/PYS1027/chnrhughes/ray_results/simple_training_example_ring_v1
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - PPO_WaveAttenuationPOEnv-v0_0:	RUNNING, [2 CPUs, 0 GPUs], [pid=143796], 3410 s, 56 iter, 560000 ts, 3.65e+03 rew

[2m[36m(pid=143797)[0m 
[2m[36m(pid=143797)[0m -----------------------
[2m[36m(pid=143797)[0m ring length: 490
[2m[36m(pid=143797)[0m v_max: 12.201610748825663
[2m[36m(pid=143797)[0m -----------------------
[2m[36m(pid=143797)[0m 
[2m[36m(pid=143797)[0m -----------------------
[2m[36m(pid=143797)[0m ring length: 510
[2m[36m(pid=143797)[0m v_max: 12.93502796218664
[2m[36m(pid=143797)[0m -----------------------
[2m[36m(pid=143797)[0m 
[2m[36m(pid=143797)[0m -----------------------
[2m[36m(pid=143797)[0m ring length: 516
[2m[36m(pid=143797)[0m v_max: 13.152137487657606
[2m[36m(pid=143797)[0m -----------------------
[2m[36m(pid=143797)[0m 
[2m[36m(pid=143797)[0m -----------------------
[2m[36m(pid=143797)[0m ring length: 515
[2m[36m(pid=143797)[0m v_max: 13.116050918675148
[2m[36m(pid=143797)[0m -----------------------
[2m[36m(pid=143797)[0m 
[2m[36m(pid=143797)[0m -----------------------
[2m[36m(pid=143797)[0m ring length: 499
[2m[36m(pid=143797)[0m v_max: 12.533432536501882
[2m[36m(pid=143797)[0m -----------------------
Result for PPO_WaveAttenuationPOEnv-v0_0:
  custom_metrics: {}
  date: 2020-03-24_15-33-43
  done: false
  episode_len_mean: 2000.0
  episode_reward_max: 4381.806995637801
  episode_reward_mean: 3698.3783477426045
  episode_reward_min: 2515.787144917711
  episodes_this_iter: 5
  episodes_total: 285
  experiment_id: 3169a4f824ed4a02b4b42d55753086c5
  hostname: p0056.ten.osc.edu
  info:
    grad_time_ms: 213.536
    learner:
      default_policy:
        cur_kl_coeff: 1.1102230411687688e-17
        cur_lr: 4.999999873689376e-05
        entropy: 0.22760751843452454
        entropy_coeff: 0.0
        kl: 0.001132044824771583
        policy_loss: -0.0006102529587224126
        total_loss: 3411.751220703125
        vf_explained_var: 5.125999450683594e-06
        vf_loss: 3411.751953125
    load_time_ms: 1.999
    num_steps_sampled: 570000
    num_steps_trained: 570000
    sample_time_ms: 60356.49
    update_time_ms: 1.925
  iterations_since_restore: 57
  node_ip: 10.4.1.55
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 2.6767441860465118
    ram_util_percent: 6.0
  pid: 143796
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 3.846818647439613
    mean_inference_ms: 0.5234227858664235
    mean_processing_ms: 1.6814714512869033
  time_since_restore: 3470.686422109604
  time_this_iter_s: 60.559147357940674
  time_total_s: 3470.686422109604
  timestamp: 1585078423
  timesteps_since_restore: 570000
  timesteps_this_iter: 10000
  timesteps_total: 570000
  training_iteration: 57
  trial_id: 44d516d6
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2/2 CPUs, 0/0 GPUs
Memory usage on this node: 12.1/201.2 GB
Result logdir: /users/PYS1027/chnrhughes/ray_results/simple_training_example_ring_v1
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - PPO_WaveAttenuationPOEnv-v0_0:	RUNNING, [2 CPUs, 0 GPUs], [pid=143796], 3470 s, 57 iter, 570000 ts, 3.7e+03 rew

[2m[36m(pid=143796)[0m 2020-03-24 15:33:43,669	WARNING ppo.py:121 -- The magnitude of your environment rewards are more than 370.0x the scale of `vf_clip_param`. This means that it will take more than 370.0 iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.
[2m[36m(pid=143797)[0m 
[2m[36m(pid=143797)[0m -----------------------
[2m[36m(pid=143797)[0m ring length: 499
[2m[36m(pid=143797)[0m v_max: 12.533432536501882
[2m[36m(pid=143797)[0m -----------------------
[2m[36m(pid=143797)[0m 
[2m[36m(pid=143797)[0m -----------------------
[2m[36m(pid=143797)[0m ring length: 507
[2m[36m(pid=143797)[0m v_max: 12.825950528689797
[2m[36m(pid=143797)[0m -----------------------
[2m[36m(pid=143797)[0m 
[2m[36m(pid=143797)[0m -----------------------
[2m[36m(pid=143797)[0m ring length: 494
[2m[36m(pid=143797)[0m v_max: 12.34943486433356
[2m[36m(pid=143797)[0m -----------------------
[2m[36m(pid=143797)[0m 
[2m[36m(pid=143797)[0m -----------------------
[2m[36m(pid=143797)[0m ring length: 491
[2m[36m(pid=143797)[0m v_max: 12.238617992673053
[2m[36m(pid=143797)[0m -----------------------
[2m[36m(pid=143797)[0m 
[2m[36m(pid=143797)[0m -----------------------
[2m[36m(pid=143797)[0m ring length: 516
[2m[36m(pid=143797)[0m v_max: 13.152137487657606
[2m[36m(pid=143797)[0m -----------------------
Result for PPO_WaveAttenuationPOEnv-v0_0:
  custom_metrics: {}
  date: 2020-03-24_15-34-44
  done: false
  episode_len_mean: 2000.0
  episode_reward_max: 4381.806995637801
  episode_reward_mean: 3734.1432451451055
  episode_reward_min: 2515.787144917711
  episodes_this_iter: 5
  episodes_total: 290
  experiment_id: 3169a4f824ed4a02b4b42d55753086c5
  hostname: p0056.ten.osc.edu
  info:
    grad_time_ms: 212.737
    learner:
      default_policy:
        cur_kl_coeff: 5.551115205843844e-18
        cur_lr: 4.999999873689376e-05
        entropy: 0.21633215248584747
        entropy_coeff: 0.0
        kl: 0.0017988441977649927
        policy_loss: -0.00038287925417535007
        total_loss: 3255.576171875
        vf_explained_var: 5.066394805908203e-06
        vf_loss: 3255.576416015625
    load_time_ms: 1.948
    num_steps_sampled: 580000
    num_steps_trained: 580000
    sample_time_ms: 60386.074
    update_time_ms: 1.934
  iterations_since_restore: 58
  node_ip: 10.4.1.55
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 2.7206896551724133
    ram_util_percent: 6.0
  pid: 143796
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 3.8465245208078533
    mean_inference_ms: 0.522647730589345
    mean_processing_ms: 1.6814951524406134
  time_since_restore: 3531.400245666504
  time_this_iter_s: 60.713823556900024
  time_total_s: 3531.400245666504
  timestamp: 1585078484
  timesteps_since_restore: 580000
  timesteps_this_iter: 10000
  timesteps_total: 580000
  training_iteration: 58
  trial_id: 44d516d6
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2/2 CPUs, 0/0 GPUs
Memory usage on this node: 12.1/201.2 GB
Result logdir: /users/PYS1027/chnrhughes/ray_results/simple_training_example_ring_v1
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - PPO_WaveAttenuationPOEnv-v0_0:	RUNNING, [2 CPUs, 0 GPUs], [pid=143796], 3531 s, 58 iter, 580000 ts, 3.73e+03 rew

[2m[36m(pid=143796)[0m 2020-03-24 15:34:44,393	WARNING ppo.py:121 -- The magnitude of your environment rewards are more than 373.0x the scale of `vf_clip_param`. This means that it will take more than 373.0 iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.
[2m[36m(pid=143797)[0m 
[2m[36m(pid=143797)[0m -----------------------
[2m[36m(pid=143797)[0m ring length: 496
[2m[36m(pid=143797)[0m v_max: 12.423139687457347
[2m[36m(pid=143797)[0m -----------------------
[2m[36m(pid=143797)[0m 
[2m[36m(pid=143797)[0m -----------------------
[2m[36m(pid=143797)[0m ring length: 511
[2m[36m(pid=143797)[0m v_max: 12.97131045565535
[2m[36m(pid=143797)[0m -----------------------
[2m[36m(pid=143797)[0m 
[2m[36m(pid=143797)[0m -----------------------
[2m[36m(pid=143797)[0m ring length: 495
[2m[36m(pid=143797)[0m v_max: 12.386304743340318
[2m[36m(pid=143797)[0m -----------------------
[2m[36m(pid=143797)[0m 
[2m[36m(pid=143797)[0m -----------------------
[2m[36m(pid=143797)[0m ring length: 514
[2m[36m(pid=143797)[0m v_max: 13.079924697543293
[2m[36m(pid=143797)[0m -----------------------
[2m[36m(pid=143797)[0m 
[2m[36m(pid=143797)[0m -----------------------
[2m[36m(pid=143797)[0m ring length: 511
[2m[36m(pid=143797)[0m v_max: 12.97131045565535
[2m[36m(pid=143797)[0m -----------------------
Result for PPO_WaveAttenuationPOEnv-v0_0:
  custom_metrics: {}
  date: 2020-03-24_15-35-44
  done: false
  episode_len_mean: 2000.0
  episode_reward_max: 4411.263926556506
  episode_reward_mean: 3799.303725957651
  episode_reward_min: 2515.787144917711
  episodes_this_iter: 5
  episodes_total: 295
  experiment_id: 3169a4f824ed4a02b4b42d55753086c5
  hostname: p0056.ten.osc.edu
  info:
    grad_time_ms: 212.137
    learner:
      default_policy:
        cur_kl_coeff: 2.775557602921922e-18
        cur_lr: 4.999999873689376e-05
        entropy: 0.20698486268520355
        entropy_coeff: 0.0
        kl: 0.0013415508437901735
        policy_loss: -0.00020116253290325403
        total_loss: 3585.5751953125
        vf_explained_var: 5.543231964111328e-06
        vf_loss: 3585.5751953125
    load_time_ms: 1.936
    num_steps_sampled: 590000
    num_steps_trained: 590000
    sample_time_ms: 60360.187
    update_time_ms: 1.934
  iterations_since_restore: 59
  node_ip: 10.4.1.55
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 2.669767441860465
    ram_util_percent: 5.995348837209303
  pid: 143796
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 3.8463039099820717
    mean_inference_ms: 0.521884627955349
    mean_processing_ms: 1.6815182383686902
  time_since_restore: 3591.975203514099
  time_this_iter_s: 60.574957847595215
  time_total_s: 3591.975203514099
  timestamp: 1585078544
  timesteps_since_restore: 590000
  timesteps_this_iter: 10000
  timesteps_total: 590000
  training_iteration: 59
  trial_id: 44d516d6
  
[2m[36m(pid=143796)[0m 2020-03-24 15:35:44,977	WARNING ppo.py:121 -- The magnitude of your environment rewards are more than 380.0x the scale of `vf_clip_param`. This means that it will take more than 380.0 iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.
2020-03-24 15:35:45,410	WARNING util.py:145 -- The `experiment_checkpoint` operation took 0.42359066009521484 seconds to complete, which may be a performance bottleneck.
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2/2 CPUs, 0/0 GPUs
Memory usage on this node: 11.2/201.2 GB
Result logdir: /users/PYS1027/chnrhughes/ray_results/simple_training_example_ring_v1
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - PPO_WaveAttenuationPOEnv-v0_0:	RUNNING, [2 CPUs, 0 GPUs], [pid=143796], 3591 s, 59 iter, 590000 ts, 3.8e+03 rew

[2m[36m(pid=143797)[0m 
[2m[36m(pid=143797)[0m -----------------------
[2m[36m(pid=143797)[0m ring length: 513
[2m[36m(pid=143797)[0m v_max: 13.043759057511211
[2m[36m(pid=143797)[0m -----------------------
