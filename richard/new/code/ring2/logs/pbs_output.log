['Network', 'BayBridgeNetwork', 'BayBridgeTollNetwork', 'BottleneckNetwork', 'FigureEightNetwork', 'TrafficLightGridNetwork', 'HighwayNetwork', 'RingNetwork', 'MergeNetwork', 'MultiRingNetwork', 'MiniCityNetwork', 'HighwayRampsNetwork']
['Env', 'AccelEnv', 'LaneChangeAccelEnv', 'LaneChangeAccelPOEnv', 'TrafficLightGridTestEnv', 'MergePOEnv', 'BottleneckEnv', 'BottleneckAccelEnv', 'WaveAttenuationEnv', 'WaveAttenuationPOEnv', 'TrafficLightGridEnv', 'TrafficLightGridPOEnv', 'BottleneckDesiredVelocityEnv', 'TestEnv', 'BayBridgeEnv', 'BottleNeckAccelEnv', 'DesiredVelocityEnv', 'PO_TrafficLightGridEnv', 'GreenWaveTestEnv']
WARNING:tensorflow:From /users/PYS1027/chnrhughes/.local/lib/python3.5/site-packages/tensorflow/python/compat/v2_compat.py:61: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.
Instructions for updating:
non-resource variables are not supported in the long term
2020-03-30 08:14:20,267	INFO node.py:498 -- Process STDOUT and STDERR is being redirected to /tmp/ray/session_2020-03-30_08-14-20_267304_385467/logs.
2020-03-30 08:14:20,390	INFO services.py:409 -- Waiting for redis server at 127.0.0.1:27934 to respond...
2020-03-30 08:14:21,145	INFO services.py:409 -- Waiting for redis server at 127.0.0.1:36244 to respond...
2020-03-30 08:14:21,145	INFO services.py:809 -- Starting Redis shard with 10.0 GB max memory.
2020-03-30 08:14:21,178	INFO node.py:512 -- Process STDOUT and STDERR is being redirected to /tmp/ray/session_2020-03-30_08-14-20_267304_385467/logs.
2020-03-30 08:14:21,179	WARNING services.py:1301 -- Warning: Capping object memory store to 20.0GB. To increase this further, specify `object_store_memory` when calling ray.init() or ray start.
2020-03-30 08:14:21,179	INFO services.py:1475 -- Starting the Plasma object store with 20.0 GB memory using /dev/shm.
2020-03-30 08:14:21,758	INFO trial_runner.py:176 -- Starting a new experiment.
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 0/2 CPUs, 0/0 GPUs
Memory usage on this node: 10.3/201.2 GB

2020-03-30 08:14:21,764	WARNING signature.py:108 -- The function with_updates has a **kwargs argument, which is currently not supported.
WARNING:tensorflow:From /users/PYS1027/chnrhughes/.local/lib/python3.5/site-packages/ray/tune/logger.py:133: The name tf.VERSION is deprecated. Please use tf.version.VERSION instead.

WARNING:tensorflow:From /users/PYS1027/chnrhughes/.local/lib/python3.5/site-packages/ray/tune/logger.py:138: The name tf.summary.FileWriter is deprecated. Please use tf.compat.v1.summary.FileWriter instead.

2020-03-30 08:14:21,802	ERROR log_sync.py:34 -- Log sync requires cluster to be setup with `ray up`.
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2/2 CPUs, 0/0 GPUs
Memory usage on this node: 10.3/201.2 GB
Result logdir: /users/PYS1027/chnrhughes/ray_results/simple_training_example_ring2_v1
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - PPO_WaveAttenuationPOEnv-v0_0:	RUNNING

[2m[36m(pid=385820)[0m WARNING:tensorflow:From /users/PYS1027/chnrhughes/.local/lib/python3.5/site-packages/tensorflow/python/compat/v2_compat.py:61: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.
[2m[36m(pid=385820)[0m Instructions for updating:
[2m[36m(pid=385820)[0m non-resource variables are not supported in the long term
[2m[36m(pid=385820)[0m 2020-03-30 08:14:26,530	WARNING ppo.py:143 -- FYI: By default, the value function will not share layers with the policy model ('vf_share_layers': False).
[2m[36m(pid=385820)[0m 2020-03-30 08:14:28,366	INFO rollout_worker.py:319 -- Creating policy evaluation worker 0 on CPU (please ignore any CUDA init errors)
[2m[36m(pid=385820)[0m 2020-03-30 08:14:28.367092: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
[2m[36m(pid=385820)[0m 2020-03-30 08:14:28.377286: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2400000000 Hz
[2m[36m(pid=385820)[0m 2020-03-30 08:14:28.379024: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x6f3b830 executing computations on platform Host. Devices:
[2m[36m(pid=385820)[0m 2020-03-30 08:14:28.379058: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
[2m[36m(pid=385820)[0m WARNING:tensorflow:From /users/PYS1027/chnrhughes/.local/lib/python3.5/site-packages/ray/rllib/models/tf/fcnet_v1.py:48: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.
[2m[36m(pid=385820)[0m Instructions for updating:
[2m[36m(pid=385820)[0m Use keras.layers.dense instead.
[2m[36m(pid=385820)[0m WARNING:tensorflow:From /users/PYS1027/chnrhughes/.local/lib/python3.5/site-packages/ray/rllib/models/tf/fcnet_v1.py:48: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.
[2m[36m(pid=385820)[0m Instructions for updating:
[2m[36m(pid=385820)[0m Use keras.layers.dense instead.
[2m[36m(pid=385820)[0m WARNING:tensorflow:From /users/PYS1027/chnrhughes/.local/lib/python3.5/site-packages/ray/rllib/models/tf/tf_action_dist.py:138: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
[2m[36m(pid=385820)[0m Instructions for updating:
[2m[36m(pid=385820)[0m Use `tf.cast` instead.
[2m[36m(pid=385820)[0m WARNING:tensorflow:From /users/PYS1027/chnrhughes/.local/lib/python3.5/site-packages/ray/rllib/models/tf/tf_action_dist.py:138: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
[2m[36m(pid=385820)[0m Instructions for updating:
[2m[36m(pid=385820)[0m Use `tf.cast` instead.
[2m[36m(pid=385820)[0m 2020-03-30 08:14:28.885345: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1412] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.
[2m[36m(pid=385820)[0m 2020-03-30 08:14:28,962	INFO dynamic_tf_policy.py:324 -- Initializing loss function with dummy input:
[2m[36m(pid=385820)[0m 
[2m[36m(pid=385820)[0m { 'action_prob': <tf.Tensor 'default_policy/action_prob:0' shape=(?,) dtype=float32>,
[2m[36m(pid=385820)[0m   'actions': <tf.Tensor 'default_policy/actions:0' shape=(?, 1) dtype=float32>,
[2m[36m(pid=385820)[0m   'advantages': <tf.Tensor 'default_policy/advantages:0' shape=(?,) dtype=float32>,
[2m[36m(pid=385820)[0m   'behaviour_logits': <tf.Tensor 'default_policy/behaviour_logits:0' shape=(?, 2) dtype=float32>,
[2m[36m(pid=385820)[0m   'dones': <tf.Tensor 'default_policy/dones:0' shape=(?,) dtype=bool>,
[2m[36m(pid=385820)[0m   'new_obs': <tf.Tensor 'default_policy/new_obs:0' shape=(?, 3) dtype=float32>,
[2m[36m(pid=385820)[0m   'obs': <tf.Tensor 'default_policy/observation:0' shape=(?, 3) dtype=float32>,
[2m[36m(pid=385820)[0m   'prev_actions': <tf.Tensor 'default_policy/action:0' shape=(?, 1) dtype=float32>,
[2m[36m(pid=385820)[0m   'prev_rewards': <tf.Tensor 'default_policy/prev_reward:0' shape=(?,) dtype=float32>,
[2m[36m(pid=385820)[0m   'rewards': <tf.Tensor 'default_policy/rewards:0' shape=(?,) dtype=float32>,
[2m[36m(pid=385820)[0m   'value_targets': <tf.Tensor 'default_policy/value_targets:0' shape=(?,) dtype=float32>,
[2m[36m(pid=385820)[0m   'vf_preds': <tf.Tensor 'default_policy/vf_preds:0' shape=(?,) dtype=float32>}
[2m[36m(pid=385820)[0m 
[2m[36m(pid=385820)[0m WARNING:tensorflow:From /users/PYS1027/chnrhughes/.local/lib/python3.5/site-packages/tensorflow/python/ops/array_ops.py:1354: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
[2m[36m(pid=385820)[0m Instructions for updating:
[2m[36m(pid=385820)[0m Use tf.where in 2.0, which has the same broadcast rule as np.where
[2m[36m(pid=385820)[0m WARNING:tensorflow:From /users/PYS1027/chnrhughes/.local/lib/python3.5/site-packages/tensorflow/python/ops/array_ops.py:1354: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
[2m[36m(pid=385820)[0m Instructions for updating:
[2m[36m(pid=385820)[0m Use tf.where in 2.0, which has the same broadcast rule as np.where
[2m[36m(pid=385820)[0m 2020-03-30 08:14:29,769	INFO rollout_worker.py:742 -- Built policy map: {'default_policy': <ray.rllib.policy.tf_policy_template.PPOTFPolicy object at 0x2b3b4af203c8>}
[2m[36m(pid=385820)[0m 2020-03-30 08:14:29,770	INFO rollout_worker.py:743 -- Built preprocessor map: {'default_policy': <ray.rllib.models.preprocessors.NoPreprocessor object at 0x2b3b4af202e8>}
[2m[36m(pid=385820)[0m 2020-03-30 08:14:29,770	INFO rollout_worker.py:356 -- Built filter map: {'default_policy': <ray.rllib.utils.filter.NoFilter object at 0x2b3b4af20198>}
[2m[36m(pid=385820)[0m 2020-03-30 08:14:29,799	INFO multi_gpu_optimizer.py:93 -- LocalMultiGPUOptimizer devices ['/cpu:0']
[2m[36m(pid=385820)[0m 2020-03-30 08:14:32,186	WARNING util.py:47 -- Install gputil for GPU system monitoring.
[2m[36m(pid=385820)[0m WARNING:tensorflow:From /users/PYS1027/chnrhughes/.local/lib/python3.5/site-packages/ray/rllib/policy/tf_policy.py:570: Variable.load (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
[2m[36m(pid=385820)[0m Instructions for updating:
[2m[36m(pid=385820)[0m Prefer Variable.assign which has equivalent behavior in 2.X.
[2m[36m(pid=385820)[0m WARNING:tensorflow:From /users/PYS1027/chnrhughes/.local/lib/python3.5/site-packages/ray/rllib/policy/tf_policy.py:570: Variable.load (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
[2m[36m(pid=385820)[0m Instructions for updating:
[2m[36m(pid=385820)[0m Prefer Variable.assign which has equivalent behavior in 2.X.
[2m[36m(pid=385821)[0m WARNING:tensorflow:From /users/PYS1027/chnrhughes/.local/lib/python3.5/site-packages/tensorflow/python/compat/v2_compat.py:61: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.
[2m[36m(pid=385821)[0m Instructions for updating:
[2m[36m(pid=385821)[0m non-resource variables are not supported in the long term
[2m[36m(pid=385821)[0m 2020-03-30 08:14:35,430	INFO rollout_worker.py:319 -- Creating policy evaluation worker 1 on CPU (please ignore any CUDA init errors)
[2m[36m(pid=385821)[0m 2020-03-30 08:14:35.444381: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
[2m[36m(pid=385821)[0m 2020-03-30 08:14:35.448091: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2400000000 Hz
[2m[36m(pid=385821)[0m 2020-03-30 08:14:35.449685: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x59c29e0 executing computations on platform Host. Devices:
[2m[36m(pid=385821)[0m 2020-03-30 08:14:35.449720: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
[2m[36m(pid=385821)[0m WARNING:tensorflow:From /users/PYS1027/chnrhughes/.local/lib/python3.5/site-packages/ray/rllib/models/tf/fcnet_v1.py:48: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.
[2m[36m(pid=385821)[0m Instructions for updating:
[2m[36m(pid=385821)[0m Use keras.layers.dense instead.
[2m[36m(pid=385821)[0m WARNING:tensorflow:From /users/PYS1027/chnrhughes/.local/lib/python3.5/site-packages/ray/rllib/models/tf/fcnet_v1.py:48: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.
[2m[36m(pid=385821)[0m Instructions for updating:
[2m[36m(pid=385821)[0m Use keras.layers.dense instead.
[2m[36m(pid=385821)[0m WARNING:tensorflow:From /users/PYS1027/chnrhughes/.local/lib/python3.5/site-packages/ray/rllib/models/tf/tf_action_dist.py:138: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
[2m[36m(pid=385821)[0m Instructions for updating:
[2m[36m(pid=385821)[0m Use `tf.cast` instead.
[2m[36m(pid=385821)[0m WARNING:tensorflow:From /users/PYS1027/chnrhughes/.local/lib/python3.5/site-packages/ray/rllib/models/tf/tf_action_dist.py:138: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
[2m[36m(pid=385821)[0m Instructions for updating:
[2m[36m(pid=385821)[0m Use `tf.cast` instead.
[2m[36m(pid=385821)[0m 2020-03-30 08:14:35.834559: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1412] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.
[2m[36m(pid=385821)[0m 2020-03-30 08:14:35,850	INFO dynamic_tf_policy.py:324 -- Initializing loss function with dummy input:
[2m[36m(pid=385821)[0m 
[2m[36m(pid=385821)[0m { 'action_prob': <tf.Tensor 'default_policy/action_prob:0' shape=(?,) dtype=float32>,
[2m[36m(pid=385821)[0m   'actions': <tf.Tensor 'default_policy/actions:0' shape=(?, 1) dtype=float32>,
[2m[36m(pid=385821)[0m   'advantages': <tf.Tensor 'default_policy/advantages:0' shape=(?,) dtype=float32>,
[2m[36m(pid=385821)[0m   'behaviour_logits': <tf.Tensor 'default_policy/behaviour_logits:0' shape=(?, 2) dtype=float32>,
[2m[36m(pid=385821)[0m   'dones': <tf.Tensor 'default_policy/dones:0' shape=(?,) dtype=bool>,
[2m[36m(pid=385821)[0m   'new_obs': <tf.Tensor 'default_policy/new_obs:0' shape=(?, 3) dtype=float32>,
[2m[36m(pid=385821)[0m   'obs': <tf.Tensor 'default_policy/observation:0' shape=(?, 3) dtype=float32>,
[2m[36m(pid=385821)[0m   'prev_actions': <tf.Tensor 'default_policy/action:0' shape=(?, 1) dtype=float32>,
[2m[36m(pid=385821)[0m   'prev_rewards': <tf.Tensor 'default_policy/prev_reward:0' shape=(?,) dtype=float32>,
[2m[36m(pid=385821)[0m   'rewards': <tf.Tensor 'default_policy/rewards:0' shape=(?,) dtype=float32>,
[2m[36m(pid=385821)[0m   'value_targets': <tf.Tensor 'default_policy/value_targets:0' shape=(?,) dtype=float32>,
[2m[36m(pid=385821)[0m   'vf_preds': <tf.Tensor 'default_policy/vf_preds:0' shape=(?,) dtype=float32>}
[2m[36m(pid=385821)[0m 
[2m[36m(pid=385821)[0m WARNING:tensorflow:From /users/PYS1027/chnrhughes/.local/lib/python3.5/site-packages/tensorflow/python/ops/array_ops.py:1354: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
[2m[36m(pid=385821)[0m Instructions for updating:
[2m[36m(pid=385821)[0m Use tf.where in 2.0, which has the same broadcast rule as np.where
[2m[36m(pid=385821)[0m WARNING:tensorflow:From /users/PYS1027/chnrhughes/.local/lib/python3.5/site-packages/tensorflow/python/ops/array_ops.py:1354: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
[2m[36m(pid=385821)[0m Instructions for updating:
[2m[36m(pid=385821)[0m Use tf.where in 2.0, which has the same broadcast rule as np.where
[2m[36m(pid=385821)[0m WARNING:tensorflow:From /users/PYS1027/chnrhughes/.local/lib/python3.5/site-packages/ray/rllib/policy/tf_policy.py:570: Variable.load (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
[2m[36m(pid=385821)[0m Instructions for updating:
[2m[36m(pid=385821)[0m Prefer Variable.assign which has equivalent behavior in 2.X.
[2m[36m(pid=385821)[0m WARNING:tensorflow:From /users/PYS1027/chnrhughes/.local/lib/python3.5/site-packages/ray/rllib/policy/tf_policy.py:570: Variable.load (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
[2m[36m(pid=385821)[0m Instructions for updating:
[2m[36m(pid=385821)[0m Prefer Variable.assign which has equivalent behavior in 2.X.
[2m[36m(pid=385821)[0m 
[2m[36m(pid=385821)[0m -----------------------
[2m[36m(pid=385821)[0m ring length: 491
[2m[36m(pid=385821)[0m v_max: 2.719840556029452
[2m[36m(pid=385821)[0m -----------------------
[2m[36m(pid=385821)[0m 2020-03-30 08:14:36,656	INFO rollout_worker.py:451 -- Generating sample batch of size 200
[2m[36m(pid=385821)[0m 2020-03-30 08:14:41,663	INFO sampler.py:304 -- Raw obs from env: { 0: { 'agent0': np.ndarray((3,), dtype=float64, min=-0.01, max=0.737, mean=0.254)}}
[2m[36m(pid=385821)[0m 2020-03-30 08:14:41,663	INFO sampler.py:305 -- Info return from env: {0: {'agent0': None}}
[2m[36m(pid=385821)[0m 2020-03-30 08:14:41,664	INFO sampler.py:403 -- Preprocessed obs: np.ndarray((3,), dtype=float64, min=-0.01, max=0.737, mean=0.254)
[2m[36m(pid=385821)[0m 2020-03-30 08:14:41,664	INFO sampler.py:407 -- Filtered obs: np.ndarray((3,), dtype=float64, min=-0.01, max=0.737, mean=0.254)
[2m[36m(pid=385821)[0m 2020-03-30 08:14:41,665	INFO sampler.py:521 -- Inputs to compute_actions():
[2m[36m(pid=385821)[0m 
[2m[36m(pid=385821)[0m { 'default_policy': [ { 'data': { 'agent_id': 'agent0',
[2m[36m(pid=385821)[0m                                   'env_id': 0,
[2m[36m(pid=385821)[0m                                   'info': None,
[2m[36m(pid=385821)[0m                                   'obs': np.ndarray((3,), dtype=float64, min=-0.01, max=0.737, mean=0.254),
[2m[36m(pid=385821)[0m                                   'prev_action': np.ndarray((1,), dtype=float32, min=0.0, max=0.0, mean=0.0),
[2m[36m(pid=385821)[0m                                   'prev_reward': 0.0,
[2m[36m(pid=385821)[0m                                   'rnn_state': []},
[2m[36m(pid=385821)[0m                         'type': 'PolicyEvalData'}]}
[2m[36m(pid=385821)[0m 
[2m[36m(pid=385821)[0m 2020-03-30 08:14:41,665	INFO tf_run_builder.py:92 -- Executing TF run without tracing. To dump TF timeline traces to disk, set the TF_TIMELINE_DIR environment variable.
[2m[36m(pid=385821)[0m 2020-03-30 08:14:41,741	INFO sampler.py:548 -- Outputs of compute_actions():
[2m[36m(pid=385821)[0m 
[2m[36m(pid=385821)[0m { 'default_policy': ( np.ndarray((1, 1), dtype=float32, min=-1.481, max=-1.481, mean=-1.481),
[2m[36m(pid=385821)[0m                       [],
[2m[36m(pid=385821)[0m                       { 'action_prob': np.ndarray((1,), dtype=float32, min=0.133, max=0.133, mean=0.133),
[2m[36m(pid=385821)[0m                         'behaviour_logits': np.ndarray((1, 2), dtype=float32, min=0.001, max=0.002, mean=0.001),
[2m[36m(pid=385821)[0m                         'vf_preds': np.ndarray((1,), dtype=float32, min=-0.001, max=-0.001, mean=-0.001)})}
[2m[36m(pid=385821)[0m 
[2m[36m(pid=385821)[0m 2020-03-30 08:14:43,096	INFO sample_batch_builder.py:161 -- Trajectory fragment after postprocess_trajectory():
[2m[36m(pid=385821)[0m 
[2m[36m(pid=385821)[0m { 'agent0': { 'data': { 'action_prob': np.ndarray((200,), dtype=float32, min=0.01, max=0.399, mean=0.287),
[2m[36m(pid=385821)[0m                         'actions': np.ndarray((200, 1), dtype=float32, min=-2.656, max=2.733, mean=0.017),
[2m[36m(pid=385821)[0m                         'advantages': np.ndarray((200,), dtype=float32, min=-19.213, max=6.871, mean=-3.666),
[2m[36m(pid=385821)[0m                         'agent_index': np.ndarray((200,), dtype=int64, min=0.0, max=0.0, mean=0.0),
[2m[36m(pid=385821)[0m                         'behaviour_logits': np.ndarray((200, 2), dtype=float32, min=0.001, max=0.002, mean=0.001),
[2m[36m(pid=385821)[0m                         'dones': np.ndarray((200,), dtype=bool, min=0.0, max=0.0, mean=0.0),
[2m[36m(pid=385821)[0m                         'eps_id': np.ndarray((200,), dtype=int64, min=526040580.0, max=526040580.0, mean=526040580.0),
[2m[36m(pid=385821)[0m                         'infos': np.ndarray((200,), dtype=object, head={}),
[2m[36m(pid=385821)[0m                         'new_obs': np.ndarray((200, 3), dtype=float32, min=-0.007, max=0.731, mean=0.272),
[2m[36m(pid=385821)[0m                         'obs': np.ndarray((200, 3), dtype=float32, min=-0.01, max=0.737, mean=0.272),
[2m[36m(pid=385821)[0m                         'prev_actions': np.ndarray((200, 1), dtype=float32, min=-2.656, max=2.733, mean=0.019),
[2m[36m(pid=385821)[0m                         'prev_rewards': np.ndarray((200,), dtype=float32, min=-1.664, max=2.39, mean=-0.147),
[2m[36m(pid=385821)[0m                         'rewards': np.ndarray((200,), dtype=float32, min=-1.664, max=2.39, mean=-0.14),
[2m[36m(pid=385821)[0m                         't': np.ndarray((200,), dtype=int64, min=0.0, max=199.0, mean=99.5),
[2m[36m(pid=385821)[0m                         'unroll_id': np.ndarray((200,), dtype=int64, min=0.0, max=0.0, mean=0.0),
[2m[36m(pid=385821)[0m                         'value_targets': np.ndarray((200,), dtype=float32, min=-19.215, max=6.87, mean=-3.668),
[2m[36m(pid=385821)[0m                         'vf_preds': np.ndarray((200,), dtype=float32, min=-0.002, max=-0.001, mean=-0.001)},
[2m[36m(pid=385821)[0m               'type': 'SampleBatch'}}
[2m[36m(pid=385821)[0m 
[2m[36m(pid=385821)[0m 2020-03-30 08:14:43,098	INFO rollout_worker.py:485 -- Completed sample batch:
[2m[36m(pid=385821)[0m 
[2m[36m(pid=385821)[0m { 'data': { 'action_prob': np.ndarray((200,), dtype=float32, min=0.01, max=0.399, mean=0.287),
[2m[36m(pid=385821)[0m             'actions': np.ndarray((200, 1), dtype=float32, min=-2.656, max=2.733, mean=0.017),
[2m[36m(pid=385821)[0m             'advantages': np.ndarray((200,), dtype=float32, min=-19.213, max=6.871, mean=-3.666),
[2m[36m(pid=385821)[0m             'agent_index': np.ndarray((200,), dtype=int64, min=0.0, max=0.0, mean=0.0),
[2m[36m(pid=385821)[0m             'behaviour_logits': np.ndarray((200, 2), dtype=float32, min=0.001, max=0.002, mean=0.001),
[2m[36m(pid=385821)[0m             'dones': np.ndarray((200,), dtype=bool, min=0.0, max=0.0, mean=0.0),
[2m[36m(pid=385821)[0m             'eps_id': np.ndarray((200,), dtype=int64, min=526040580.0, max=526040580.0, mean=526040580.0),
[2m[36m(pid=385821)[0m             'infos': np.ndarray((200,), dtype=object, head={}),
[2m[36m(pid=385821)[0m             'new_obs': np.ndarray((200, 3), dtype=float32, min=-0.007, max=0.731, mean=0.272),
[2m[36m(pid=385821)[0m             'obs': np.ndarray((200, 3), dtype=float32, min=-0.01, max=0.737, mean=0.272),
[2m[36m(pid=385821)[0m             'prev_actions': np.ndarray((200, 1), dtype=float32, min=-2.656, max=2.733, mean=0.019),
[2m[36m(pid=385821)[0m             'prev_rewards': np.ndarray((200,), dtype=float32, min=-1.664, max=2.39, mean=-0.147),
[2m[36m(pid=385821)[0m             'rewards': np.ndarray((200,), dtype=float32, min=-1.664, max=2.39, mean=-0.14),
[2m[36m(pid=385821)[0m             't': np.ndarray((200,), dtype=int64, min=0.0, max=199.0, mean=99.5),
[2m[36m(pid=385821)[0m             'unroll_id': np.ndarray((200,), dtype=int64, min=0.0, max=0.0, mean=0.0),
[2m[36m(pid=385821)[0m             'value_targets': np.ndarray((200,), dtype=float32, min=-19.215, max=6.87, mean=-3.668),
[2m[36m(pid=385821)[0m             'vf_preds': np.ndarray((200,), dtype=float32, min=-0.002, max=-0.001, mean=-0.001)},
[2m[36m(pid=385821)[0m   'type': 'SampleBatch'}
[2m[36m(pid=385821)[0m 
[2m[36m(pid=385821)[0m 
[2m[36m(pid=385821)[0m -----------------------
[2m[36m(pid=385821)[0m ring length: 506
[2m[36m(pid=385821)[0m v_max: 3.0197423207835943
[2m[36m(pid=385821)[0m -----------------------
[2m[36m(pid=385821)[0m 
[2m[36m(pid=385821)[0m -----------------------
[2m[36m(pid=385821)[0m ring length: 505
[2m[36m(pid=385821)[0m v_max: 2.999750077051092
[2m[36m(pid=385821)[0m -----------------------
[2m[36m(pid=385821)[0m 
[2m[36m(pid=385821)[0m -----------------------
[2m[36m(pid=385821)[0m ring length: 509
[2m[36m(pid=385821)[0m v_max: 3.0797178990784078
[2m[36m(pid=385821)[0m -----------------------
[2m[36m(pid=385821)[0m 
[2m[36m(pid=385821)[0m -----------------------
[2m[36m(pid=385821)[0m ring length: 494
[2m[36m(pid=385821)[0m v_max: 2.7798238064662253
[2m[36m(pid=385821)[0m -----------------------
[2m[36m(pid=385821)[0m 
[2m[36m(pid=385821)[0m -----------------------
[2m[36m(pid=385821)[0m ring length: 512
[2m[36m(pid=385821)[0m v_max: 3.139691674719026
[2m[36m(pid=385821)[0m -----------------------
[2m[36m(pid=385820)[0m 2020-03-30 08:16:22,749	INFO tf_policy.py:355 -- Optimizing variable <tf.Variable 'default_policy/default_model/fc1/kernel:0' shape=(3, 32) dtype=float32_ref>
[2m[36m(pid=385820)[0m 2020-03-30 08:16:22,749	INFO tf_policy.py:355 -- Optimizing variable <tf.Variable 'default_policy/default_model/fc1/bias:0' shape=(32,) dtype=float32_ref>
[2m[36m(pid=385820)[0m 2020-03-30 08:16:22,749	INFO tf_policy.py:355 -- Optimizing variable <tf.Variable 'default_policy/default_model/fc2/kernel:0' shape=(32, 32) dtype=float32_ref>
[2m[36m(pid=385820)[0m 2020-03-30 08:16:22,749	INFO tf_policy.py:355 -- Optimizing variable <tf.Variable 'default_policy/default_model/fc2/bias:0' shape=(32,) dtype=float32_ref>
[2m[36m(pid=385820)[0m 2020-03-30 08:16:22,749	INFO tf_policy.py:355 -- Optimizing variable <tf.Variable 'default_policy/default_model/fc3/kernel:0' shape=(32, 32) dtype=float32_ref>
[2m[36m(pid=385820)[0m 2020-03-30 08:16:22,749	INFO tf_policy.py:355 -- Optimizing variable <tf.Variable 'default_policy/default_model/fc3/bias:0' shape=(32,) dtype=float32_ref>
[2m[36m(pid=385820)[0m 2020-03-30 08:16:22,749	INFO tf_policy.py:355 -- Optimizing variable <tf.Variable 'default_policy/default_model/fc_out/kernel:0' shape=(32, 2) dtype=float32_ref>
[2m[36m(pid=385820)[0m 2020-03-30 08:16:22,749	INFO tf_policy.py:355 -- Optimizing variable <tf.Variable 'default_policy/default_model/fc_out/bias:0' shape=(2,) dtype=float32_ref>
[2m[36m(pid=385820)[0m 2020-03-30 08:16:22,749	INFO tf_policy.py:355 -- Optimizing variable <tf.Variable 'default_policy/value_function/fc1/kernel:0' shape=(3, 32) dtype=float32_ref>
[2m[36m(pid=385820)[0m 2020-03-30 08:16:22,749	INFO tf_policy.py:355 -- Optimizing variable <tf.Variable 'default_policy/value_function/fc1/bias:0' shape=(32,) dtype=float32_ref>
[2m[36m(pid=385820)[0m 2020-03-30 08:16:22,749	INFO tf_policy.py:355 -- Optimizing variable <tf.Variable 'default_policy/value_function/fc2/kernel:0' shape=(32, 32) dtype=float32_ref>
[2m[36m(pid=385820)[0m 2020-03-30 08:16:22,749	INFO tf_policy.py:355 -- Optimizing variable <tf.Variable 'default_policy/value_function/fc2/bias:0' shape=(32,) dtype=float32_ref>
[2m[36m(pid=385820)[0m 2020-03-30 08:16:22,749	INFO tf_policy.py:355 -- Optimizing variable <tf.Variable 'default_policy/value_function/fc3/kernel:0' shape=(32, 32) dtype=float32_ref>
[2m[36m(pid=385820)[0m 2020-03-30 08:16:22,749	INFO tf_policy.py:355 -- Optimizing variable <tf.Variable 'default_policy/value_function/fc3/bias:0' shape=(32,) dtype=float32_ref>
[2m[36m(pid=385820)[0m 2020-03-30 08:16:22,749	INFO tf_policy.py:355 -- Optimizing variable <tf.Variable 'default_policy/value_function/fc_out/kernel:0' shape=(32, 1) dtype=float32_ref>
[2m[36m(pid=385820)[0m 2020-03-30 08:16:22,749	INFO tf_policy.py:355 -- Optimizing variable <tf.Variable 'default_policy/value_function/fc_out/bias:0' shape=(1,) dtype=float32_ref>
[2m[36m(pid=385820)[0m 2020-03-30 08:16:22,751	INFO multi_gpu_impl.py:146 -- Training on concatenated sample batches:
[2m[36m(pid=385820)[0m 
[2m[36m(pid=385820)[0m { 'inputs': [ np.ndarray((10000, 1), dtype=float32, min=-3.601, max=3.544, mean=0.002),
[2m[36m(pid=385820)[0m               np.ndarray((10000,), dtype=float32, min=-1.841, max=2.517, mean=-0.137),
[2m[36m(pid=385820)[0m               np.ndarray((10000, 3), dtype=float32, min=-0.209, max=0.935, mean=0.276),
[2m[36m(pid=385820)[0m               np.ndarray((10000, 1), dtype=float32, min=-3.601, max=3.544, mean=0.003),
[2m[36m(pid=385820)[0m               np.ndarray((10000,), dtype=float32, min=-3.873, max=3.322, mean=0.0),
[2m[36m(pid=385820)[0m               np.ndarray((10000, 2), dtype=float32, min=-0.0, max=0.002, mean=0.001),
[2m[36m(pid=385820)[0m               np.ndarray((10000,), dtype=float32, min=-24.006, max=13.727, mean=-3.694),
[2m[36m(pid=385820)[0m               np.ndarray((10000,), dtype=float32, min=-0.003, max=-0.0, mean=-0.001)],
[2m[36m(pid=385820)[0m   'placeholders': [ <tf.Tensor 'default_policy/action:0' shape=(?, 1) dtype=float32>,
[2m[36m(pid=385820)[0m                     <tf.Tensor 'default_policy/prev_reward:0' shape=(?,) dtype=float32>,
[2m[36m(pid=385820)[0m                     <tf.Tensor 'default_policy/observation:0' shape=(?, 3) dtype=float32>,
[2m[36m(pid=385820)[0m                     <tf.Tensor 'default_policy/actions:0' shape=(?, 1) dtype=float32>,
[2m[36m(pid=385820)[0m                     <tf.Tensor 'default_policy/advantages:0' shape=(?,) dtype=float32>,
[2m[36m(pid=385820)[0m                     <tf.Tensor 'default_policy/behaviour_logits:0' shape=(?, 2) dtype=float32>,
[2m[36m(pid=385820)[0m                     <tf.Tensor 'default_policy/value_targets:0' shape=(?,) dtype=float32>,
[2m[36m(pid=385820)[0m                     <tf.Tensor 'default_policy/vf_preds:0' shape=(?,) dtype=float32>],
[2m[36m(pid=385820)[0m   'state_inputs': []}
[2m[36m(pid=385820)[0m 
[2m[36m(pid=385820)[0m 2020-03-30 08:16:22,751	INFO multi_gpu_impl.py:191 -- Divided 10000 rollout sequences, each of length 1, among 1 devices.
Result for PPO_WaveAttenuationPOEnv-v0_0:
  custom_metrics: {}
  date: 2020-03-30_08-16-23
  done: false
  episode_len_mean: 2000.0
  episode_reward_max: -95.89249244209938
  episode_reward_mean: -274.90752548232507
  episode_reward_min: -410.83504028583553
  episodes_this_iter: 5
  episodes_total: 5
  experiment_id: ba0edb931dde48dcb020df4b454540a2
  hostname: p0035.ten.osc.edu
  info:
    grad_time_ms: 678.255
    learner:
      default_policy:
        cur_kl_coeff: 0.20000000298023224
        cur_lr: 4.999999873689376e-05
        entropy: 1.4063726663589478
        entropy_coeff: 0.0
        kl: 0.0008239292073994875
        policy_loss: -0.005507676862180233
        total_loss: 40.97770690917969
        vf_explained_var: -6.35385513305664e-05
        vf_loss: 40.983055114746094
    load_time_ms: 48.98
    num_steps_sampled: 10000
    num_steps_trained: 10000
    sample_time_ms: 110007.322
    update_time_ms: 520.866
  iterations_since_restore: 1
  node_ip: 10.4.1.36
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 2.688050314465409
    ram_util_percent: 5.301257861635219
  pid: 385820
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 7.434430163856173
    mean_inference_ms: 0.5248516228851968
    mean_processing_ms: 2.6339569183340457
  time_since_restore: 111.30771279335022
  time_this_iter_s: 111.30771279335022
  time_total_s: 111.30771279335022
  timestamp: 1585570583
  timesteps_since_restore: 10000
  timesteps_this_iter: 10000
  timesteps_total: 10000
  training_iteration: 1
  trial_id: fce6b7f4
  
WARNING:tensorflow:From /users/PYS1027/chnrhughes/.local/lib/python3.5/site-packages/ray/tune/logger.py:118: The name tf.Summary is deprecated. Please use tf.compat.v1.Summary instead.

== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2/2 CPUs, 0/0 GPUs
Memory usage on this node: 10.8/201.2 GB
Result logdir: /users/PYS1027/chnrhughes/ray_results/simple_training_example_ring2_v1
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - PPO_WaveAttenuationPOEnv-v0_0:	RUNNING, [2 CPUs, 0 GPUs], [pid=385820], 111 s, 1 iter, 10000 ts, -275 rew

[2m[36m(pid=385821)[0m 
[2m[36m(pid=385821)[0m -----------------------
[2m[36m(pid=385821)[0m ring length: 505
[2m[36m(pid=385821)[0m v_max: 2.999750077051092
[2m[36m(pid=385821)[0m -----------------------
[2m[36m(pid=385821)[0m 
[2m[36m(pid=385821)[0m -----------------------
[2m[36m(pid=385821)[0m ring length: 501
[2m[36m(pid=385821)[0m v_max: 2.919779270736568
[2m[36m(pid=385821)[0m -----------------------
[2m[36m(pid=385821)[0m 
[2m[36m(pid=385821)[0m -----------------------
[2m[36m(pid=385821)[0m ring length: 503
[2m[36m(pid=385821)[0m v_max: 2.9597650335315784
[2m[36m(pid=385821)[0m -----------------------
[2m[36m(pid=385821)[0m 
[2m[36m(pid=385821)[0m -----------------------
[2m[36m(pid=385821)[0m ring length: 492
[2m[36m(pid=385821)[0m v_max: 2.739835119766572
[2m[36m(pid=385821)[0m -----------------------
[2m[36m(pid=385821)[0m 
[2m[36m(pid=385821)[0m -----------------------
[2m[36m(pid=385821)[0m ring length: 496
[2m[36m(pid=385821)[0m v_max: 2.819811886031332
[2m[36m(pid=385821)[0m -----------------------
Result for PPO_WaveAttenuationPOEnv-v0_0:
  custom_metrics: {}
  date: 2020-03-30_08-18-04
  done: false
  episode_len_mean: 2000.0
  episode_reward_max: -92.68725641773526
  episode_reward_mean: -240.16301672615236
  episode_reward_min: -410.83504028583553
  episodes_this_iter: 5
  episodes_total: 10
  experiment_id: ba0edb931dde48dcb020df4b454540a2
  hostname: p0035.ten.osc.edu
  info:
    grad_time_ms: 455.843
    learner:
      default_policy:
        cur_kl_coeff: 0.10000000149011612
        cur_lr: 4.999999873689376e-05
        entropy: 1.389931082725525
        entropy_coeff: 0.0
        kl: 0.001418965868651867
        policy_loss: -0.00681211007758975
        total_loss: 44.55014419555664
        vf_explained_var: -0.00018131732940673828
        vf_loss: 44.556819915771484
    load_time_ms: 25.469
    num_steps_sampled: 20000
    num_steps_trained: 20000
    sample_time_ms: 105443.611
    update_time_ms: 261.523
  iterations_since_restore: 2
  node_ip: 10.4.1.36
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 2.6083333333333334
    ram_util_percent: 5.3999999999999995
  pid: 385820
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 7.311688404393098
    mean_inference_ms: 0.5178597360278022
    mean_processing_ms: 2.6341604557304943
  time_since_restore: 212.43076252937317
  time_this_iter_s: 101.12304973602295
  time_total_s: 212.43076252937317
  timestamp: 1585570684
  timesteps_since_restore: 20000
  timesteps_this_iter: 10000
  timesteps_total: 20000
  training_iteration: 2
  trial_id: fce6b7f4
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2/2 CPUs, 0/0 GPUs
Memory usage on this node: 10.8/201.2 GB
Result logdir: /users/PYS1027/chnrhughes/ray_results/simple_training_example_ring2_v1
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - PPO_WaveAttenuationPOEnv-v0_0:	RUNNING, [2 CPUs, 0 GPUs], [pid=385820], 212 s, 2 iter, 20000 ts, -240 rew

[2m[36m(pid=385821)[0m 
[2m[36m(pid=385821)[0m -----------------------
[2m[36m(pid=385821)[0m ring length: 505
[2m[36m(pid=385821)[0m v_max: 2.999750077051092
[2m[36m(pid=385821)[0m -----------------------
[2m[36m(pid=385821)[0m 
[2m[36m(pid=385821)[0m -----------------------
[2m[36m(pid=385821)[0m ring length: 503
[2m[36m(pid=385821)[0m v_max: 2.9597650335315784
[2m[36m(pid=385821)[0m -----------------------
[2m[36m(pid=385821)[0m 
[2m[36m(pid=385821)[0m -----------------------
[2m[36m(pid=385821)[0m ring length: 504
[2m[36m(pid=385821)[0m v_max: 2.979757646850631
[2m[36m(pid=385821)[0m -----------------------
[2m[36m(pid=385821)[0m 
[2m[36m(pid=385821)[0m -----------------------
[2m[36m(pid=385821)[0m ring length: 491
[2m[36m(pid=385821)[0m v_max: 2.719840556029452
[2m[36m(pid=385821)[0m -----------------------
[2m[36m(pid=385821)[0m 
[2m[36m(pid=385821)[0m -----------------------
[2m[36m(pid=385821)[0m ring length: 501
[2m[36m(pid=385821)[0m v_max: 2.919779270736568
[2m[36m(pid=385821)[0m -----------------------
Result for PPO_WaveAttenuationPOEnv-v0_0:
  custom_metrics: {}
  date: 2020-03-30_08-19-45
  done: false
  episode_len_mean: 2000.0
  episode_reward_max: 119.10655523401196
  episode_reward_mean: -186.2060336913489
  episode_reward_min: -410.83504028583553
  episodes_this_iter: 5
  episodes_total: 15
  experiment_id: ba0edb931dde48dcb020df4b454540a2
  hostname: p0035.ten.osc.edu
  info:
    grad_time_ms: 379.305
    learner:
      default_policy:
        cur_kl_coeff: 0.05000000074505806
        cur_lr: 4.999999873689376e-05
        entropy: 1.3680254220962524
        entropy_coeff: 0.0
        kl: 0.001972897443920374
        policy_loss: -0.010136641561985016
        total_loss: 39.696495056152344
        vf_explained_var: -0.00021076202392578125
        vf_loss: 39.70653533935547
    load_time_ms: 17.639
    num_steps_sampled: 30000
    num_steps_trained: 30000
    sample_time_ms: 103925.45
    update_time_ms: 175.09
  iterations_since_restore: 3
  node_ip: 10.4.1.36
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 2.6118055555555557
    ram_util_percent: 5.3999999999999995
  pid: 385820
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 7.243091771283289
    mean_inference_ms: 0.5147010443475472
    mean_processing_ms: 2.6340480436522937
  time_since_restore: 313.55574107170105
  time_this_iter_s: 101.12497854232788
  time_total_s: 313.55574107170105
  timestamp: 1585570785
  timesteps_since_restore: 30000
  timesteps_this_iter: 10000
  timesteps_total: 30000
  training_iteration: 3
  trial_id: fce6b7f4
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2/2 CPUs, 0/0 GPUs
Memory usage on this node: 10.8/201.2 GB
Result logdir: /users/PYS1027/chnrhughes/ray_results/simple_training_example_ring2_v1
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - PPO_WaveAttenuationPOEnv-v0_0:	RUNNING, [2 CPUs, 0 GPUs], [pid=385820], 313 s, 3 iter, 30000 ts, -186 rew

[2m[36m(pid=385821)[0m 
[2m[36m(pid=385821)[0m -----------------------
[2m[36m(pid=385821)[0m ring length: 499
[2m[36m(pid=385821)[0m v_max: 2.8797928146697993
[2m[36m(pid=385821)[0m -----------------------
[2m[36m(pid=385821)[0m 
[2m[36m(pid=385821)[0m -----------------------
[2m[36m(pid=385821)[0m ring length: 509
[2m[36m(pid=385821)[0m v_max: 3.0797178990784078
[2m[36m(pid=385821)[0m -----------------------
[2m[36m(pid=385821)[0m 
[2m[36m(pid=385821)[0m -----------------------
[2m[36m(pid=385821)[0m ring length: 495
[2m[36m(pid=385821)[0m v_max: 2.79981792361692
[2m[36m(pid=385821)[0m -----------------------
[2m[36m(pid=385821)[0m 
[2m[36m(pid=385821)[0m -----------------------
[2m[36m(pid=385821)[0m ring length: 514
[2m[36m(pid=385821)[0m v_max: 3.1796731425699525
[2m[36m(pid=385821)[0m -----------------------
[2m[36m(pid=385821)[0m 
[2m[36m(pid=385821)[0m -----------------------
[2m[36m(pid=385821)[0m ring length: 506
[2m[36m(pid=385821)[0m v_max: 3.0197423207835943
[2m[36m(pid=385821)[0m -----------------------
Result for PPO_WaveAttenuationPOEnv-v0_0:
  custom_metrics: {}
  date: 2020-03-30_08-21-26
  done: false
  episode_len_mean: 2000.0
  episode_reward_max: 146.9991033927922
  episode_reward_mean: -202.1880406316077
  episode_reward_min: -673.9917406328241
  episodes_this_iter: 5
  episodes_total: 20
  experiment_id: ba0edb931dde48dcb020df4b454540a2
  hostname: p0035.ten.osc.edu
  info:
    grad_time_ms: 339.743
    learner:
      default_policy:
        cur_kl_coeff: 0.02500000037252903
        cur_lr: 4.999999873689376e-05
        entropy: 1.3524377346038818
        entropy_coeff: 0.0
        kl: 0.001641047652810812
        policy_loss: -0.006441528908908367
        total_loss: 92.57451629638672
        vf_explained_var: -0.0012985467910766602
        vf_loss: 92.58092498779297
    load_time_ms: 13.713
    num_steps_sampled: 40000
    num_steps_trained: 40000
    sample_time_ms: 103121.659
    update_time_ms: 131.818
  iterations_since_restore: 4
  node_ip: 10.4.1.36
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 2.6847222222222222
    ram_util_percent: 5.3999999999999995
  pid: 385820
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 7.196185359164309
    mean_inference_ms: 0.5137494743546508
    mean_processing_ms: 2.6340900805271446
  time_since_restore: 414.4965398311615
  time_this_iter_s: 100.94079875946045
  time_total_s: 414.4965398311615
  timestamp: 1585570886
  timesteps_since_restore: 40000
  timesteps_this_iter: 10000
  timesteps_total: 40000
  training_iteration: 4
  trial_id: fce6b7f4
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2/2 CPUs, 0/0 GPUs
Memory usage on this node: 10.8/201.2 GB
Result logdir: /users/PYS1027/chnrhughes/ray_results/simple_training_example_ring2_v1
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - PPO_WaveAttenuationPOEnv-v0_0:	RUNNING, [2 CPUs, 0 GPUs], [pid=385820], 414 s, 4 iter, 40000 ts, -202 rew

[2m[36m(pid=385821)[0m 
[2m[36m(pid=385821)[0m -----------------------
[2m[36m(pid=385821)[0m ring length: 501
[2m[36m(pid=385821)[0m v_max: 2.919779270736568
[2m[36m(pid=385821)[0m -----------------------
[2m[36m(pid=385821)[0m 
[2m[36m(pid=385821)[0m -----------------------
[2m[36m(pid=385821)[0m ring length: 518
[2m[36m(pid=385821)[0m v_max: 3.2596334266284783
[2m[36m(pid=385821)[0m -----------------------
[2m[36m(pid=385821)[0m 
[2m[36m(pid=385821)[0m -----------------------
[2m[36m(pid=385821)[0m ring length: 516
[2m[36m(pid=385821)[0m v_max: 3.2196537366217006
[2m[36m(pid=385821)[0m -----------------------
[2m[36m(pid=385821)[0m 
[2m[36m(pid=385821)[0m -----------------------
[2m[36m(pid=385821)[0m ring length: 501
[2m[36m(pid=385821)[0m v_max: 2.919779270736568
[2m[36m(pid=385821)[0m -----------------------
[2m[36m(pid=385821)[0m 
[2m[36m(pid=385821)[0m -----------------------
[2m[36m(pid=385821)[0m ring length: 494
[2m[36m(pid=385821)[0m v_max: 2.7798238064662253
[2m[36m(pid=385821)[0m -----------------------
Result for PPO_WaveAttenuationPOEnv-v0_0:
  custom_metrics: {}
  date: 2020-03-30_08-23-07
  done: false
  episode_len_mean: 2000.0
  episode_reward_max: 384.73627652671905
  episode_reward_mean: -134.76486713271484
  episode_reward_min: -673.9917406328241
  episodes_this_iter: 5
  episodes_total: 25
  experiment_id: ba0edb931dde48dcb020df4b454540a2
  hostname: p0035.ten.osc.edu
  info:
    grad_time_ms: 316.894
    learner:
      default_policy:
        cur_kl_coeff: 0.012500000186264515
        cur_lr: 4.999999873689376e-05
        entropy: 1.3170630931854248
        entropy_coeff: 0.0
        kl: 0.0035965575370937586
        policy_loss: -0.011901275254786015
        total_loss: 50.90338134765625
        vf_explained_var: -0.00011229515075683594
        vf_loss: 50.915245056152344
    load_time_ms: 11.372
    num_steps_sampled: 50000
    num_steps_trained: 50000
    sample_time_ms: 102640.836
    update_time_ms: 105.898
  iterations_since_restore: 5
  node_ip: 10.4.1.36
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 2.606993006993007
    ram_util_percent: 5.399999999999999
  pid: 385820
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 7.162415188369405
    mean_inference_ms: 0.5134348400436463
    mean_processing_ms: 2.6338041658826525
  time_since_restore: 515.449296951294
  time_this_iter_s: 100.95275712013245
  time_total_s: 515.449296951294
  timestamp: 1585570987
  timesteps_since_restore: 50000
  timesteps_this_iter: 10000
  timesteps_total: 50000
  training_iteration: 5
  trial_id: fce6b7f4
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2/2 CPUs, 0/0 GPUs
Memory usage on this node: 10.8/201.2 GB
Result logdir: /users/PYS1027/chnrhughes/ray_results/simple_training_example_ring2_v1
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - PPO_WaveAttenuationPOEnv-v0_0:	RUNNING, [2 CPUs, 0 GPUs], [pid=385820], 515 s, 5 iter, 50000 ts, -135 rew

[2m[36m(pid=385821)[0m 
[2m[36m(pid=385821)[0m -----------------------
[2m[36m(pid=385821)[0m ring length: 516
[2m[36m(pid=385821)[0m v_max: 3.2196537366217006
[2m[36m(pid=385821)[0m -----------------------
[2m[36m(pid=385821)[0m 
[2m[36m(pid=385821)[0m -----------------------
[2m[36m(pid=385821)[0m ring length: 493
[2m[36m(pid=385821)[0m v_max: 2.759829537541262
[2m[36m(pid=385821)[0m -----------------------
[2m[36m(pid=385821)[0m 
[2m[36m(pid=385821)[0m -----------------------
[2m[36m(pid=385821)[0m ring length: 501
[2m[36m(pid=385821)[0m v_max: 2.919779270736568
[2m[36m(pid=385821)[0m -----------------------
[2m[36m(pid=385821)[0m 
[2m[36m(pid=385821)[0m -----------------------
[2m[36m(pid=385821)[0m ring length: 498
[2m[36m(pid=385821)[0m v_max: 2.8597993346145016
[2m[36m(pid=385821)[0m -----------------------
[2m[36m(pid=385821)[0m 
[2m[36m(pid=385821)[0m -----------------------
[2m[36m(pid=385821)[0m ring length: 511
[2m[36m(pid=385821)[0m v_max: 3.1197006223865698
[2m[36m(pid=385821)[0m -----------------------
Result for PPO_WaveAttenuationPOEnv-v0_0:
  custom_metrics: {}
  date: 2020-03-30_08-24-48
  done: false
  episode_len_mean: 2000.0
  episode_reward_max: 444.63433089131775
  episode_reward_mean: -66.61938640428473
  episode_reward_min: -673.9917406328241
  episodes_this_iter: 5
  episodes_total: 30
  experiment_id: ba0edb931dde48dcb020df4b454540a2
  hostname: p0035.ten.osc.edu
  info:
    grad_time_ms: 304.093
    learner:
      default_policy:
        cur_kl_coeff: 0.0062500000931322575
        cur_lr: 4.999999873689376e-05
        entropy: 1.277140736579895
        entropy_coeff: 0.0
        kl: 0.0068113235756754875
        policy_loss: -0.0163072869181633
        total_loss: 47.135650634765625
        vf_explained_var: 6.413459777832031e-05
        vf_loss: 47.151920318603516
    load_time_ms: 10.049
    num_steps_sampled: 60000
    num_steps_trained: 60000
    sample_time_ms: 102260.819
    update_time_ms: 88.649
  iterations_since_restore: 6
  node_ip: 10.4.1.36
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 2.6298611111111114
    ram_util_percent: 5.3999999999999995
  pid: 385820
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 7.136404425241666
    mean_inference_ms: 0.512760777249515
    mean_processing_ms: 2.633413985237382
  time_since_restore: 616.0624446868896
  time_this_iter_s: 100.6131477355957
  time_total_s: 616.0624446868896
  timestamp: 1585571088
  timesteps_since_restore: 60000
  timesteps_this_iter: 10000
  timesteps_total: 60000
  training_iteration: 6
  trial_id: fce6b7f4
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2/2 CPUs, 0/0 GPUs
Memory usage on this node: 10.8/201.2 GB
Result logdir: /users/PYS1027/chnrhughes/ray_results/simple_training_example_ring2_v1
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - PPO_WaveAttenuationPOEnv-v0_0:	RUNNING, [2 CPUs, 0 GPUs], [pid=385820], 616 s, 6 iter, 60000 ts, -66.6 rew

[2m[36m(pid=385821)[0m 
[2m[36m(pid=385821)[0m -----------------------
[2m[36m(pid=385821)[0m ring length: 513
[2m[36m(pid=385821)[0m v_max: 3.1596825160053825
[2m[36m(pid=385821)[0m -----------------------
[2m[36m(pid=385821)[0m 
[2m[36m(pid=385821)[0m -----------------------
[2m[36m(pid=385821)[0m ring length: 502
[2m[36m(pid=385821)[0m v_max: 2.9397722404035362
[2m[36m(pid=385821)[0m -----------------------
[2m[36m(pid=385821)[0m 
[2m[36m(pid=385821)[0m -----------------------
[2m[36m(pid=385821)[0m ring length: 492
[2m[36m(pid=385821)[0m v_max: 2.739835119766572
[2m[36m(pid=385821)[0m -----------------------
[2m[36m(pid=385821)[0m 
[2m[36m(pid=385821)[0m -----------------------
[2m[36m(pid=385821)[0m ring length: 495
[2m[36m(pid=385821)[0m v_max: 2.79981792361692
[2m[36m(pid=385821)[0m -----------------------
[2m[36m(pid=385821)[0m 
[2m[36m(pid=385821)[0m -----------------------
[2m[36m(pid=385821)[0m ring length: 503
[2m[36m(pid=385821)[0m v_max: 2.9597650335315784
[2m[36m(pid=385821)[0m -----------------------
Result for PPO_WaveAttenuationPOEnv-v0_0:
  custom_metrics: {}
  date: 2020-03-30_08-26-28
  done: false
  episode_len_mean: 2000.0
  episode_reward_max: 622.3040404326987
  episode_reward_mean: -31.66549711771
  episode_reward_min: -673.9917406328241
  episodes_this_iter: 5
  episodes_total: 35
  experiment_id: ba0edb931dde48dcb020df4b454540a2
  hostname: p0035.ten.osc.edu
  info:
    grad_time_ms: 294.679
    learner:
      default_policy:
        cur_kl_coeff: 0.0031250000465661287
        cur_lr: 4.999999873689376e-05
        entropy: 1.254276990890503
        entropy_coeff: 0.0
        kl: 0.005440301261842251
        policy_loss: -0.011646445840597153
        total_loss: 74.77823638916016
        vf_explained_var: 0.0007219314575195312
        vf_loss: 74.78987121582031
    load_time_ms: 9.038
    num_steps_sampled: 70000
    num_steps_trained: 70000
    sample_time_ms: 101911.296
    update_time_ms: 76.338
  iterations_since_restore: 7
  node_ip: 10.4.1.36
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 2.6499999999999995
    ram_util_percent: 5.399999999999998
  pid: 385820
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 7.114907418950205
    mean_inference_ms: 0.5117571349036953
    mean_processing_ms: 2.632918972973137
  time_since_restore: 716.1266765594482
  time_this_iter_s: 100.0642318725586
  time_total_s: 716.1266765594482
  timestamp: 1585571188
  timesteps_since_restore: 70000
  timesteps_this_iter: 10000
  timesteps_total: 70000
  training_iteration: 7
  trial_id: fce6b7f4
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2/2 CPUs, 0/0 GPUs
Memory usage on this node: 10.8/201.2 GB
Result logdir: /users/PYS1027/chnrhughes/ray_results/simple_training_example_ring2_v1
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - PPO_WaveAttenuationPOEnv-v0_0:	RUNNING, [2 CPUs, 0 GPUs], [pid=385820], 716 s, 7 iter, 70000 ts, -31.7 rew

[2m[36m(pid=385821)[0m 
[2m[36m(pid=385821)[0m -----------------------
[2m[36m(pid=385821)[0m ring length: 505
[2m[36m(pid=385821)[0m v_max: 2.999750077051092
[2m[36m(pid=385821)[0m -----------------------
[2m[36m(pid=385821)[0m 
[2m[36m(pid=385821)[0m -----------------------
[2m[36m(pid=385821)[0m ring length: 499
[2m[36m(pid=385821)[0m v_max: 2.8797928146697993
[2m[36m(pid=385821)[0m -----------------------
[2m[36m(pid=385821)[0m 
[2m[36m(pid=385821)[0m -----------------------
[2m[36m(pid=385821)[0m ring length: 505
[2m[36m(pid=385821)[0m v_max: 2.999750077051092
[2m[36m(pid=385821)[0m -----------------------
[2m[36m(pid=385821)[0m 
[2m[36m(pid=385821)[0m -----------------------
[2m[36m(pid=385821)[0m ring length: 507
[2m[36m(pid=385821)[0m v_max: 3.0397343746587766
[2m[36m(pid=385821)[0m -----------------------
[2m[36m(pid=385821)[0m 
[2m[36m(pid=385821)[0m -----------------------
[2m[36m(pid=385821)[0m ring length: 505
[2m[36m(pid=385821)[0m v_max: 2.999750077051092
[2m[36m(pid=385821)[0m -----------------------
Result for PPO_WaveAttenuationPOEnv-v0_0:
  custom_metrics: {}
  date: 2020-03-30_08-28-08
  done: false
  episode_len_mean: 2000.0
  episode_reward_max: 772.4603521894818
  episode_reward_mean: 55.97176185717258
  episode_reward_min: -673.9917406328241
  episodes_this_iter: 5
  episodes_total: 40
  experiment_id: ba0edb931dde48dcb020df4b454540a2
  hostname: p0035.ten.osc.edu
  info:
    grad_time_ms: 286.567
    learner:
      default_policy:
        cur_kl_coeff: 0.0015625000232830644
        cur_lr: 4.999999873689376e-05
        entropy: 1.1993844509124756
        entropy_coeff: 0.0
        kl: 0.00843561440706253
        policy_loss: -0.01878078281879425
        total_loss: 123.08291625976562
        vf_explained_var: 0.000752866268157959
        vf_loss: 123.10167694091797
    load_time_ms: 8.287
    num_steps_sampled: 80000
    num_steps_trained: 80000
    sample_time_ms: 101689.018
    update_time_ms: 67.109
  iterations_since_restore: 8
  node_ip: 10.4.1.36
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 2.6692307692307695
    ram_util_percent: 5.399999999999999
  pid: 385820
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 7.097687871377803
    mean_inference_ms: 0.5105581803694746
    mean_processing_ms: 2.632184093149558
  time_since_restore: 816.5016367435455
  time_this_iter_s: 100.37496018409729
  time_total_s: 816.5016367435455
  timestamp: 1585571288
  timesteps_since_restore: 80000
  timesteps_this_iter: 10000
  timesteps_total: 80000
  training_iteration: 8
  trial_id: fce6b7f4
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2/2 CPUs, 0/0 GPUs
Memory usage on this node: 10.8/201.2 GB
Result logdir: /users/PYS1027/chnrhughes/ray_results/simple_training_example_ring2_v1
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - PPO_WaveAttenuationPOEnv-v0_0:	RUNNING, [2 CPUs, 0 GPUs], [pid=385820], 816 s, 8 iter, 80000 ts, 56 rew

[2m[36m(pid=385821)[0m 
[2m[36m(pid=385821)[0m -----------------------
[2m[36m(pid=385821)[0m ring length: 493
[2m[36m(pid=385821)[0m v_max: 2.759829537541262
[2m[36m(pid=385821)[0m -----------------------
[2m[36m(pid=385821)[0m 
[2m[36m(pid=385821)[0m -----------------------
[2m[36m(pid=385821)[0m ring length: 506
[2m[36m(pid=385821)[0m v_max: 3.0197423207835943
[2m[36m(pid=385821)[0m -----------------------
[2m[36m(pid=385821)[0m 
[2m[36m(pid=385821)[0m -----------------------
[2m[36m(pid=385821)[0m ring length: 513
[2m[36m(pid=385821)[0m v_max: 3.1596825160053825
[2m[36m(pid=385821)[0m -----------------------
[2m[36m(pid=385821)[0m 
[2m[36m(pid=385821)[0m -----------------------
[2m[36m(pid=385821)[0m ring length: 509
[2m[36m(pid=385821)[0m v_max: 3.0797178990784078
[2m[36m(pid=385821)[0m -----------------------
[2m[36m(pid=385821)[0m 
[2m[36m(pid=385821)[0m -----------------------
[2m[36m(pid=385821)[0m ring length: 498
[2m[36m(pid=385821)[0m v_max: 2.8597993346145016
[2m[36m(pid=385821)[0m -----------------------
Result for PPO_WaveAttenuationPOEnv-v0_0:
  custom_metrics: {}
  date: 2020-03-30_08-29-49
  done: false
  episode_len_mean: 2000.0
  episode_reward_max: 1260.7235159917109
  episode_reward_mean: 169.81533770456642
  episode_reward_min: -673.9917406328241
  episodes_this_iter: 5
  episodes_total: 45
  experiment_id: ba0edb931dde48dcb020df4b454540a2
  hostname: p0035.ten.osc.edu
  info:
    grad_time_ms: 279.856
    learner:
      default_policy:
        cur_kl_coeff: 0.0007812500116415322
        cur_lr: 4.999999873689376e-05
        entropy: 1.1522904634475708
        entropy_coeff: 0.0
        kl: 0.007840774953365326
        policy_loss: -0.014774252660572529
        total_loss: 262.8092956542969
        vf_explained_var: 0.0004544854164123535
        vf_loss: 262.82403564453125
    load_time_ms: 7.589
    num_steps_sampled: 90000
    num_steps_trained: 90000
    sample_time_ms: 101553.585
    update_time_ms: 59.909
  iterations_since_restore: 9
  node_ip: 10.4.1.36
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 2.619580419580419
    ram_util_percent: 5.399999999999999
  pid: 385820
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 7.083562632170051
    mean_inference_ms: 0.5096186953123026
    mean_processing_ms: 2.6314538300015036
  time_since_restore: 917.2079269886017
  time_this_iter_s: 100.70629024505615
  time_total_s: 917.2079269886017
  timestamp: 1585571389
  timesteps_since_restore: 90000
  timesteps_this_iter: 10000
  timesteps_total: 90000
  training_iteration: 9
  trial_id: fce6b7f4
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2/2 CPUs, 0/0 GPUs
Memory usage on this node: 10.8/201.2 GB
Result logdir: /users/PYS1027/chnrhughes/ray_results/simple_training_example_ring2_v1
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - PPO_WaveAttenuationPOEnv-v0_0:	RUNNING, [2 CPUs, 0 GPUs], [pid=385820], 917 s, 9 iter, 90000 ts, 170 rew

[2m[36m(pid=385821)[0m 
[2m[36m(pid=385821)[0m -----------------------
[2m[36m(pid=385821)[0m ring length: 515
[2m[36m(pid=385821)[0m v_max: 3.199663550695237
[2m[36m(pid=385821)[0m -----------------------
[2m[36m(pid=385821)[0m 
[2m[36m(pid=385821)[0m -----------------------
[2m[36m(pid=385821)[0m ring length: 490
[2m[36m(pid=385821)[0m v_max: 2.699845849180192
[2m[36m(pid=385821)[0m -----------------------
[2m[36m(pid=385821)[0m 
[2m[36m(pid=385821)[0m -----------------------
[2m[36m(pid=385821)[0m ring length: 520
[2m[36m(pid=385821)[0m v_max: 3.2996121816646764
[2m[36m(pid=385821)[0m -----------------------
[2m[36m(pid=385821)[0m 
[2m[36m(pid=385821)[0m -----------------------
[2m[36m(pid=385821)[0m ring length: 520
[2m[36m(pid=385821)[0m v_max: 3.2996121816646764
[2m[36m(pid=385821)[0m -----------------------
[2m[36m(pid=385821)[0m 
[2m[36m(pid=385821)[0m -----------------------
[2m[36m(pid=385821)[0m ring length: 500
[2m[36m(pid=385821)[0m v_max: 2.8997861277614296
[2m[36m(pid=385821)[0m -----------------------
Result for PPO_WaveAttenuationPOEnv-v0_0:
  custom_metrics: {}
  date: 2020-03-30_08-31-30
  done: false
  episode_len_mean: 2000.0
  episode_reward_max: 1633.1892858280478
  episode_reward_mean: 296.275587476744
  episode_reward_min: -673.9917406328241
  episodes_this_iter: 5
  episodes_total: 50
  experiment_id: ba0edb931dde48dcb020df4b454540a2
  hostname: p0035.ten.osc.edu
  info:
    grad_time_ms: 273.831
    learner:
      default_policy:
        cur_kl_coeff: 0.0003906250058207661
        cur_lr: 4.999999873689376e-05
        entropy: 1.1090683937072754
        entropy_coeff: 0.0
        kl: 0.007252618204802275
        policy_loss: -0.013451996259391308
        total_loss: 440.285888671875
        vf_explained_var: 0.0005486011505126953
        vf_loss: 440.2994079589844
    load_time_ms: 7.12
    num_steps_sampled: 100000
    num_steps_trained: 100000
    sample_time_ms: 101451.438
    update_time_ms: 54.14
  iterations_since_restore: 10
  node_ip: 10.4.1.36
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 2.650694444444445
    ram_util_percent: 5.3999999999999995
  pid: 385820
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 7.071977009879677
    mean_inference_ms: 0.5087959919003975
    mean_processing_ms: 2.6306398257055412
  time_since_restore: 1017.9712243080139
  time_this_iter_s: 100.76329731941223
  time_total_s: 1017.9712243080139
  timestamp: 1585571490
  timesteps_since_restore: 100000
  timesteps_this_iter: 10000
  timesteps_total: 100000
  training_iteration: 10
  trial_id: fce6b7f4
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2/2 CPUs, 0/0 GPUs
Memory usage on this node: 10.8/201.2 GB
Result logdir: /users/PYS1027/chnrhughes/ray_results/simple_training_example_ring2_v1
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - PPO_WaveAttenuationPOEnv-v0_0:	RUNNING, [2 CPUs, 0 GPUs], [pid=385820], 1017 s, 10 iter, 100000 ts, 296 rew

[2m[36m(pid=385821)[0m 
[2m[36m(pid=385821)[0m -----------------------
[2m[36m(pid=385821)[0m ring length: 510
[2m[36m(pid=385821)[0m v_max: 3.0997093626421153
[2m[36m(pid=385821)[0m -----------------------
[2m[36m(pid=385821)[0m 
[2m[36m(pid=385821)[0m -----------------------
[2m[36m(pid=385821)[0m ring length: 497
[2m[36m(pid=385821)[0m v_max: 2.839805690709741
[2m[36m(pid=385821)[0m -----------------------
[2m[36m(pid=385821)[0m 
[2m[36m(pid=385821)[0m -----------------------
[2m[36m(pid=385821)[0m ring length: 507
[2m[36m(pid=385821)[0m v_max: 3.0397343746587766
[2m[36m(pid=385821)[0m -----------------------
[2m[36m(pid=385821)[0m 
[2m[36m(pid=385821)[0m -----------------------
[2m[36m(pid=385821)[0m ring length: 494
[2m[36m(pid=385821)[0m v_max: 2.7798238064662253
[2m[36m(pid=385821)[0m -----------------------
[2m[36m(pid=385821)[0m 
[2m[36m(pid=385821)[0m -----------------------
[2m[36m(pid=385821)[0m ring length: 516
[2m[36m(pid=385821)[0m v_max: 3.2196537366217006
[2m[36m(pid=385821)[0m -----------------------
Result for PPO_WaveAttenuationPOEnv-v0_0:
  custom_metrics: {}
  date: 2020-03-30_08-33-11
  done: false
  episode_len_mean: 2000.0
  episode_reward_max: 1677.508193556313
  episode_reward_mean: 401.0274364588436
  episode_reward_min: -673.9917406328241
  episodes_this_iter: 5
  episodes_total: 55
  experiment_id: ba0edb931dde48dcb020df4b454540a2
  hostname: p0035.ten.osc.edu
  info:
    grad_time_ms: 229.51
    learner:
      default_policy:
        cur_kl_coeff: 0.00019531250291038305
        cur_lr: 4.999999873689376e-05
        entropy: 1.0685930252075195
        entropy_coeff: 0.0
        kl: 0.008515855297446251
        policy_loss: -0.01624101586639881
        total_loss: 437.02020263671875
        vf_explained_var: 0.0004895925521850586
        vf_loss: 437.0364074707031
    load_time_ms: 2.446
    num_steps_sampled: 110000
    num_steps_trained: 110000
    sample_time_ms: 100496.426
    update_time_ms: 2.267
  iterations_since_restore: 11
  node_ip: 10.4.1.36
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 2.6356643356643357
    ram_util_percent: 5.399999999999999
  pid: 385820
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 7.062088215787006
    mean_inference_ms: 0.508055849413464
    mean_processing_ms: 2.6299547725021433
  time_since_restore: 1118.6736721992493
  time_this_iter_s: 100.70244789123535
  time_total_s: 1118.6736721992493
  timestamp: 1585571591
  timesteps_since_restore: 110000
  timesteps_this_iter: 10000
  timesteps_total: 110000
  training_iteration: 11
  trial_id: fce6b7f4
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2/2 CPUs, 0/0 GPUs
Memory usage on this node: 10.8/201.2 GB
Result logdir: /users/PYS1027/chnrhughes/ray_results/simple_training_example_ring2_v1
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - PPO_WaveAttenuationPOEnv-v0_0:	RUNNING, [2 CPUs, 0 GPUs], [pid=385820], 1118 s, 11 iter, 110000 ts, 401 rew

[2m[36m(pid=385821)[0m 
[2m[36m(pid=385821)[0m -----------------------
[2m[36m(pid=385821)[0m ring length: 504
[2m[36m(pid=385821)[0m v_max: 2.979757646850631
[2m[36m(pid=385821)[0m -----------------------
[2m[36m(pid=385821)[0m 
[2m[36m(pid=385821)[0m -----------------------
[2m[36m(pid=385821)[0m ring length: 502
[2m[36m(pid=385821)[0m v_max: 2.9397722404035362
[2m[36m(pid=385821)[0m -----------------------
[2m[36m(pid=385821)[0m 
[2m[36m(pid=385821)[0m -----------------------
[2m[36m(pid=385821)[0m ring length: 499
[2m[36m(pid=385821)[0m v_max: 2.8797928146697993
[2m[36m(pid=385821)[0m -----------------------
[2m[36m(pid=385821)[0m 
[2m[36m(pid=385821)[0m -----------------------
[2m[36m(pid=385821)[0m ring length: 499
[2m[36m(pid=385821)[0m v_max: 2.8797928146697993
[2m[36m(pid=385821)[0m -----------------------
[2m[36m(pid=385821)[0m 
[2m[36m(pid=385821)[0m -----------------------
[2m[36m(pid=385821)[0m ring length: 490
[2m[36m(pid=385821)[0m v_max: 2.699845849180192
[2m[36m(pid=385821)[0m -----------------------
Result for PPO_WaveAttenuationPOEnv-v0_0:
  custom_metrics: {}
  date: 2020-03-30_08-34-51
  done: false
  episode_len_mean: 2000.0
  episode_reward_max: 1928.0277142567113
  episode_reward_mean: 510.4502558325974
  episode_reward_min: -673.9917406328241
  episodes_this_iter: 5
  episodes_total: 60
  experiment_id: ba0edb931dde48dcb020df4b454540a2
  hostname: p0035.ten.osc.edu
  info:
    grad_time_ms: 228.514
    learner:
      default_policy:
        cur_kl_coeff: 9.765625145519152e-05
        cur_lr: 4.999999873689376e-05
        entropy: 1.0331693887710571
        entropy_coeff: 0.0
        kl: 0.005412685219198465
        policy_loss: -0.009322358295321465
        total_loss: 597.6569213867188
        vf_explained_var: 0.0009549856185913086
        vf_loss: 597.6663208007812
    load_time_ms: 2.453
    num_steps_sampled: 120000
    num_steps_trained: 120000
    sample_time_ms: 100435.327
    update_time_ms: 2.261
  iterations_since_restore: 12
  node_ip: 10.4.1.36
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 2.649650349650349
    ram_util_percent: 5.399999999999999
  pid: 385820
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 7.053529158840569
    mean_inference_ms: 0.5073380689916563
    mean_processing_ms: 2.629294120541325
  time_since_restore: 1219.1776239871979
  time_this_iter_s: 100.50395178794861
  time_total_s: 1219.1776239871979
  timestamp: 1585571691
  timesteps_since_restore: 120000
  timesteps_this_iter: 10000
  timesteps_total: 120000
  training_iteration: 12
  trial_id: fce6b7f4
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2/2 CPUs, 0/0 GPUs
Memory usage on this node: 10.8/201.2 GB
Result logdir: /users/PYS1027/chnrhughes/ray_results/simple_training_example_ring2_v1
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - PPO_WaveAttenuationPOEnv-v0_0:	RUNNING, [2 CPUs, 0 GPUs], [pid=385820], 1219 s, 12 iter, 120000 ts, 510 rew

[2m[36m(pid=385821)[0m 
[2m[36m(pid=385821)[0m -----------------------
[2m[36m(pid=385821)[0m ring length: 513
[2m[36m(pid=385821)[0m v_max: 3.1596825160053825
[2m[36m(pid=385821)[0m -----------------------
[2m[36m(pid=385821)[0m 
[2m[36m(pid=385821)[0m -----------------------
[2m[36m(pid=385821)[0m ring length: 515
[2m[36m(pid=385821)[0m v_max: 3.199663550695237
[2m[36m(pid=385821)[0m -----------------------
[2m[36m(pid=385821)[0m 
[2m[36m(pid=385821)[0m -----------------------
[2m[36m(pid=385821)[0m ring length: 494
[2m[36m(pid=385821)[0m v_max: 2.7798238064662253
[2m[36m(pid=385821)[0m -----------------------
[2m[36m(pid=385821)[0m 
[2m[36m(pid=385821)[0m -----------------------
[2m[36m(pid=385821)[0m ring length: 520
[2m[36m(pid=385821)[0m v_max: 3.2996121816646764
[2m[36m(pid=385821)[0m -----------------------
[2m[36m(pid=385821)[0m 
[2m[36m(pid=385821)[0m -----------------------
[2m[36m(pid=385821)[0m ring length: 507
[2m[36m(pid=385821)[0m v_max: 3.0397343746587766
[2m[36m(pid=385821)[0m -----------------------
Result for PPO_WaveAttenuationPOEnv-v0_0:
  custom_metrics: {}
  date: 2020-03-30_08-36-32
  done: false
  episode_len_mean: 2000.0
  episode_reward_max: 2220.764770020804
  episode_reward_mean: 614.8391383819102
  episode_reward_min: -673.9917406328241
  episodes_this_iter: 5
  episodes_total: 65
  experiment_id: ba0edb931dde48dcb020df4b454540a2
  hostname: p0035.ten.osc.edu
  info:
    grad_time_ms: 228.095
    learner:
      default_policy:
        cur_kl_coeff: 4.882812572759576e-05
        cur_lr: 4.999999873689376e-05
        entropy: 0.9977552890777588
        entropy_coeff: 0.0
        kl: 0.0054964120499789715
        policy_loss: -0.009758168831467628
        total_loss: 714.2116088867188
        vf_explained_var: 0.0007939338684082031
        vf_loss: 714.2213745117188
    load_time_ms: 2.492
    num_steps_sampled: 130000
    num_steps_trained: 130000
    sample_time_ms: 100374.222
    update_time_ms: 2.285
  iterations_since_restore: 13
  node_ip: 10.4.1.36
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 2.6356643356643357
    ram_util_percent: 5.399999999999999
  pid: 385820
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 7.04592139363148
    mean_inference_ms: 0.5068614694169798
    mean_processing_ms: 2.6285768146790205
  time_since_restore: 1319.688730955124
  time_this_iter_s: 100.51110696792603
  time_total_s: 1319.688730955124
  timestamp: 1585571792
  timesteps_since_restore: 130000
  timesteps_this_iter: 10000
  timesteps_total: 130000
  training_iteration: 13
  trial_id: fce6b7f4
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2/2 CPUs, 0/0 GPUs
Memory usage on this node: 10.8/201.2 GB
Result logdir: /users/PYS1027/chnrhughes/ray_results/simple_training_example_ring2_v1
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - PPO_WaveAttenuationPOEnv-v0_0:	RUNNING, [2 CPUs, 0 GPUs], [pid=385820], 1319 s, 13 iter, 130000 ts, 615 rew

[2m[36m(pid=385821)[0m 
[2m[36m(pid=385821)[0m -----------------------
[2m[36m(pid=385821)[0m ring length: 519
[2m[36m(pid=385821)[0m v_max: 3.2796229229775036
[2m[36m(pid=385821)[0m -----------------------
[2m[36m(pid=385821)[0m 
[2m[36m(pid=385821)[0m -----------------------
[2m[36m(pid=385821)[0m ring length: 515
[2m[36m(pid=385821)[0m v_max: 3.199663550695237
[2m[36m(pid=385821)[0m -----------------------
[2m[36m(pid=385821)[0m 
[2m[36m(pid=385821)[0m -----------------------
[2m[36m(pid=385821)[0m ring length: 495
[2m[36m(pid=385821)[0m v_max: 2.79981792361692
[2m[36m(pid=385821)[0m -----------------------
[2m[36m(pid=385821)[0m 
[2m[36m(pid=385821)[0m -----------------------
[2m[36m(pid=385821)[0m ring length: 517
[2m[36m(pid=385821)[0m v_max: 3.2396436965475437
[2m[36m(pid=385821)[0m -----------------------
[2m[36m(pid=385821)[0m 
[2m[36m(pid=385821)[0m -----------------------
[2m[36m(pid=385821)[0m ring length: 513
[2m[36m(pid=385821)[0m v_max: 3.1596825160053825
[2m[36m(pid=385821)[0m -----------------------
Result for PPO_WaveAttenuationPOEnv-v0_0:
  custom_metrics: {}
  date: 2020-03-30_08-38-12
  done: false
  episode_len_mean: 2000.0
  episode_reward_max: 2443.6820265868346
  episode_reward_mean: 722.3421580503331
  episode_reward_min: -673.9917406328241
  episodes_this_iter: 5
  episodes_total: 70
  experiment_id: ba0edb931dde48dcb020df4b454540a2
  hostname: p0035.ten.osc.edu
  info:
    grad_time_ms: 228.171
    learner:
      default_policy:
        cur_kl_coeff: 2.441406286379788e-05
        cur_lr: 4.999999873689376e-05
        entropy: 0.9615804553031921
        entropy_coeff: 0.0
        kl: 0.005303822923451662
        policy_loss: -0.009361623786389828
        total_loss: 926.4631958007812
        vf_explained_var: 0.0016412138938903809
        vf_loss: 926.4730224609375
    load_time_ms: 2.489
    num_steps_sampled: 140000
    num_steps_trained: 140000
    sample_time_ms: 100349.862
    update_time_ms: 2.293
  iterations_since_restore: 14
  node_ip: 10.4.1.36
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 2.62027972027972
    ram_util_percent: 5.399999999999999
  pid: 385820
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 7.039298078463482
    mean_inference_ms: 0.506394729902201
    mean_processing_ms: 2.6279051545882672
  time_since_restore: 1420.3884618282318
  time_this_iter_s: 100.69973087310791
  time_total_s: 1420.3884618282318
  timestamp: 1585571892
  timesteps_since_restore: 140000
  timesteps_this_iter: 10000
  timesteps_total: 140000
  training_iteration: 14
  trial_id: fce6b7f4
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2/2 CPUs, 0/0 GPUs
Memory usage on this node: 10.8/201.2 GB
Result logdir: /users/PYS1027/chnrhughes/ray_results/simple_training_example_ring2_v1
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - PPO_WaveAttenuationPOEnv-v0_0:	RUNNING, [2 CPUs, 0 GPUs], [pid=385820], 1420 s, 14 iter, 140000 ts, 722 rew

[2m[36m(pid=385821)[0m 
[2m[36m(pid=385821)[0m -----------------------
[2m[36m(pid=385821)[0m ring length: 515
[2m[36m(pid=385821)[0m v_max: 3.199663550695237
[2m[36m(pid=385821)[0m -----------------------
[2m[36m(pid=385821)[0m 
[2m[36m(pid=385821)[0m -----------------------
[2m[36m(pid=385821)[0m ring length: 510
[2m[36m(pid=385821)[0m v_max: 3.0997093626421153
[2m[36m(pid=385821)[0m -----------------------
[2m[36m(pid=385821)[0m 
[2m[36m(pid=385821)[0m -----------------------
[2m[36m(pid=385821)[0m ring length: 498
[2m[36m(pid=385821)[0m v_max: 2.8597993346145016
[2m[36m(pid=385821)[0m -----------------------
[2m[36m(pid=385821)[0m 
[2m[36m(pid=385821)[0m -----------------------
[2m[36m(pid=385821)[0m ring length: 504
[2m[36m(pid=385821)[0m v_max: 2.979757646850631
[2m[36m(pid=385821)[0m -----------------------
[2m[36m(pid=385821)[0m 
[2m[36m(pid=385821)[0m -----------------------
[2m[36m(pid=385821)[0m ring length: 491
[2m[36m(pid=385821)[0m v_max: 2.719840556029452
[2m[36m(pid=385821)[0m -----------------------
Result for PPO_WaveAttenuationPOEnv-v0_0:
  custom_metrics: {}
  date: 2020-03-30_08-39-53
  done: false
  episode_len_mean: 2000.0
  episode_reward_max: 2515.01479718144
  episode_reward_mean: 832.626144872977
  episode_reward_min: -673.9917406328241
  episodes_this_iter: 5
  episodes_total: 75
  experiment_id: ba0edb931dde48dcb020df4b454540a2
  hostname: p0035.ten.osc.edu
  info:
    grad_time_ms: 229.626
    learner:
      default_policy:
        cur_kl_coeff: 1.220703143189894e-05
        cur_lr: 4.999999873689376e-05
        entropy: 0.9258286952972412
        entropy_coeff: 0.0
        kl: 0.0038548933807760477
        policy_loss: -0.006293934769928455
        total_loss: 1129.735107421875
        vf_explained_var: 0.00016254186630249023
        vf_loss: 1129.741455078125
    load_time_ms: 2.515
    num_steps_sampled: 150000
    num_steps_trained: 150000
    sample_time_ms: 100307.84
    update_time_ms: 2.296
  iterations_since_restore: 15
  node_ip: 10.4.1.36
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 2.667132867132867
    ram_util_percent: 5.399999999999999
  pid: 385820
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 7.033433825719975
    mean_inference_ms: 0.505921026162639
    mean_processing_ms: 2.627265463954518
  time_since_restore: 1520.9378130435944
  time_this_iter_s: 100.54935121536255
  time_total_s: 1520.9378130435944
  timestamp: 1585571993
  timesteps_since_restore: 150000
  timesteps_this_iter: 10000
  timesteps_total: 150000
  training_iteration: 15
  trial_id: fce6b7f4
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2/2 CPUs, 0/0 GPUs
Memory usage on this node: 10.8/201.2 GB
Result logdir: /users/PYS1027/chnrhughes/ray_results/simple_training_example_ring2_v1
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - PPO_WaveAttenuationPOEnv-v0_0:	RUNNING, [2 CPUs, 0 GPUs], [pid=385820], 1520 s, 15 iter, 150000 ts, 833 rew

[2m[36m(pid=385821)[0m 
[2m[36m(pid=385821)[0m -----------------------
[2m[36m(pid=385821)[0m ring length: 499
[2m[36m(pid=385821)[0m v_max: 2.8797928146697993
[2m[36m(pid=385821)[0m -----------------------
[2m[36m(pid=385821)[0m 
[2m[36m(pid=385821)[0m -----------------------
[2m[36m(pid=385821)[0m ring length: 510
[2m[36m(pid=385821)[0m v_max: 3.0997093626421153
[2m[36m(pid=385821)[0m -----------------------
[2m[36m(pid=385821)[0m 
[2m[36m(pid=385821)[0m -----------------------
[2m[36m(pid=385821)[0m ring length: 496
[2m[36m(pid=385821)[0m v_max: 2.819811886031332
[2m[36m(pid=385821)[0m -----------------------
[2m[36m(pid=385821)[0m 
[2m[36m(pid=385821)[0m -----------------------
[2m[36m(pid=385821)[0m ring length: 496
[2m[36m(pid=385821)[0m v_max: 2.819811886031332
[2m[36m(pid=385821)[0m -----------------------
[2m[36m(pid=385821)[0m 
[2m[36m(pid=385821)[0m -----------------------
[2m[36m(pid=385821)[0m ring length: 496
[2m[36m(pid=385821)[0m v_max: 2.819811886031332
[2m[36m(pid=385821)[0m -----------------------
Result for PPO_WaveAttenuationPOEnv-v0_0:
  custom_metrics: {}
  date: 2020-03-30_08-41-33
  done: false
  episode_len_mean: 2000.0
  episode_reward_max: 2521.1665120066423
  episode_reward_mean: 927.1733967614819
  episode_reward_min: -673.9917406328241
  episodes_this_iter: 5
  episodes_total: 80
  experiment_id: ba0edb931dde48dcb020df4b454540a2
  hostname: p0035.ten.osc.edu
  info:
    grad_time_ms: 228.16
    learner:
      default_policy:
        cur_kl_coeff: 6.10351571594947e-06
        cur_lr: 4.999999873689376e-05
        entropy: 0.9034627079963684
        entropy_coeff: 0.0
        kl: 0.004840551409870386
        policy_loss: -0.005948413163423538
        total_loss: 1100.0616455078125
        vf_explained_var: 0.0004978179931640625
        vf_loss: 1100.067626953125
    load_time_ms: 2.406
    num_steps_sampled: 160000
    num_steps_trained: 160000
    sample_time_ms: 100291.22
    update_time_ms: 2.265
  iterations_since_restore: 16
  node_ip: 10.4.1.36
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 2.632867132867133
    ram_util_percent: 5.399999999999999
  pid: 385820
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 7.028136544359955
    mean_inference_ms: 0.5054354094458697
    mean_processing_ms: 2.6266968005779576
  time_since_restore: 1621.3682134151459
  time_this_iter_s: 100.43040037155151
  time_total_s: 1621.3682134151459
  timestamp: 1585572093
  timesteps_since_restore: 160000
  timesteps_this_iter: 10000
  timesteps_total: 160000
  training_iteration: 16
  trial_id: fce6b7f4
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2/2 CPUs, 0/0 GPUs
Memory usage on this node: 10.8/201.2 GB
Result logdir: /users/PYS1027/chnrhughes/ray_results/simple_training_example_ring2_v1
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - PPO_WaveAttenuationPOEnv-v0_0:	RUNNING, [2 CPUs, 0 GPUs], [pid=385820], 1621 s, 16 iter, 160000 ts, 927 rew

[2m[36m(pid=385821)[0m 
[2m[36m(pid=385821)[0m -----------------------
[2m[36m(pid=385821)[0m ring length: 511
[2m[36m(pid=385821)[0m v_max: 3.1197006223865698
[2m[36m(pid=385821)[0m -----------------------
[2m[36m(pid=385821)[0m 
[2m[36m(pid=385821)[0m -----------------------
[2m[36m(pid=385821)[0m ring length: 515
[2m[36m(pid=385821)[0m v_max: 3.199663550695237
[2m[36m(pid=385821)[0m -----------------------
[2m[36m(pid=385821)[0m 
[2m[36m(pid=385821)[0m -----------------------
[2m[36m(pid=385821)[0m ring length: 490
[2m[36m(pid=385821)[0m v_max: 2.699845849180192
[2m[36m(pid=385821)[0m -----------------------
[2m[36m(pid=385821)[0m 
[2m[36m(pid=385821)[0m -----------------------
[2m[36m(pid=385821)[0m ring length: 507
[2m[36m(pid=385821)[0m v_max: 3.0397343746587766
[2m[36m(pid=385821)[0m -----------------------
[2m[36m(pid=385821)[0m 
[2m[36m(pid=385821)[0m -----------------------
[2m[36m(pid=385821)[0m ring length: 495
[2m[36m(pid=385821)[0m v_max: 2.79981792361692
[2m[36m(pid=385821)[0m -----------------------
Result for PPO_WaveAttenuationPOEnv-v0_0:
  custom_metrics: {}
  date: 2020-03-30_08-43-14
  done: false
  episode_len_mean: 2000.0
  episode_reward_max: 2841.7231795301095
  episode_reward_mean: 1030.5097346732634
  episode_reward_min: -673.9917406328241
  episodes_this_iter: 5
  episodes_total: 85
  experiment_id: ba0edb931dde48dcb020df4b454540a2
  hostname: p0035.ten.osc.edu
  info:
    grad_time_ms: 226.675
    learner:
      default_policy:
        cur_kl_coeff: 3.051757857974735e-06
        cur_lr: 4.999999873689376e-05
        entropy: 0.8709263801574707
        entropy_coeff: 0.0
        kl: 0.003020036965608597
        policy_loss: -0.0049842470325529575
        total_loss: 1436.58837890625
        vf_explained_var: 5.4001808166503906e-05
        vf_loss: 1436.593017578125
    load_time_ms: 2.324
    num_steps_sampled: 170000
    num_steps_trained: 170000
    sample_time_ms: 100328.67
    update_time_ms: 2.219
  iterations_since_restore: 17
  node_ip: 10.4.1.36
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 2.6244755244755247
    ram_util_percent: 5.399999999999999
  pid: 385820
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 7.023266916208089
    mean_inference_ms: 0.5050487111334054
    mean_processing_ms: 2.6261386922237056
  time_since_restore: 1721.790896654129
  time_this_iter_s: 100.42268323898315
  time_total_s: 1721.790896654129
  timestamp: 1585572194
  timesteps_since_restore: 170000
  timesteps_this_iter: 10000
  timesteps_total: 170000
  training_iteration: 17
  trial_id: fce6b7f4
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2/2 CPUs, 0/0 GPUs
Memory usage on this node: 10.8/201.2 GB
Result logdir: /users/PYS1027/chnrhughes/ray_results/simple_training_example_ring2_v1
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - PPO_WaveAttenuationPOEnv-v0_0:	RUNNING, [2 CPUs, 0 GPUs], [pid=385820], 1721 s, 17 iter, 170000 ts, 1.03e+03 rew

[2m[36m(pid=385821)[0m 
[2m[36m(pid=385821)[0m -----------------------
[2m[36m(pid=385821)[0m ring length: 493
[2m[36m(pid=385821)[0m v_max: 2.759829537541262
[2m[36m(pid=385821)[0m -----------------------
[2m[36m(pid=385821)[0m 
[2m[36m(pid=385821)[0m -----------------------
[2m[36m(pid=385821)[0m ring length: 510
[2m[36m(pid=385821)[0m v_max: 3.0997093626421153
[2m[36m(pid=385821)[0m -----------------------
[2m[36m(pid=385821)[0m 
[2m[36m(pid=385821)[0m -----------------------
[2m[36m(pid=385821)[0m ring length: 510
[2m[36m(pid=385821)[0m v_max: 3.0997093626421153
[2m[36m(pid=385821)[0m -----------------------
[2m[36m(pid=385821)[0m 
[2m[36m(pid=385821)[0m -----------------------
[2m[36m(pid=385821)[0m ring length: 513
[2m[36m(pid=385821)[0m v_max: 3.1596825160053825
[2m[36m(pid=385821)[0m -----------------------
[2m[36m(pid=385821)[0m 
[2m[36m(pid=385821)[0m -----------------------
[2m[36m(pid=385821)[0m ring length: 500
[2m[36m(pid=385821)[0m v_max: 2.8997861277614296
[2m[36m(pid=385821)[0m -----------------------
Result for PPO_WaveAttenuationPOEnv-v0_0:
  custom_metrics: {}
  date: 2020-03-30_08-44-55
  done: false
  episode_len_mean: 2000.0
  episode_reward_max: 2925.7011523994647
  episode_reward_mean: 1128.9111628150017
  episode_reward_min: -673.9917406328241
  episodes_this_iter: 5
  episodes_total: 90
  experiment_id: ba0edb931dde48dcb020df4b454540a2
  hostname: p0035.ten.osc.edu
  info:
    grad_time_ms: 225.502
    learner:
      default_policy:
        cur_kl_coeff: 1.5258789289873675e-06
        cur_lr: 4.999999873689376e-05
        entropy: 0.8456517457962036
        entropy_coeff: 0.0
        kl: 0.0028024199418723583
        policy_loss: -0.004054521210491657
        total_loss: 1561.29833984375
        vf_explained_var: 5.066394805908203e-05
        vf_loss: 1561.302001953125
    load_time_ms: 2.237
    num_steps_sampled: 180000
    num_steps_trained: 180000
    sample_time_ms: 100386.96
    update_time_ms: 2.181
  iterations_since_restore: 18
  node_ip: 10.4.1.36
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 2.6180555555555554
    ram_util_percent: 5.3999999999999995
  pid: 385820
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 7.0187876025689455
    mean_inference_ms: 0.504833592645639
    mean_processing_ms: 2.62564896569399
  time_since_restore: 1822.7354717254639
  time_this_iter_s: 100.94457507133484
  time_total_s: 1822.7354717254639
  timestamp: 1585572295
  timesteps_since_restore: 180000
  timesteps_this_iter: 10000
  timesteps_total: 180000
  training_iteration: 18
  trial_id: fce6b7f4
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2/2 CPUs, 0/0 GPUs
Memory usage on this node: 10.8/201.2 GB
Result logdir: /users/PYS1027/chnrhughes/ray_results/simple_training_example_ring2_v1
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - PPO_WaveAttenuationPOEnv-v0_0:	RUNNING, [2 CPUs, 0 GPUs], [pid=385820], 1822 s, 18 iter, 180000 ts, 1.13e+03 rew

[2m[36m(pid=385821)[0m 
[2m[36m(pid=385821)[0m -----------------------
[2m[36m(pid=385821)[0m ring length: 510
[2m[36m(pid=385821)[0m v_max: 3.0997093626421153
[2m[36m(pid=385821)[0m -----------------------
[2m[36m(pid=385821)[0m 
[2m[36m(pid=385821)[0m -----------------------
[2m[36m(pid=385821)[0m ring length: 493
[2m[36m(pid=385821)[0m v_max: 2.759829537541262
[2m[36m(pid=385821)[0m -----------------------
[2m[36m(pid=385821)[0m 
[2m[36m(pid=385821)[0m -----------------------
[2m[36m(pid=385821)[0m ring length: 500
[2m[36m(pid=385821)[0m v_max: 2.8997861277614296
[2m[36m(pid=385821)[0m -----------------------
[2m[36m(pid=385821)[0m 
[2m[36m(pid=385821)[0m -----------------------
[2m[36m(pid=385821)[0m ring length: 519
[2m[36m(pid=385821)[0m v_max: 3.2796229229775036
[2m[36m(pid=385821)[0m -----------------------
[2m[36m(pid=385821)[0m 
[2m[36m(pid=385821)[0m -----------------------
[2m[36m(pid=385821)[0m ring length: 494
[2m[36m(pid=385821)[0m v_max: 2.7798238064662253
[2m[36m(pid=385821)[0m -----------------------
Result for PPO_WaveAttenuationPOEnv-v0_0:
  custom_metrics: {}
  date: 2020-03-30_08-46-36
  done: false
  episode_len_mean: 2000.0
  episode_reward_max: 3168.7193398026034
  episode_reward_mean: 1223.3551253962398
  episode_reward_min: -673.9917406328241
  episodes_this_iter: 5
  episodes_total: 95
  experiment_id: ba0edb931dde48dcb020df4b454540a2
  hostname: p0035.ten.osc.edu
  info:
    grad_time_ms: 224.047
    learner:
      default_policy:
        cur_kl_coeff: 7.629394644936838e-07
        cur_lr: 4.999999873689376e-05
        entropy: 0.8191396594047546
        entropy_coeff: 0.0
        kl: 0.0032712891697883606
        policy_loss: -0.0050054918974637985
        total_loss: 1696.6669921875
        vf_explained_var: 6.788969039916992e-05
        vf_loss: 1696.67236328125
    load_time_ms: 2.247
    num_steps_sampled: 190000
    num_steps_trained: 190000
    sample_time_ms: 100404.734
    update_time_ms: 2.171
  iterations_since_restore: 19
  node_ip: 10.4.1.36
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 2.673611111111111
    ram_util_percent: 5.3999999999999995
  pid: 385820
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 7.014620782656857
    mean_inference_ms: 0.5047903872492591
    mean_processing_ms: 2.625186996592991
  time_since_restore: 1923.6054601669312
  time_this_iter_s: 100.86998844146729
  time_total_s: 1923.6054601669312
  timestamp: 1585572396
  timesteps_since_restore: 190000
  timesteps_this_iter: 10000
  timesteps_total: 190000
  training_iteration: 19
  trial_id: fce6b7f4
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2/2 CPUs, 0/0 GPUs
Memory usage on this node: 10.8/201.2 GB
Result logdir: /users/PYS1027/chnrhughes/ray_results/simple_training_example_ring2_v1
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - PPO_WaveAttenuationPOEnv-v0_0:	RUNNING, [2 CPUs, 0 GPUs], [pid=385820], 1923 s, 19 iter, 190000 ts, 1.22e+03 rew

[2m[36m(pid=385821)[0m 
[2m[36m(pid=385821)[0m -----------------------
[2m[36m(pid=385821)[0m ring length: 507
[2m[36m(pid=385821)[0m v_max: 3.0397343746587766
[2m[36m(pid=385821)[0m -----------------------
[2m[36m(pid=385821)[0m 
[2m[36m(pid=385821)[0m -----------------------
[2m[36m(pid=385821)[0m ring length: 491
[2m[36m(pid=385821)[0m v_max: 2.719840556029452
[2m[36m(pid=385821)[0m -----------------------
[2m[36m(pid=385821)[0m 
[2m[36m(pid=385821)[0m -----------------------
[2m[36m(pid=385821)[0m ring length: 507
[2m[36m(pid=385821)[0m v_max: 3.0397343746587766
[2m[36m(pid=385821)[0m -----------------------
[2m[36m(pid=385821)[0m 
[2m[36m(pid=385821)[0m -----------------------
[2m[36m(pid=385821)[0m ring length: 519
[2m[36m(pid=385821)[0m v_max: 3.2796229229775036
[2m[36m(pid=385821)[0m -----------------------
[2m[36m(pid=385821)[0m 
[2m[36m(pid=385821)[0m -----------------------
[2m[36m(pid=385821)[0m ring length: 509
[2m[36m(pid=385821)[0m v_max: 3.0797178990784078
[2m[36m(pid=385821)[0m -----------------------
Result for PPO_WaveAttenuationPOEnv-v0_0:
  custom_metrics: {}
  date: 2020-03-30_08-48-16
  done: false
  episode_len_mean: 2000.0
  episode_reward_max: 3236.6898899884513
  episode_reward_mean: 1313.1098772767439
  episode_reward_min: -673.9917406328241
  episodes_this_iter: 5
  episodes_total: 100
  experiment_id: ba0edb931dde48dcb020df4b454540a2
  hostname: p0035.ten.osc.edu
  info:
    grad_time_ms: 224.584
    learner:
      default_policy:
        cur_kl_coeff: 3.814697322468419e-07
        cur_lr: 4.999999873689376e-05
        entropy: 0.7973360419273376
        entropy_coeff: 0.0
        kl: 0.0034237303771078587
        policy_loss: -0.003551370929926634
        total_loss: 1809.510009765625
        vf_explained_var: 3.987550735473633e-05
        vf_loss: 1809.5135498046875
    load_time_ms: 2.176
    num_steps_sampled: 200000
    num_steps_trained: 200000
    sample_time_ms: 100411.717
    update_time_ms: 2.172
  iterations_since_restore: 20
  node_ip: 10.4.1.36
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 2.592307692307692
    ram_util_percent: 5.399999999999999
  pid: 385820
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 7.010763966939932
    mean_inference_ms: 0.5048315279977779
    mean_processing_ms: 2.624759086202603
  time_since_restore: 2024.4438769817352
  time_this_iter_s: 100.83841681480408
  time_total_s: 2024.4438769817352
  timestamp: 1585572496
  timesteps_since_restore: 200000
  timesteps_this_iter: 10000
  timesteps_total: 200000
  training_iteration: 20
  trial_id: fce6b7f4
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2/2 CPUs, 0/0 GPUs
Memory usage on this node: 10.8/201.2 GB
Result logdir: /users/PYS1027/chnrhughes/ray_results/simple_training_example_ring2_v1
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - PPO_WaveAttenuationPOEnv-v0_0:	RUNNING, [2 CPUs, 0 GPUs], [pid=385820], 2024 s, 20 iter, 200000 ts, 1.31e+03 rew

[2m[36m(pid=385821)[0m 
[2m[36m(pid=385821)[0m -----------------------
[2m[36m(pid=385821)[0m ring length: 498
[2m[36m(pid=385821)[0m v_max: 2.8597993346145016
[2m[36m(pid=385821)[0m -----------------------
[2m[36m(pid=385821)[0m 
[2m[36m(pid=385821)[0m -----------------------
[2m[36m(pid=385821)[0m ring length: 492
[2m[36m(pid=385821)[0m v_max: 2.739835119766572
[2m[36m(pid=385821)[0m -----------------------
[2m[36m(pid=385821)[0m 
[2m[36m(pid=385821)[0m -----------------------
[2m[36m(pid=385821)[0m ring length: 505
[2m[36m(pid=385821)[0m v_max: 2.999750077051092
[2m[36m(pid=385821)[0m -----------------------
[2m[36m(pid=385821)[0m 
[2m[36m(pid=385821)[0m -----------------------
[2m[36m(pid=385821)[0m ring length: 503
[2m[36m(pid=385821)[0m v_max: 2.9597650335315784
[2m[36m(pid=385821)[0m -----------------------
[2m[36m(pid=385821)[0m 
[2m[36m(pid=385821)[0m -----------------------
[2m[36m(pid=385821)[0m ring length: 493
[2m[36m(pid=385821)[0m v_max: 2.759829537541262
[2m[36m(pid=385821)[0m -----------------------
Result for PPO_WaveAttenuationPOEnv-v0_0:
  custom_metrics: {}
  date: 2020-03-30_08-49-58
  done: false
  episode_len_mean: 2000.0
  episode_reward_max: 3236.6898899884513
  episode_reward_mean: 1478.534181436451
  episode_reward_min: -673.9917406328241
  episodes_this_iter: 5
  episodes_total: 105
  experiment_id: ba0edb931dde48dcb020df4b454540a2
  hostname: p0035.ten.osc.edu
  info:
    grad_time_ms: 223.012
    learner:
      default_policy:
        cur_kl_coeff: 1.9073486612342094e-07
        cur_lr: 4.999999873689376e-05
        entropy: 0.7693883776664734
        entropy_coeff: 0.0
        kl: 0.003677037078887224
        policy_loss: -0.005946220364421606
        total_loss: 1826.482177734375
        vf_explained_var: 2.0802021026611328e-05
        vf_loss: 1826.488037109375
    load_time_ms: 2.165
    num_steps_sampled: 210000
    num_steps_trained: 210000
    sample_time_ms: 100485.914
    update_time_ms: 2.183
  iterations_since_restore: 21
  node_ip: 10.4.1.36
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 2.618620689655173
    ram_util_percent: 5.3999999999999995
  pid: 385820
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 6.985885166013529
    mean_inference_ms: 0.503970378481427
    mean_processing_ms: 2.6239280052457405
  time_since_restore: 2125.873027563095
  time_this_iter_s: 101.42915058135986
  time_total_s: 2125.873027563095
  timestamp: 1585572598
  timesteps_since_restore: 210000
  timesteps_this_iter: 10000
  timesteps_total: 210000
  training_iteration: 21
  trial_id: fce6b7f4
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2/2 CPUs, 0/0 GPUs
Memory usage on this node: 10.8/201.2 GB
Result logdir: /users/PYS1027/chnrhughes/ray_results/simple_training_example_ring2_v1
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - PPO_WaveAttenuationPOEnv-v0_0:	RUNNING, [2 CPUs, 0 GPUs], [pid=385820], 2125 s, 21 iter, 210000 ts, 1.48e+03 rew

[2m[36m(pid=385821)[0m 
[2m[36m(pid=385821)[0m -----------------------
[2m[36m(pid=385821)[0m ring length: 502
[2m[36m(pid=385821)[0m v_max: 2.9397722404035362
[2m[36m(pid=385821)[0m -----------------------
[2m[36m(pid=385821)[0m 
[2m[36m(pid=385821)[0m -----------------------
[2m[36m(pid=385821)[0m ring length: 518
[2m[36m(pid=385821)[0m v_max: 3.2596334266284783
[2m[36m(pid=385821)[0m -----------------------
[2m[36m(pid=385821)[0m 
[2m[36m(pid=385821)[0m -----------------------
[2m[36m(pid=385821)[0m ring length: 493
[2m[36m(pid=385821)[0m v_max: 2.759829537541262
[2m[36m(pid=385821)[0m -----------------------
[2m[36m(pid=385821)[0m 
[2m[36m(pid=385821)[0m -----------------------
[2m[36m(pid=385821)[0m ring length: 511
[2m[36m(pid=385821)[0m v_max: 3.1197006223865698
[2m[36m(pid=385821)[0m -----------------------
[2m[36m(pid=385821)[0m 
[2m[36m(pid=385821)[0m -----------------------
[2m[36m(pid=385821)[0m ring length: 502
[2m[36m(pid=385821)[0m v_max: 2.9397722404035362
[2m[36m(pid=385821)[0m -----------------------
Result for PPO_WaveAttenuationPOEnv-v0_0:
  custom_metrics: {}
  date: 2020-03-30_08-51-38
  done: false
  episode_len_mean: 2000.0
  episode_reward_max: 3332.094223992922
  episode_reward_mean: 1646.3933650831834
  episode_reward_min: -673.9917406328241
  episodes_this_iter: 5
  episodes_total: 110
  experiment_id: ba0edb931dde48dcb020df4b454540a2
  hostname: p0035.ten.osc.edu
  info:
    grad_time_ms: 221.88
    learner:
      default_policy:
        cur_kl_coeff: 9.536743306171047e-08
        cur_lr: 4.999999873689376e-05
        entropy: 0.7468942999839783
        entropy_coeff: 0.0
        kl: 0.0030867280438542366
        policy_loss: -0.0030347260180860758
        total_loss: 1980.8536376953125
        vf_explained_var: 0.00010538101196289062
        vf_loss: 1980.8564453125
    load_time_ms: 2.173
    num_steps_sampled: 220000
    num_steps_trained: 220000
    sample_time_ms: 100430.745
    update_time_ms: 2.19
  iterations_since_restore: 22
  node_ip: 10.4.1.36
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 2.6718309859154923
    ram_util_percent: 5.399999999999998
  pid: 385820
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 6.973103234824705
    mean_inference_ms: 0.50379681939607
    mean_processing_ms: 2.623026517876667
  time_since_restore: 2225.8130366802216
  time_this_iter_s: 99.94000911712646
  time_total_s: 2225.8130366802216
  timestamp: 1585572698
  timesteps_since_restore: 220000
  timesteps_this_iter: 10000
  timesteps_total: 220000
  training_iteration: 22
  trial_id: fce6b7f4
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2/2 CPUs, 0/0 GPUs
Memory usage on this node: 10.8/201.2 GB
Result logdir: /users/PYS1027/chnrhughes/ray_results/simple_training_example_ring2_v1
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - PPO_WaveAttenuationPOEnv-v0_0:	RUNNING, [2 CPUs, 0 GPUs], [pid=385820], 2225 s, 22 iter, 220000 ts, 1.65e+03 rew

[2m[36m(pid=385821)[0m 
[2m[36m(pid=385821)[0m -----------------------
[2m[36m(pid=385821)[0m ring length: 496
[2m[36m(pid=385821)[0m v_max: 2.819811886031332
[2m[36m(pid=385821)[0m -----------------------
[2m[36m(pid=385821)[0m 
[2m[36m(pid=385821)[0m -----------------------
[2m[36m(pid=385821)[0m ring length: 494
[2m[36m(pid=385821)[0m v_max: 2.7798238064662253
[2m[36m(pid=385821)[0m -----------------------
[2m[36m(pid=385821)[0m 
[2m[36m(pid=385821)[0m -----------------------
[2m[36m(pid=385821)[0m ring length: 518
[2m[36m(pid=385821)[0m v_max: 3.2596334266284783
[2m[36m(pid=385821)[0m -----------------------
[2m[36m(pid=385821)[0m 
[2m[36m(pid=385821)[0m -----------------------
[2m[36m(pid=385821)[0m ring length: 493
[2m[36m(pid=385821)[0m v_max: 2.759829537541262
[2m[36m(pid=385821)[0m -----------------------
[2m[36m(pid=385821)[0m 
[2m[36m(pid=385821)[0m -----------------------
[2m[36m(pid=385821)[0m ring length: 500
[2m[36m(pid=385821)[0m v_max: 2.8997861277614296
[2m[36m(pid=385821)[0m -----------------------
Result for PPO_WaveAttenuationPOEnv-v0_0:
  custom_metrics: {}
  date: 2020-03-30_08-53-18
  done: false
  episode_len_mean: 2000.0
  episode_reward_max: 3434.065816088463
  episode_reward_mean: 1811.2836091898562
  episode_reward_min: -673.9917406328241
  episodes_this_iter: 5
  episodes_total: 115
  experiment_id: ba0edb931dde48dcb020df4b454540a2
  hostname: p0035.ten.osc.edu
  info:
    grad_time_ms: 221.347
    learner:
      default_policy:
        cur_kl_coeff: 4.7683716530855236e-08
        cur_lr: 4.999999873689376e-05
        entropy: 0.73061603307724
        entropy_coeff: 0.0
        kl: 0.0032180408015847206
        policy_loss: -0.0021457115653902292
        total_loss: 2053.380859375
        vf_explained_var: 2.3663043975830078e-05
        vf_loss: 2053.38330078125
    load_time_ms: 2.227
    num_steps_sampled: 230000
    num_steps_trained: 230000
    sample_time_ms: 100355.436
    update_time_ms: 2.156
  iterations_since_restore: 23
  node_ip: 10.4.1.36
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 2.63169014084507
    ram_util_percent: 5.399999999999998
  pid: 385820
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 6.964316386736657
    mean_inference_ms: 0.5036735978211033
    mean_processing_ms: 2.6221268100466153
  time_since_restore: 2325.567067861557
  time_this_iter_s: 99.75403118133545
  time_total_s: 2325.567067861557
  timestamp: 1585572798
  timesteps_since_restore: 230000
  timesteps_this_iter: 10000
  timesteps_total: 230000
  training_iteration: 23
  trial_id: fce6b7f4
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2/2 CPUs, 0/0 GPUs
Memory usage on this node: 10.8/201.2 GB
Result logdir: /users/PYS1027/chnrhughes/ray_results/simple_training_example_ring2_v1
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - PPO_WaveAttenuationPOEnv-v0_0:	RUNNING, [2 CPUs, 0 GPUs], [pid=385820], 2325 s, 23 iter, 230000 ts, 1.81e+03 rew

[2m[36m(pid=385821)[0m 
[2m[36m(pid=385821)[0m -----------------------
[2m[36m(pid=385821)[0m ring length: 503
[2m[36m(pid=385821)[0m v_max: 2.9597650335315784
[2m[36m(pid=385821)[0m -----------------------
[2m[36m(pid=385821)[0m 
[2m[36m(pid=385821)[0m -----------------------
[2m[36m(pid=385821)[0m ring length: 490
[2m[36m(pid=385821)[0m v_max: 2.699845849180192
[2m[36m(pid=385821)[0m -----------------------
[2m[36m(pid=385821)[0m 
[2m[36m(pid=385821)[0m -----------------------
[2m[36m(pid=385821)[0m ring length: 512
[2m[36m(pid=385821)[0m v_max: 3.139691674719026
[2m[36m(pid=385821)[0m -----------------------
[2m[36m(pid=385821)[0m 
[2m[36m(pid=385821)[0m -----------------------
[2m[36m(pid=385821)[0m ring length: 516
[2m[36m(pid=385821)[0m v_max: 3.2196537366217006
[2m[36m(pid=385821)[0m -----------------------
[2m[36m(pid=385821)[0m 
[2m[36m(pid=385821)[0m -----------------------
[2m[36m(pid=385821)[0m ring length: 490
[2m[36m(pid=385821)[0m v_max: 2.699845849180192
[2m[36m(pid=385821)[0m -----------------------
Result for PPO_WaveAttenuationPOEnv-v0_0:
  custom_metrics: {}
  date: 2020-03-30_08-54-58
  done: false
  episode_len_mean: 2000.0
  episode_reward_max: 3582.089087429403
  episode_reward_mean: 1991.2233665105405
  episode_reward_min: -433.8311561938026
  episodes_this_iter: 5
  episodes_total: 120
  experiment_id: ba0edb931dde48dcb020df4b454540a2
  hostname: p0035.ten.osc.edu
  info:
    grad_time_ms: 221.995
    learner:
      default_policy:
        cur_kl_coeff: 2.3841858265427618e-08
        cur_lr: 4.999999873689376e-05
        entropy: 0.7072645425796509
        entropy_coeff: 0.0
        kl: 0.0025408363435417414
        policy_loss: -0.0035999449901282787
        total_loss: 2223.9619140625
        vf_explained_var: 3.5762786865234375e-05
        vf_loss: 2223.96533203125
    load_time_ms: 2.262
    num_steps_sampled: 240000
    num_steps_trained: 240000
    sample_time_ms: 100324.823
    update_time_ms: 2.254
  iterations_since_restore: 24
  node_ip: 10.4.1.36
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 2.627272727272727
    ram_util_percent: 5.399999999999999
  pid: 385820
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 6.957943126540445
    mean_inference_ms: 0.503446296218899
    mean_processing_ms: 2.621190569545165
  time_since_restore: 2425.9680852890015
  time_this_iter_s: 100.40101742744446
  time_total_s: 2425.9680852890015
  timestamp: 1585572898
  timesteps_since_restore: 240000
  timesteps_this_iter: 10000
  timesteps_total: 240000
  training_iteration: 24
  trial_id: fce6b7f4
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2/2 CPUs, 0/0 GPUs
Memory usage on this node: 10.8/201.2 GB
Result logdir: /users/PYS1027/chnrhughes/ray_results/simple_training_example_ring2_v1
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - PPO_WaveAttenuationPOEnv-v0_0:	RUNNING, [2 CPUs, 0 GPUs], [pid=385820], 2425 s, 24 iter, 240000 ts, 1.99e+03 rew

[2m[36m(pid=385821)[0m 
[2m[36m(pid=385821)[0m -----------------------
[2m[36m(pid=385821)[0m ring length: 500
[2m[36m(pid=385821)[0m v_max: 2.8997861277614296
[2m[36m(pid=385821)[0m -----------------------
[2m[36m(pid=385821)[0m 
[2m[36m(pid=385821)[0m -----------------------
[2m[36m(pid=385821)[0m ring length: 519
[2m[36m(pid=385821)[0m v_max: 3.2796229229775036
[2m[36m(pid=385821)[0m -----------------------
[2m[36m(pid=385821)[0m 
[2m[36m(pid=385821)[0m -----------------------
[2m[36m(pid=385821)[0m ring length: 502
[2m[36m(pid=385821)[0m v_max: 2.9397722404035362
[2m[36m(pid=385821)[0m -----------------------
[2m[36m(pid=385821)[0m 
[2m[36m(pid=385821)[0m -----------------------
[2m[36m(pid=385821)[0m ring length: 509
[2m[36m(pid=385821)[0m v_max: 3.0797178990784078
[2m[36m(pid=385821)[0m -----------------------
[2m[36m(pid=385821)[0m 
[2m[36m(pid=385821)[0m -----------------------
[2m[36m(pid=385821)[0m ring length: 515
[2m[36m(pid=385821)[0m v_max: 3.199663550695237
[2m[36m(pid=385821)[0m -----------------------
Result for PPO_WaveAttenuationPOEnv-v0_0:
  custom_metrics: {}
  date: 2020-03-30_08-56-39
  done: false
  episode_len_mean: 2000.0
  episode_reward_max: 3582.089087429403
  episode_reward_mean: 2148.4191178298815
  episode_reward_min: -433.8311561938026
  episodes_this_iter: 5
  episodes_total: 125
  experiment_id: ba0edb931dde48dcb020df4b454540a2
  hostname: p0035.ten.osc.edu
  info:
    grad_time_ms: 219.943
    learner:
      default_policy:
        cur_kl_coeff: 1.1920929132713809e-08
        cur_lr: 4.999999873689376e-05
        entropy: 0.6875144839286804
        entropy_coeff: 0.0
        kl: 0.0021277631167322397
        policy_loss: -0.0027627204544842243
        total_loss: 2131.124755859375
        vf_explained_var: 8.553266525268555e-05
        vf_loss: 2131.127685546875
    load_time_ms: 2.257
    num_steps_sampled: 250000
    num_steps_trained: 250000
    sample_time_ms: 100415.28
    update_time_ms: 2.246
  iterations_since_restore: 25
  node_ip: 10.4.1.36
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 2.613194444444445
    ram_util_percent: 5.3999999999999995
  pid: 385820
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 6.953010483312339
    mean_inference_ms: 0.5031908981989559
    mean_processing_ms: 2.6203738714338023
  time_since_restore: 2527.4021689891815
  time_this_iter_s: 101.43408370018005
  time_total_s: 2527.4021689891815
  timestamp: 1585572999
  timesteps_since_restore: 250000
  timesteps_this_iter: 10000
  timesteps_total: 250000
  training_iteration: 25
  trial_id: fce6b7f4
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2/2 CPUs, 0/0 GPUs
Memory usage on this node: 10.8/201.2 GB
Result logdir: /users/PYS1027/chnrhughes/ray_results/simple_training_example_ring2_v1
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - PPO_WaveAttenuationPOEnv-v0_0:	RUNNING, [2 CPUs, 0 GPUs], [pid=385820], 2527 s, 25 iter, 250000 ts, 2.15e+03 rew

[2m[36m(pid=385820)[0m 2020-03-30 08:56:39,950	WARNING ppo.py:121 -- The magnitude of your environment rewards are more than 215.0x the scale of `vf_clip_param`. This means that it will take more than 215.0 iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.
[2m[36m(pid=385821)[0m 
[2m[36m(pid=385821)[0m -----------------------
[2m[36m(pid=385821)[0m ring length: 513
[2m[36m(pid=385821)[0m v_max: 3.1596825160053825
[2m[36m(pid=385821)[0m -----------------------
[2m[36m(pid=385821)[0m 
[2m[36m(pid=385821)[0m -----------------------
[2m[36m(pid=385821)[0m ring length: 518
[2m[36m(pid=385821)[0m v_max: 3.2596334266284783
[2m[36m(pid=385821)[0m -----------------------
[2m[36m(pid=385821)[0m 
[2m[36m(pid=385821)[0m -----------------------
[2m[36m(pid=385821)[0m ring length: 514
[2m[36m(pid=385821)[0m v_max: 3.1796731425699525
[2m[36m(pid=385821)[0m -----------------------
[2m[36m(pid=385821)[0m 
[2m[36m(pid=385821)[0m -----------------------
[2m[36m(pid=385821)[0m ring length: 492
[2m[36m(pid=385821)[0m v_max: 2.739835119766572
[2m[36m(pid=385821)[0m -----------------------
[2m[36m(pid=385821)[0m 
[2m[36m(pid=385821)[0m -----------------------
[2m[36m(pid=385821)[0m ring length: 508
[2m[36m(pid=385821)[0m v_max: 3.059726235247059
[2m[36m(pid=385821)[0m -----------------------
Result for PPO_WaveAttenuationPOEnv-v0_0:
  custom_metrics: {}
  date: 2020-03-30_08-58-20
  done: false
  episode_len_mean: 2000.0
  episode_reward_max: 3690.8205502481155
  episode_reward_mean: 2308.33685127469
  episode_reward_min: -433.8311561938026
  episodes_this_iter: 5
  episodes_total: 130
  experiment_id: ba0edb931dde48dcb020df4b454540a2
  hostname: p0035.ten.osc.edu
  info:
    grad_time_ms: 219.2
    learner:
      default_policy:
        cur_kl_coeff: 5.9604645663569045e-09
        cur_lr: 4.999999873689376e-05
        entropy: 0.6696827411651611
        entropy_coeff: 0.0
        kl: 0.008854096755385399
        policy_loss: -0.0030214295256882906
        total_loss: 2398.763671875
        vf_explained_var: 3.49879264831543e-05
        vf_loss: 2398.766845703125
    load_time_ms: 2.264
    num_steps_sampled: 260000
    num_steps_trained: 260000
    sample_time_ms: 100455.047
    update_time_ms: 2.229
  iterations_since_restore: 26
  node_ip: 10.4.1.36
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 2.6500000000000004
    ram_util_percent: 5.3999999999999995
  pid: 385820
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 6.949163297951561
    mean_inference_ms: 0.5030119140464098
    mean_processing_ms: 2.6196313480451754
  time_since_restore: 2628.2232496738434
  time_this_iter_s: 100.82108068466187
  time_total_s: 2628.2232496738434
  timestamp: 1585573100
  timesteps_since_restore: 260000
  timesteps_this_iter: 10000
  timesteps_total: 260000
  training_iteration: 26
  trial_id: fce6b7f4
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2/2 CPUs, 0/0 GPUs
Memory usage on this node: 10.8/201.2 GB
Result logdir: /users/PYS1027/chnrhughes/ray_results/simple_training_example_ring2_v1
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - PPO_WaveAttenuationPOEnv-v0_0:	RUNNING, [2 CPUs, 0 GPUs], [pid=385820], 2628 s, 26 iter, 260000 ts, 2.31e+03 rew

[2m[36m(pid=385820)[0m 2020-03-30 08:58:20,796	WARNING ppo.py:121 -- The magnitude of your environment rewards are more than 231.0x the scale of `vf_clip_param`. This means that it will take more than 231.0 iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.
[2m[36m(pid=385821)[0m 
[2m[36m(pid=385821)[0m -----------------------
[2m[36m(pid=385821)[0m ring length: 508
[2m[36m(pid=385821)[0m v_max: 3.059726235247059
[2m[36m(pid=385821)[0m -----------------------
[2m[36m(pid=385821)[0m 
[2m[36m(pid=385821)[0m -----------------------
[2m[36m(pid=385821)[0m ring length: 493
[2m[36m(pid=385821)[0m v_max: 2.759829537541262
[2m[36m(pid=385821)[0m -----------------------
[2m[36m(pid=385821)[0m 
[2m[36m(pid=385821)[0m -----------------------
[2m[36m(pid=385821)[0m ring length: 508
[2m[36m(pid=385821)[0m v_max: 3.059726235247059
[2m[36m(pid=385821)[0m -----------------------
[2m[36m(pid=385821)[0m 
[2m[36m(pid=385821)[0m -----------------------
[2m[36m(pid=385821)[0m ring length: 516
[2m[36m(pid=385821)[0m v_max: 3.2196537366217006
[2m[36m(pid=385821)[0m -----------------------
[2m[36m(pid=385821)[0m 
[2m[36m(pid=385821)[0m -----------------------
[2m[36m(pid=385821)[0m ring length: 490
[2m[36m(pid=385821)[0m v_max: 2.699845849180192
[2m[36m(pid=385821)[0m -----------------------
Result for PPO_WaveAttenuationPOEnv-v0_0:
  custom_metrics: {}
  date: 2020-03-30_09-00-01
  done: false
  episode_len_mean: 2000.0
  episode_reward_max: 3690.8205502481155
  episode_reward_mean: 2445.410027004904
  episode_reward_min: 521.3390294941165
  episodes_this_iter: 5
  episodes_total: 135
  experiment_id: ba0edb931dde48dcb020df4b454540a2
  hostname: p0035.ten.osc.edu
  info:
    grad_time_ms: 218.77
    learner:
      default_policy:
        cur_kl_coeff: 2.9802322831784522e-09
        cur_lr: 4.999999873689376e-05
        entropy: 0.6768926978111267
        entropy_coeff: 0.0
        kl: 0.002540187444537878
        policy_loss: -0.0026579059194773436
        total_loss: 1712.5107421875
        vf_explained_var: 0.001438438892364502
        vf_loss: 1712.51318359375
    load_time_ms: 2.266
    num_steps_sampled: 270000
    num_steps_trained: 270000
    sample_time_ms: 100460.854
    update_time_ms: 2.239
  iterations_since_restore: 27
  node_ip: 10.4.1.36
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 2.5937062937062936
    ram_util_percent: 5.399999999999999
  pid: 385820
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 6.9462963515581775
    mean_inference_ms: 0.502960426717793
    mean_processing_ms: 2.6189853333235247
  time_since_restore: 2728.6996994018555
  time_this_iter_s: 100.47644972801208
  time_total_s: 2728.6996994018555
  timestamp: 1585573201
  timesteps_since_restore: 270000
  timesteps_this_iter: 10000
  timesteps_total: 270000
  training_iteration: 27
  trial_id: fce6b7f4
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2/2 CPUs, 0/0 GPUs
Memory usage on this node: 10.8/201.2 GB
Result logdir: /users/PYS1027/chnrhughes/ray_results/simple_training_example_ring2_v1
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - PPO_WaveAttenuationPOEnv-v0_0:	RUNNING, [2 CPUs, 0 GPUs], [pid=385820], 2728 s, 27 iter, 270000 ts, 2.45e+03 rew

[2m[36m(pid=385820)[0m 2020-03-30 09:00:01,283	WARNING ppo.py:121 -- The magnitude of your environment rewards are more than 245.0x the scale of `vf_clip_param`. This means that it will take more than 245.0 iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.
[2m[36m(pid=385821)[0m 
[2m[36m(pid=385821)[0m -----------------------
[2m[36m(pid=385821)[0m ring length: 495
[2m[36m(pid=385821)[0m v_max: 2.79981792361692
[2m[36m(pid=385821)[0m -----------------------
[2m[36m(pid=385821)[0m 
[2m[36m(pid=385821)[0m -----------------------
[2m[36m(pid=385821)[0m ring length: 509
[2m[36m(pid=385821)[0m v_max: 3.0797178990784078
[2m[36m(pid=385821)[0m -----------------------
[2m[36m(pid=385821)[0m 
[2m[36m(pid=385821)[0m -----------------------
[2m[36m(pid=385821)[0m ring length: 496
[2m[36m(pid=385821)[0m v_max: 2.819811886031332
[2m[36m(pid=385821)[0m -----------------------
[2m[36m(pid=385821)[0m 
[2m[36m(pid=385821)[0m -----------------------
[2m[36m(pid=385821)[0m ring length: 491
[2m[36m(pid=385821)[0m v_max: 2.719840556029452
[2m[36m(pid=385821)[0m -----------------------
[2m[36m(pid=385821)[0m 
[2m[36m(pid=385821)[0m -----------------------
[2m[36m(pid=385821)[0m ring length: 513
[2m[36m(pid=385821)[0m v_max: 3.1596825160053825
[2m[36m(pid=385821)[0m -----------------------
Result for PPO_WaveAttenuationPOEnv-v0_0:
  custom_metrics: {}
  date: 2020-03-30_09-01-41
  done: false
  episode_len_mean: 2000.0
  episode_reward_max: 3690.8205502481155
  episode_reward_mean: 2547.5424210241968
  episode_reward_min: 754.5535867686482
  episodes_this_iter: 5
  episodes_total: 140
  experiment_id: ba0edb931dde48dcb020df4b454540a2
  hostname: p0035.ten.osc.edu
  info:
    grad_time_ms: 219.678
    learner:
      default_policy:
        cur_kl_coeff: 1.4901161415892261e-09
        cur_lr: 4.999999873689376e-05
        entropy: 0.6676769256591797
        entropy_coeff: 0.0
        kl: 0.005903230980038643
        policy_loss: -0.0037446357309818268
        total_loss: 1509.0850830078125
        vf_explained_var: 0.0031843185424804688
        vf_loss: 1509.0889892578125
    load_time_ms: 2.263
    num_steps_sampled: 280000
    num_steps_trained: 280000
    sample_time_ms: 100395.927
    update_time_ms: 2.231
  iterations_since_restore: 28
  node_ip: 10.4.1.36
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 2.5937062937062936
    ram_util_percent: 5.399999999999999
  pid: 385820
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 6.943772205672812
    mean_inference_ms: 0.5030737062641354
    mean_processing_ms: 2.6184920437247197
  time_since_restore: 2829.011884689331
  time_this_iter_s: 100.31218528747559
  time_total_s: 2829.011884689331
  timestamp: 1585573301
  timesteps_since_restore: 280000
  timesteps_this_iter: 10000
  timesteps_total: 280000
  training_iteration: 28
  trial_id: fce6b7f4
  
[2m[36m(pid=385820)[0m 2020-03-30 09:01:41,605	WARNING ppo.py:121 -- The magnitude of your environment rewards are more than 255.0x the scale of `vf_clip_param`. This means that it will take more than 255.0 iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2/2 CPUs, 0/0 GPUs
Memory usage on this node: 10.8/201.2 GB
Result logdir: /users/PYS1027/chnrhughes/ray_results/simple_training_example_ring2_v1
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - PPO_WaveAttenuationPOEnv-v0_0:	RUNNING, [2 CPUs, 0 GPUs], [pid=385820], 2829 s, 28 iter, 280000 ts, 2.55e+03 rew

[2m[36m(pid=385821)[0m 
[2m[36m(pid=385821)[0m -----------------------
[2m[36m(pid=385821)[0m ring length: 515
[2m[36m(pid=385821)[0m v_max: 3.199663550695237
[2m[36m(pid=385821)[0m -----------------------
[2m[36m(pid=385821)[0m 
[2m[36m(pid=385821)[0m -----------------------
[2m[36m(pid=385821)[0m ring length: 513
[2m[36m(pid=385821)[0m v_max: 3.1596825160053825
[2m[36m(pid=385821)[0m -----------------------
[2m[36m(pid=385821)[0m 
[2m[36m(pid=385821)[0m -----------------------
[2m[36m(pid=385821)[0m ring length: 492
[2m[36m(pid=385821)[0m v_max: 2.739835119766572
[2m[36m(pid=385821)[0m -----------------------
[2m[36m(pid=385821)[0m 
[2m[36m(pid=385821)[0m -----------------------
[2m[36m(pid=385821)[0m ring length: 508
[2m[36m(pid=385821)[0m v_max: 3.059726235247059
[2m[36m(pid=385821)[0m -----------------------
[2m[36m(pid=385821)[0m 
[2m[36m(pid=385821)[0m -----------------------
[2m[36m(pid=385821)[0m ring length: 514
[2m[36m(pid=385821)[0m v_max: 3.1796731425699525
[2m[36m(pid=385821)[0m -----------------------
Result for PPO_WaveAttenuationPOEnv-v0_0:
  custom_metrics: {}
  date: 2020-03-30_09-03-22
  done: false
  episode_len_mean: 2000.0
  episode_reward_max: 3690.8205502481155
  episode_reward_mean: 2658.70307542602
  episode_reward_min: 1048.0126132594855
  episodes_this_iter: 5
  episodes_total: 145
  experiment_id: ba0edb931dde48dcb020df4b454540a2
  hostname: p0035.ten.osc.edu
  info:
    grad_time_ms: 220.262
    learner:
      default_policy:
        cur_kl_coeff: 7.450580707946131e-10
        cur_lr: 4.999999873689376e-05
        entropy: 0.6282535195350647
        entropy_coeff: 0.0
        kl: 0.0006145433872006834
        policy_loss: -0.0006565831135958433
        total_loss: 2179.507080078125
        vf_explained_var: 0.00026786327362060547
        vf_loss: 2179.507568359375
    load_time_ms: 2.37
    num_steps_sampled: 290000
    num_steps_trained: 290000
    sample_time_ms: 100388.896
    update_time_ms: 2.348
  iterations_since_restore: 29
  node_ip: 10.4.1.36
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 2.6312499999999996
    ram_util_percent: 5.3999999999999995
  pid: 385820
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 6.941620249761721
    mean_inference_ms: 0.5031237544283963
    mean_processing_ms: 2.6180865581376476
  time_since_restore: 2929.8189902305603
  time_this_iter_s: 100.80710554122925
  time_total_s: 2929.8189902305603
  timestamp: 1585573402
  timesteps_since_restore: 290000
  timesteps_this_iter: 10000
  timesteps_total: 290000
  training_iteration: 29
  trial_id: fce6b7f4
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2/2 CPUs, 0/0 GPUs
Memory usage on this node: 10.8/201.2 GB
Result logdir: /users/PYS1027/chnrhughes/ray_results/simple_training_example_ring2_v1
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - PPO_WaveAttenuationPOEnv-v0_0:	RUNNING, [2 CPUs, 0 GPUs], [pid=385820], 2929 s, 29 iter, 290000 ts, 2.66e+03 rew

[2m[36m(pid=385820)[0m 2020-03-30 09:03:22,425	WARNING ppo.py:121 -- The magnitude of your environment rewards are more than 266.0x the scale of `vf_clip_param`. This means that it will take more than 266.0 iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.
[2m[36m(pid=385821)[0m 
[2m[36m(pid=385821)[0m -----------------------
[2m[36m(pid=385821)[0m ring length: 512
[2m[36m(pid=385821)[0m v_max: 3.139691674719026
[2m[36m(pid=385821)[0m -----------------------
[2m[36m(pid=385821)[0m 
[2m[36m(pid=385821)[0m -----------------------
[2m[36m(pid=385821)[0m ring length: 502
[2m[36m(pid=385821)[0m v_max: 2.9397722404035362
[2m[36m(pid=385821)[0m -----------------------
[2m[36m(pid=385821)[0m 
[2m[36m(pid=385821)[0m -----------------------
[2m[36m(pid=385821)[0m ring length: 517
[2m[36m(pid=385821)[0m v_max: 3.2396436965475437
[2m[36m(pid=385821)[0m -----------------------
[2m[36m(pid=385821)[0m 
[2m[36m(pid=385821)[0m -----------------------
[2m[36m(pid=385821)[0m ring length: 514
[2m[36m(pid=385821)[0m v_max: 3.1796731425699525
[2m[36m(pid=385821)[0m -----------------------
[2m[36m(pid=385821)[0m 
[2m[36m(pid=385821)[0m -----------------------
[2m[36m(pid=385821)[0m ring length: 498
[2m[36m(pid=385821)[0m v_max: 2.8597993346145016
[2m[36m(pid=385821)[0m -----------------------
Result for PPO_WaveAttenuationPOEnv-v0_0:
  custom_metrics: {}
  date: 2020-03-30_09-05-02
  done: false
  episode_len_mean: 2000.0
  episode_reward_max: 3690.8205502481155
  episode_reward_mean: 2754.1566255606485
  episode_reward_min: 1308.3828946712847
  episodes_this_iter: 5
  episodes_total: 150
  experiment_id: ba0edb931dde48dcb020df4b454540a2
  hostname: p0035.ten.osc.edu
  info:
    grad_time_ms: 220.007
    learner:
      default_policy:
        cur_kl_coeff: 3.7252903539730653e-10
        cur_lr: 4.999999873689376e-05
        entropy: 0.6095687747001648
        entropy_coeff: 0.0
        kl: 0.0018285415135324001
        policy_loss: -0.002402570331469178
        total_loss: 2224.40087890625
        vf_explained_var: 0.0003789067268371582
        vf_loss: 2224.40283203125
    load_time_ms: 2.371
    num_steps_sampled: 300000
    num_steps_trained: 300000
    sample_time_ms: 100347.524
    update_time_ms: 2.346
  iterations_since_restore: 30
  node_ip: 10.4.1.36
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 2.648951048951049
    ram_util_percent: 5.399999999999999
  pid: 385820
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 6.939488347948956
    mean_inference_ms: 0.5032599851176931
    mean_processing_ms: 2.6177927592776005
  time_since_restore: 3030.2416183948517
  time_this_iter_s: 100.42262816429138
  time_total_s: 3030.2416183948517
  timestamp: 1585573502
  timesteps_since_restore: 300000
  timesteps_this_iter: 10000
  timesteps_total: 300000
  training_iteration: 30
  trial_id: fce6b7f4
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2/2 CPUs, 0/0 GPUs
Memory usage on this node: 10.8/201.2 GB
Result logdir: /users/PYS1027/chnrhughes/ray_results/simple_training_example_ring2_v1
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - PPO_WaveAttenuationPOEnv-v0_0:	RUNNING, [2 CPUs, 0 GPUs], [pid=385820], 3030 s, 30 iter, 300000 ts, 2.75e+03 rew

[2m[36m(pid=385820)[0m 2020-03-30 09:05:02,858	WARNING ppo.py:121 -- The magnitude of your environment rewards are more than 275.0x the scale of `vf_clip_param`. This means that it will take more than 275.0 iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.
[2m[36m(pid=385821)[0m 
[2m[36m(pid=385821)[0m -----------------------
[2m[36m(pid=385821)[0m ring length: 498
[2m[36m(pid=385821)[0m v_max: 2.8597993346145016
[2m[36m(pid=385821)[0m -----------------------
[2m[36m(pid=385821)[0m 
[2m[36m(pid=385821)[0m -----------------------
[2m[36m(pid=385821)[0m ring length: 514
[2m[36m(pid=385821)[0m v_max: 3.1796731425699525
[2m[36m(pid=385821)[0m -----------------------
[2m[36m(pid=385821)[0m 
[2m[36m(pid=385821)[0m -----------------------
[2m[36m(pid=385821)[0m ring length: 504
[2m[36m(pid=385821)[0m v_max: 2.979757646850631
[2m[36m(pid=385821)[0m -----------------------
[2m[36m(pid=385821)[0m 
[2m[36m(pid=385821)[0m -----------------------
[2m[36m(pid=385821)[0m ring length: 510
[2m[36m(pid=385821)[0m v_max: 3.0997093626421153
[2m[36m(pid=385821)[0m -----------------------
[2m[36m(pid=385821)[0m 
[2m[36m(pid=385821)[0m -----------------------
[2m[36m(pid=385821)[0m ring length: 504
[2m[36m(pid=385821)[0m v_max: 2.979757646850631
[2m[36m(pid=385821)[0m -----------------------
Result for PPO_WaveAttenuationPOEnv-v0_0:
  custom_metrics: {}
  date: 2020-03-30_09-06-43
  done: false
  episode_len_mean: 2000.0
  episode_reward_max: 3690.8205502481155
  episode_reward_mean: 2849.683224278012
  episode_reward_min: 1536.0330095038541
  episodes_this_iter: 5
  episodes_total: 155
  experiment_id: ba0edb931dde48dcb020df4b454540a2
  hostname: p0035.ten.osc.edu
  info:
    grad_time_ms: 220.834
    learner:
      default_policy:
        cur_kl_coeff: 1.8626451769865326e-10
        cur_lr: 4.999999873689376e-05
        entropy: 0.5843765139579773
        entropy_coeff: 0.0
        kl: 0.0024560955353081226
        policy_loss: -0.002522760070860386
        total_loss: 2244.551513671875
        vf_explained_var: 0.00020807981491088867
        vf_loss: 2244.5546875
    load_time_ms: 2.366
    num_steps_sampled: 310000
    num_steps_trained: 310000
    sample_time_ms: 100268.717
    update_time_ms: 2.331
  iterations_since_restore: 31
  node_ip: 10.4.1.36
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 2.5930069930069926
    ram_util_percent: 5.399999999999999
  pid: 385820
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 6.9375249847386975
    mean_inference_ms: 0.503457789411416
    mean_processing_ms: 2.61750659685361
  time_since_restore: 3130.892070531845
  time_this_iter_s: 100.65045213699341
  time_total_s: 3130.892070531845
  timestamp: 1585573603
  timesteps_since_restore: 310000
  timesteps_this_iter: 10000
  timesteps_total: 310000
  training_iteration: 31
  trial_id: fce6b7f4
  
[2m[36m(pid=385820)[0m 2020-03-30 09:06:43,535	WARNING ppo.py:121 -- The magnitude of your environment rewards are more than 285.0x the scale of `vf_clip_param`. This means that it will take more than 285.0 iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2/2 CPUs, 0/0 GPUs
Memory usage on this node: 10.8/201.2 GB
Result logdir: /users/PYS1027/chnrhughes/ray_results/simple_training_example_ring2_v1
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - PPO_WaveAttenuationPOEnv-v0_0:	RUNNING, [2 CPUs, 0 GPUs], [pid=385820], 3130 s, 31 iter, 310000 ts, 2.85e+03 rew

[2m[36m(pid=385821)[0m 
[2m[36m(pid=385821)[0m -----------------------
[2m[36m(pid=385821)[0m ring length: 498
[2m[36m(pid=385821)[0m v_max: 2.8597993346145016
[2m[36m(pid=385821)[0m -----------------------
[2m[36m(pid=385821)[0m 
[2m[36m(pid=385821)[0m -----------------------
[2m[36m(pid=385821)[0m ring length: 502
[2m[36m(pid=385821)[0m v_max: 2.9397722404035362
[2m[36m(pid=385821)[0m -----------------------
[2m[36m(pid=385821)[0m 
[2m[36m(pid=385821)[0m -----------------------
[2m[36m(pid=385821)[0m ring length: 497
[2m[36m(pid=385821)[0m v_max: 2.839805690709741
[2m[36m(pid=385821)[0m -----------------------
[2m[36m(pid=385821)[0m 
[2m[36m(pid=385821)[0m -----------------------
[2m[36m(pid=385821)[0m ring length: 520
[2m[36m(pid=385821)[0m v_max: 3.2996121816646764
[2m[36m(pid=385821)[0m -----------------------
[2m[36m(pid=385821)[0m 
[2m[36m(pid=385821)[0m -----------------------
[2m[36m(pid=385821)[0m ring length: 515
[2m[36m(pid=385821)[0m v_max: 3.199663550695237
[2m[36m(pid=385821)[0m -----------------------
Result for PPO_WaveAttenuationPOEnv-v0_0:
  custom_metrics: {}
  date: 2020-03-30_09-08-24
  done: false
  episode_len_mean: 2000.0
  episode_reward_max: 3690.8205502481155
  episode_reward_mean: 2937.6101211043333
  episode_reward_min: 1570.9730381946074
  episodes_this_iter: 5
  episodes_total: 160
  experiment_id: ba0edb931dde48dcb020df4b454540a2
  hostname: p0035.ten.osc.edu
  info:
    grad_time_ms: 222.097
    learner:
      default_policy:
        cur_kl_coeff: 9.313225884932663e-11
        cur_lr: 4.999999873689376e-05
        entropy: 0.5682555437088013
        entropy_coeff: 0.0
        kl: 0.0072872391901910305
        policy_loss: -0.0017995864618569613
        total_loss: 2395.9580078125
        vf_explained_var: 0.00016939640045166016
        vf_loss: 2395.95947265625
    load_time_ms: 2.386
    num_steps_sampled: 320000
    num_steps_trained: 320000
    sample_time_ms: 100369.318
    update_time_ms: 2.341
  iterations_since_restore: 32
  node_ip: 10.4.1.36
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 2.647916666666667
    ram_util_percent: 5.3999999999999995
  pid: 385820
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 6.935727745877885
    mean_inference_ms: 0.5037469378675403
    mean_processing_ms: 2.6172820350804114
  time_since_restore: 3231.8538975715637
  time_this_iter_s: 100.96182703971863
  time_total_s: 3231.8538975715637
  timestamp: 1585573704
  timesteps_since_restore: 320000
  timesteps_this_iter: 10000
  timesteps_total: 320000
  training_iteration: 32
  trial_id: fce6b7f4
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2/2 CPUs, 0/0 GPUs
Memory usage on this node: 10.8/201.2 GB
Result logdir: /users/PYS1027/chnrhughes/ray_results/simple_training_example_ring2_v1
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - PPO_WaveAttenuationPOEnv-v0_0:	RUNNING, [2 CPUs, 0 GPUs], [pid=385820], 3231 s, 32 iter, 320000 ts, 2.94e+03 rew

[2m[36m(pid=385820)[0m 2020-03-30 09:08:24,507	WARNING ppo.py:121 -- The magnitude of your environment rewards are more than 294.0x the scale of `vf_clip_param`. This means that it will take more than 294.0 iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.
[2m[36m(pid=385821)[0m 
[2m[36m(pid=385821)[0m -----------------------
[2m[36m(pid=385821)[0m ring length: 512
[2m[36m(pid=385821)[0m v_max: 3.139691674719026
[2m[36m(pid=385821)[0m -----------------------
[2m[36m(pid=385821)[0m 
[2m[36m(pid=385821)[0m -----------------------
[2m[36m(pid=385821)[0m ring length: 510
[2m[36m(pid=385821)[0m v_max: 3.0997093626421153
[2m[36m(pid=385821)[0m -----------------------
[2m[36m(pid=385821)[0m 
[2m[36m(pid=385821)[0m -----------------------
[2m[36m(pid=385821)[0m ring length: 499
[2m[36m(pid=385821)[0m v_max: 2.8797928146697993
[2m[36m(pid=385821)[0m -----------------------
[2m[36m(pid=385821)[0m 
[2m[36m(pid=385821)[0m -----------------------
[2m[36m(pid=385821)[0m ring length: 501
[2m[36m(pid=385821)[0m v_max: 2.919779270736568
[2m[36m(pid=385821)[0m -----------------------
[2m[36m(pid=385821)[0m 
[2m[36m(pid=385821)[0m -----------------------
[2m[36m(pid=385821)[0m ring length: 520
[2m[36m(pid=385821)[0m v_max: 3.2996121816646764
[2m[36m(pid=385821)[0m -----------------------
Result for PPO_WaveAttenuationPOEnv-v0_0:
  custom_metrics: {}
  date: 2020-03-30_09-10-05
  done: false
  episode_len_mean: 2000.0
  episode_reward_max: 3892.762126056608
  episode_reward_mean: 3034.3886899024524
  episode_reward_min: 1711.4905425164322
  episodes_this_iter: 5
  episodes_total: 165
  experiment_id: ba0edb931dde48dcb020df4b454540a2
  hostname: p0035.ten.osc.edu
  info:
    grad_time_ms: 222.498
    learner:
      default_policy:
        cur_kl_coeff: 4.6566129424663316e-11
        cur_lr: 4.999999873689376e-05
        entropy: 0.5442785024642944
        entropy_coeff: 0.0
        kl: 0.00206534075550735
        policy_loss: -0.0016790889203548431
        total_loss: 2860.461181640625
        vf_explained_var: 4.5299530029296875e-06
        vf_loss: 2860.463134765625
    load_time_ms: 2.611
    num_steps_sampled: 330000
    num_steps_trained: 330000
    sample_time_ms: 100455.281
    update_time_ms: 2.379
  iterations_since_restore: 33
  node_ip: 10.4.1.36
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 2.6370629370629373
    ram_util_percent: 5.399999999999999
  pid: 385820
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 6.934100192308133
    mean_inference_ms: 0.5039979132534185
    mean_processing_ms: 2.617144130059957
  time_since_restore: 3332.478589773178
  time_this_iter_s: 100.62469220161438
  time_total_s: 3332.478589773178
  timestamp: 1585573805
  timesteps_since_restore: 330000
  timesteps_this_iter: 10000
  timesteps_total: 330000
  training_iteration: 33
  trial_id: fce6b7f4
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2/2 CPUs, 0/0 GPUs
Memory usage on this node: 10.8/201.2 GB
Result logdir: /users/PYS1027/chnrhughes/ray_results/simple_training_example_ring2_v1
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - PPO_WaveAttenuationPOEnv-v0_0:	RUNNING, [2 CPUs, 0 GPUs], [pid=385820], 3332 s, 33 iter, 330000 ts, 3.03e+03 rew

[2m[36m(pid=385820)[0m 2020-03-30 09:10:05,140	WARNING ppo.py:121 -- The magnitude of your environment rewards are more than 303.0x the scale of `vf_clip_param`. This means that it will take more than 303.0 iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.
[2m[36m(pid=385821)[0m 
[2m[36m(pid=385821)[0m -----------------------
[2m[36m(pid=385821)[0m ring length: 492
[2m[36m(pid=385821)[0m v_max: 2.739835119766572
[2m[36m(pid=385821)[0m -----------------------
[2m[36m(pid=385821)[0m 
[2m[36m(pid=385821)[0m -----------------------
[2m[36m(pid=385821)[0m ring length: 499
[2m[36m(pid=385821)[0m v_max: 2.8797928146697993
[2m[36m(pid=385821)[0m -----------------------
[2m[36m(pid=385821)[0m 
[2m[36m(pid=385821)[0m -----------------------
[2m[36m(pid=385821)[0m ring length: 492
[2m[36m(pid=385821)[0m v_max: 2.739835119766572
[2m[36m(pid=385821)[0m -----------------------
[2m[36m(pid=385821)[0m 
[2m[36m(pid=385821)[0m -----------------------
[2m[36m(pid=385821)[0m ring length: 501
[2m[36m(pid=385821)[0m v_max: 2.919779270736568
[2m[36m(pid=385821)[0m -----------------------
[2m[36m(pid=385821)[0m 
[2m[36m(pid=385821)[0m -----------------------
[2m[36m(pid=385821)[0m ring length: 514
[2m[36m(pid=385821)[0m v_max: 3.1796731425699525
[2m[36m(pid=385821)[0m -----------------------
Result for PPO_WaveAttenuationPOEnv-v0_0:
  custom_metrics: {}
  date: 2020-03-30_09-11-45
  done: false
  episode_len_mean: 2000.0
  episode_reward_max: 3928.443571306391
  episode_reward_mean: 3113.2844022690197
  episode_reward_min: 2168.1261330746015
  episodes_this_iter: 5
  episodes_total: 170
  experiment_id: ba0edb931dde48dcb020df4b454540a2
  hostname: p0035.ten.osc.edu
  info:
    grad_time_ms: 220.607
    learner:
      default_policy:
        cur_kl_coeff: 2.3283064712331658e-11
        cur_lr: 4.999999873689376e-05
        entropy: 0.5292269587516785
        entropy_coeff: 0.0
        kl: 0.00814742874354124
        policy_loss: -0.002926185028627515
        total_loss: 2715.3681640625
        vf_explained_var: 1.8417835235595703e-05
        vf_loss: 2715.370849609375
    load_time_ms: 2.588
    num_steps_sampled: 340000
    num_steps_trained: 340000
    sample_time_ms: 100455.146
    update_time_ms: 2.424
  iterations_since_restore: 34
  node_ip: 10.4.1.36
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 2.62027972027972
    ram_util_percent: 5.399999999999999
  pid: 385820
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 6.932429300441607
    mean_inference_ms: 0.5043553809274972
    mean_processing_ms: 2.617028129449807
  time_since_restore: 3432.8593673706055
  time_this_iter_s: 100.38077759742737
  time_total_s: 3432.8593673706055
  timestamp: 1585573905
  timesteps_since_restore: 340000
  timesteps_this_iter: 10000
  timesteps_total: 340000
  training_iteration: 34
  trial_id: fce6b7f4
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2/2 CPUs, 0/0 GPUs
Memory usage on this node: 10.8/201.2 GB
Result logdir: /users/PYS1027/chnrhughes/ray_results/simple_training_example_ring2_v1
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - PPO_WaveAttenuationPOEnv-v0_0:	RUNNING, [2 CPUs, 0 GPUs], [pid=385820], 3432 s, 34 iter, 340000 ts, 3.11e+03 rew

[2m[36m(pid=385820)[0m 2020-03-30 09:11:45,532	WARNING ppo.py:121 -- The magnitude of your environment rewards are more than 311.0x the scale of `vf_clip_param`. This means that it will take more than 311.0 iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.
[2m[36m(pid=385821)[0m 
[2m[36m(pid=385821)[0m -----------------------
[2m[36m(pid=385821)[0m ring length: 499
[2m[36m(pid=385821)[0m v_max: 2.8797928146697993
[2m[36m(pid=385821)[0m -----------------------
[2m[36m(pid=385821)[0m 
[2m[36m(pid=385821)[0m -----------------------
[2m[36m(pid=385821)[0m ring length: 491
[2m[36m(pid=385821)[0m v_max: 2.719840556029452
[2m[36m(pid=385821)[0m -----------------------
[2m[36m(pid=385821)[0m 
[2m[36m(pid=385821)[0m -----------------------
[2m[36m(pid=385821)[0m ring length: 495
[2m[36m(pid=385821)[0m v_max: 2.79981792361692
[2m[36m(pid=385821)[0m -----------------------
[2m[36m(pid=385821)[0m 
[2m[36m(pid=385821)[0m -----------------------
[2m[36m(pid=385821)[0m ring length: 496
[2m[36m(pid=385821)[0m v_max: 2.819811886031332
[2m[36m(pid=385821)[0m -----------------------
[2m[36m(pid=385821)[0m 
[2m[36m(pid=385821)[0m -----------------------
[2m[36m(pid=385821)[0m ring length: 513
[2m[36m(pid=385821)[0m v_max: 3.1596825160053825
[2m[36m(pid=385821)[0m -----------------------
Result for PPO_WaveAttenuationPOEnv-v0_0:
  custom_metrics: {}
  date: 2020-03-30_09-13-25
  done: false
  episode_len_mean: 2000.0
  episode_reward_max: 3928.443571306391
  episode_reward_mean: 3169.0331827289506
  episode_reward_min: 2168.1261330746015
  episodes_this_iter: 5
  episodes_total: 175
  experiment_id: ba0edb931dde48dcb020df4b454540a2
  hostname: p0035.ten.osc.edu
  info:
    grad_time_ms: 220.232
    learner:
      default_policy:
        cur_kl_coeff: 1.1641532356165829e-11
        cur_lr: 4.999999873689376e-05
        entropy: 0.5234225392341614
        entropy_coeff: 0.0
        kl: 0.0028063845820724964
        policy_loss: -0.000914347474463284
        total_loss: 2420.162353515625
        vf_explained_var: 0.0001195073127746582
        vf_loss: 2420.1630859375
    load_time_ms: 2.579
    num_steps_sampled: 350000
    num_steps_trained: 350000
    sample_time_ms: 100356.847
    update_time_ms: 2.431
  iterations_since_restore: 35
  node_ip: 10.4.1.36
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 2.6125874125874127
    ram_util_percent: 5.399999999999999
  pid: 385820
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 6.9307213432062955
    mean_inference_ms: 0.5048364625451042
    mean_processing_ms: 2.616959754488545
  time_since_restore: 3533.306292772293
  time_this_iter_s: 100.44692540168762
  time_total_s: 3533.306292772293
  timestamp: 1585574005
  timesteps_since_restore: 350000
  timesteps_this_iter: 10000
  timesteps_total: 350000
  training_iteration: 35
  trial_id: fce6b7f4
  
[2m[36m(pid=385820)[0m 2020-03-30 09:13:25,989	WARNING ppo.py:121 -- The magnitude of your environment rewards are more than 317.0x the scale of `vf_clip_param`. This means that it will take more than 317.0 iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2/2 CPUs, 0/0 GPUs
Memory usage on this node: 10.8/201.2 GB
Result logdir: /users/PYS1027/chnrhughes/ray_results/simple_training_example_ring2_v1
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - PPO_WaveAttenuationPOEnv-v0_0:	RUNNING, [2 CPUs, 0 GPUs], [pid=385820], 3533 s, 35 iter, 350000 ts, 3.17e+03 rew

[2m[36m(pid=385821)[0m 
[2m[36m(pid=385821)[0m -----------------------
[2m[36m(pid=385821)[0m ring length: 508
[2m[36m(pid=385821)[0m v_max: 3.059726235247059
[2m[36m(pid=385821)[0m -----------------------
[2m[36m(pid=385821)[0m 
[2m[36m(pid=385821)[0m -----------------------
[2m[36m(pid=385821)[0m ring length: 517
[2m[36m(pid=385821)[0m v_max: 3.2396436965475437
[2m[36m(pid=385821)[0m -----------------------
[2m[36m(pid=385821)[0m 
[2m[36m(pid=385821)[0m -----------------------
[2m[36m(pid=385821)[0m ring length: 500
[2m[36m(pid=385821)[0m v_max: 2.8997861277614296
[2m[36m(pid=385821)[0m -----------------------
[2m[36m(pid=385821)[0m 
[2m[36m(pid=385821)[0m -----------------------
[2m[36m(pid=385821)[0m ring length: 515
[2m[36m(pid=385821)[0m v_max: 3.199663550695237
[2m[36m(pid=385821)[0m -----------------------
[2m[36m(pid=385821)[0m 
[2m[36m(pid=385821)[0m -----------------------
[2m[36m(pid=385821)[0m ring length: 490
[2m[36m(pid=385821)[0m v_max: 2.699845849180192
[2m[36m(pid=385821)[0m -----------------------
Result for PPO_WaveAttenuationPOEnv-v0_0:
  custom_metrics: {}
  date: 2020-03-30_09-15-06
  done: false
  episode_len_mean: 2000.0
  episode_reward_max: 3928.443571306391
  episode_reward_mean: 3225.1226756675446
  episode_reward_min: 2461.572413150588
  episodes_this_iter: 5
  episodes_total: 180
  experiment_id: ba0edb931dde48dcb020df4b454540a2
  hostname: p0035.ten.osc.edu
  info:
    grad_time_ms: 219.729
    learner:
      default_policy:
        cur_kl_coeff: 5.8207661780829145e-12
        cur_lr: 4.999999873689376e-05
        entropy: 0.5173869132995605
        entropy_coeff: 0.0
        kl: 0.009846930392086506
        policy_loss: -0.0031129587441682816
        total_loss: 2404.3203125
        vf_explained_var: 0.0003573298454284668
        vf_loss: 2404.323486328125
    load_time_ms: 2.532
    num_steps_sampled: 360000
    num_steps_trained: 360000
    sample_time_ms: 100305.371
    update_time_ms: 2.451
  iterations_since_restore: 36
  node_ip: 10.4.1.36
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 2.6146853146853144
    ram_util_percent: 5.399999999999999
  pid: 385820
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 6.929051540048999
    mean_inference_ms: 0.5054030265146205
    mean_processing_ms: 2.61689175586863
  time_since_restore: 3633.6076266765594
  time_this_iter_s: 100.30133390426636
  time_total_s: 3633.6076266765594
  timestamp: 1585574106
  timesteps_since_restore: 360000
  timesteps_this_iter: 10000
  timesteps_total: 360000
  training_iteration: 36
  trial_id: fce6b7f4
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2/2 CPUs, 0/0 GPUs
Memory usage on this node: 10.8/201.2 GB
Result logdir: /users/PYS1027/chnrhughes/ray_results/simple_training_example_ring2_v1
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - PPO_WaveAttenuationPOEnv-v0_0:	RUNNING, [2 CPUs, 0 GPUs], [pid=385820], 3633 s, 36 iter, 360000 ts, 3.23e+03 rew

[2m[36m(pid=385820)[0m 2020-03-30 09:15:06,323	WARNING ppo.py:121 -- The magnitude of your environment rewards are more than 323.0x the scale of `vf_clip_param`. This means that it will take more than 323.0 iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.
[2m[36m(pid=385821)[0m 
[2m[36m(pid=385821)[0m -----------------------
[2m[36m(pid=385821)[0m ring length: 501
[2m[36m(pid=385821)[0m v_max: 2.919779270736568
[2m[36m(pid=385821)[0m -----------------------
[2m[36m(pid=385821)[0m 
[2m[36m(pid=385821)[0m -----------------------
[2m[36m(pid=385821)[0m ring length: 499
[2m[36m(pid=385821)[0m v_max: 2.8797928146697993
[2m[36m(pid=385821)[0m -----------------------
[2m[36m(pid=385821)[0m 
[2m[36m(pid=385821)[0m -----------------------
[2m[36m(pid=385821)[0m ring length: 500
[2m[36m(pid=385821)[0m v_max: 2.8997861277614296
[2m[36m(pid=385821)[0m -----------------------
[2m[36m(pid=385821)[0m 
[2m[36m(pid=385821)[0m -----------------------
[2m[36m(pid=385821)[0m ring length: 508
[2m[36m(pid=385821)[0m v_max: 3.059726235247059
[2m[36m(pid=385821)[0m -----------------------
[2m[36m(pid=385821)[0m 
[2m[36m(pid=385821)[0m -----------------------
[2m[36m(pid=385821)[0m ring length: 492
[2m[36m(pid=385821)[0m v_max: 2.739835119766572
[2m[36m(pid=385821)[0m -----------------------
Result for PPO_WaveAttenuationPOEnv-v0_0:
  custom_metrics: {}
  date: 2020-03-30_09-16-46
  done: false
  episode_len_mean: 2000.0
  episode_reward_max: 3928.443571306391
  episode_reward_mean: 3272.3012396420904
  episode_reward_min: 2461.572413150588
  episodes_this_iter: 5
  episodes_total: 185
  experiment_id: ba0edb931dde48dcb020df4b454540a2
  hostname: p0035.ten.osc.edu
  info:
    grad_time_ms: 219.722
    learner:
      default_policy:
        cur_kl_coeff: 2.9103830890414573e-12
        cur_lr: 4.999999873689376e-05
        entropy: 0.4959920346736908
        entropy_coeff: 0.0
        kl: 0.0028379950672388077
        policy_loss: -0.0008047943119890988
        total_loss: 2606.569580078125
        vf_explained_var: 5.161762237548828e-05
        vf_loss: 2606.57080078125
    load_time_ms: 2.517
    num_steps_sampled: 370000
    num_steps_trained: 370000
    sample_time_ms: 100314.374
    update_time_ms: 2.453
  iterations_since_restore: 37
  node_ip: 10.4.1.36
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 2.6237762237762237
    ram_util_percent: 5.399999999999999
  pid: 385820
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 6.927456418476511
    mean_inference_ms: 0.5059574894281846
    mean_processing_ms: 2.6169047700165917
  time_since_restore: 3734.174042701721
  time_this_iter_s: 100.56641602516174
  time_total_s: 3734.174042701721
  timestamp: 1585574206
  timesteps_since_restore: 370000
  timesteps_this_iter: 10000
  timesteps_total: 370000
  training_iteration: 37
  trial_id: fce6b7f4
  
[2m[36m(pid=385820)[0m 2020-03-30 09:16:46,899	WARNING ppo.py:121 -- The magnitude of your environment rewards are more than 327.0x the scale of `vf_clip_param`. This means that it will take more than 327.0 iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2/2 CPUs, 0/0 GPUs
Memory usage on this node: 10.8/201.2 GB
Result logdir: /users/PYS1027/chnrhughes/ray_results/simple_training_example_ring2_v1
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - PPO_WaveAttenuationPOEnv-v0_0:	RUNNING, [2 CPUs, 0 GPUs], [pid=385820], 3734 s, 37 iter, 370000 ts, 3.27e+03 rew

[2m[36m(pid=385821)[0m 
[2m[36m(pid=385821)[0m -----------------------
[2m[36m(pid=385821)[0m ring length: 506
[2m[36m(pid=385821)[0m v_max: 3.0197423207835943
[2m[36m(pid=385821)[0m -----------------------
[2m[36m(pid=385821)[0m 
[2m[36m(pid=385821)[0m -----------------------
[2m[36m(pid=385821)[0m ring length: 511
[2m[36m(pid=385821)[0m v_max: 3.1197006223865698
[2m[36m(pid=385821)[0m -----------------------
[2m[36m(pid=385821)[0m 
[2m[36m(pid=385821)[0m -----------------------
[2m[36m(pid=385821)[0m ring length: 511
[2m[36m(pid=385821)[0m v_max: 3.1197006223865698
[2m[36m(pid=385821)[0m -----------------------
[2m[36m(pid=385821)[0m 
[2m[36m(pid=385821)[0m -----------------------
[2m[36m(pid=385821)[0m ring length: 520
[2m[36m(pid=385821)[0m v_max: 3.2996121816646764
[2m[36m(pid=385821)[0m -----------------------
[2m[36m(pid=385821)[0m 
[2m[36m(pid=385821)[0m -----------------------
[2m[36m(pid=385821)[0m ring length: 507
[2m[36m(pid=385821)[0m v_max: 3.0397343746587766
[2m[36m(pid=385821)[0m -----------------------
Result for PPO_WaveAttenuationPOEnv-v0_0:
  custom_metrics: {}
  date: 2020-03-30_09-18-27
  done: false
  episode_len_mean: 2000.0
  episode_reward_max: 3928.443571306391
  episode_reward_mean: 3317.950849558975
  episode_reward_min: 2461.572413150588
  episodes_this_iter: 5
  episodes_total: 190
  experiment_id: ba0edb931dde48dcb020df4b454540a2
  hostname: p0035.ten.osc.edu
  info:
    grad_time_ms: 219.381
    learner:
      default_policy:
        cur_kl_coeff: 1.4551915445207286e-12
        cur_lr: 4.999999873689376e-05
        entropy: 0.47977691888809204
        entropy_coeff: 0.0
        kl: 0.0011204257607460022
        policy_loss: -0.0012464493047446012
        total_loss: 2737.89697265625
        vf_explained_var: 6.848573684692383e-05
        vf_loss: 2737.8984375
    load_time_ms: 2.493
    num_steps_sampled: 380000
    num_steps_trained: 380000
    sample_time_ms: 100314.48
    update_time_ms: 2.445
  iterations_since_restore: 38
  node_ip: 10.4.1.36
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 2.6216783216783215
    ram_util_percent: 5.399999999999999
  pid: 385820
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 6.925909884113887
    mean_inference_ms: 0.5064226657695683
    mean_processing_ms: 2.6169055205225247
  time_since_restore: 3834.477386236191
  time_this_iter_s: 100.3033435344696
  time_total_s: 3834.477386236191
  timestamp: 1585574307
  timesteps_since_restore: 380000
  timesteps_this_iter: 10000
  timesteps_total: 380000
  training_iteration: 38
  trial_id: fce6b7f4
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2/2 CPUs, 0/0 GPUs
Memory usage on this node: 10.8/201.2 GB
Result logdir: /users/PYS1027/chnrhughes/ray_results/simple_training_example_ring2_v1
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - PPO_WaveAttenuationPOEnv-v0_0:	RUNNING, [2 CPUs, 0 GPUs], [pid=385820], 3834 s, 38 iter, 380000 ts, 3.32e+03 rew

[2m[36m(pid=385820)[0m 2020-03-30 09:18:27,211	WARNING ppo.py:121 -- The magnitude of your environment rewards are more than 332.0x the scale of `vf_clip_param`. This means that it will take more than 332.0 iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.
[2m[36m(pid=385821)[0m 
[2m[36m(pid=385821)[0m -----------------------
[2m[36m(pid=385821)[0m ring length: 493
[2m[36m(pid=385821)[0m v_max: 2.759829537541262
[2m[36m(pid=385821)[0m -----------------------
[2m[36m(pid=385821)[0m 
[2m[36m(pid=385821)[0m -----------------------
[2m[36m(pid=385821)[0m ring length: 507
[2m[36m(pid=385821)[0m v_max: 3.0397343746587766
[2m[36m(pid=385821)[0m -----------------------
[2m[36m(pid=385821)[0m 
[2m[36m(pid=385821)[0m -----------------------
[2m[36m(pid=385821)[0m ring length: 508
[2m[36m(pid=385821)[0m v_max: 3.059726235247059
[2m[36m(pid=385821)[0m -----------------------
[2m[36m(pid=385821)[0m 
[2m[36m(pid=385821)[0m -----------------------
[2m[36m(pid=385821)[0m ring length: 516
[2m[36m(pid=385821)[0m v_max: 3.2196537366217006
[2m[36m(pid=385821)[0m -----------------------
[2m[36m(pid=385821)[0m 
[2m[36m(pid=385821)[0m -----------------------
[2m[36m(pid=385821)[0m ring length: 494
[2m[36m(pid=385821)[0m v_max: 2.7798238064662253
[2m[36m(pid=385821)[0m -----------------------
Result for PPO_WaveAttenuationPOEnv-v0_0:
  custom_metrics: {}
  date: 2020-03-30_09-20-07
  done: false
  episode_len_mean: 2000.0
  episode_reward_max: 3928.443571306391
  episode_reward_mean: 3356.2942479752833
  episode_reward_min: 2461.572413150588
  episodes_this_iter: 5
  episodes_total: 195
  experiment_id: ba0edb931dde48dcb020df4b454540a2
  hostname: p0035.ten.osc.edu
  info:
    grad_time_ms: 220.85
    learner:
      default_policy:
        cur_kl_coeff: 7.275957722603643e-13
        cur_lr: 4.999999873689376e-05
        entropy: 0.4690930247306824
        entropy_coeff: 0.0
        kl: 0.008338659070432186
        policy_loss: -0.0012785708531737328
        total_loss: 2701.5576171875
        vf_explained_var: 8.171796798706055e-05
        vf_loss: 2701.55810546875
    load_time_ms: 2.377
    num_steps_sampled: 390000
    num_steps_trained: 390000
    sample_time_ms: 100298.428
    update_time_ms: 2.339
  iterations_since_restore: 39
  node_ip: 10.4.1.36
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 2.588111888111888
    ram_util_percent: 5.399999999999999
  pid: 385820
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 6.924439675512494
    mean_inference_ms: 0.5067874808566896
    mean_processing_ms: 2.616941532662242
  time_since_restore: 3935.1386666297913
  time_this_iter_s: 100.66128039360046
  time_total_s: 3935.1386666297913
  timestamp: 1585574407
  timesteps_since_restore: 390000
  timesteps_this_iter: 10000
  timesteps_total: 390000
  training_iteration: 39
  trial_id: fce6b7f4
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2/2 CPUs, 0/0 GPUs
Memory usage on this node: 10.8/201.2 GB
Result logdir: /users/PYS1027/chnrhughes/ray_results/simple_training_example_ring2_v1
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - PPO_WaveAttenuationPOEnv-v0_0:	RUNNING, [2 CPUs, 0 GPUs], [pid=385820], 3935 s, 39 iter, 390000 ts, 3.36e+03 rew

[2m[36m(pid=385820)[0m 2020-03-30 09:20:07,882	WARNING ppo.py:121 -- The magnitude of your environment rewards are more than 336.0x the scale of `vf_clip_param`. This means that it will take more than 336.0 iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.
[2m[36m(pid=385821)[0m 
[2m[36m(pid=385821)[0m -----------------------
[2m[36m(pid=385821)[0m ring length: 495
[2m[36m(pid=385821)[0m v_max: 2.79981792361692
[2m[36m(pid=385821)[0m -----------------------
[2m[36m(pid=385821)[0m 
[2m[36m(pid=385821)[0m -----------------------
[2m[36m(pid=385821)[0m ring length: 501
[2m[36m(pid=385821)[0m v_max: 2.919779270736568
[2m[36m(pid=385821)[0m -----------------------
[2m[36m(pid=385821)[0m 
[2m[36m(pid=385821)[0m -----------------------
[2m[36m(pid=385821)[0m ring length: 514
[2m[36m(pid=385821)[0m v_max: 3.1796731425699525
[2m[36m(pid=385821)[0m -----------------------
[2m[36m(pid=385821)[0m 
[2m[36m(pid=385821)[0m -----------------------
[2m[36m(pid=385821)[0m ring length: 517
[2m[36m(pid=385821)[0m v_max: 3.2396436965475437
[2m[36m(pid=385821)[0m -----------------------
[2m[36m(pid=385821)[0m 
[2m[36m(pid=385821)[0m -----------------------
[2m[36m(pid=385821)[0m ring length: 516
[2m[36m(pid=385821)[0m v_max: 3.2196537366217006
[2m[36m(pid=385821)[0m -----------------------
Result for PPO_WaveAttenuationPOEnv-v0_0:
  custom_metrics: {}
  date: 2020-03-30_09-21-48
  done: false
  episode_len_mean: 2000.0
  episode_reward_max: 4056.1366254355803
  episode_reward_mean: 3400.535716444554
  episode_reward_min: 2461.572413150588
  episodes_this_iter: 5
  episodes_total: 200
  experiment_id: ba0edb931dde48dcb020df4b454540a2
  hostname: p0035.ten.osc.edu
  info:
    grad_time_ms: 220.72
    learner:
      default_policy:
        cur_kl_coeff: 3.6379788613018216e-13
        cur_lr: 4.999999873689376e-05
        entropy: 0.4580872654914856
        entropy_coeff: 0.0
        kl: 0.008080527186393738
        policy_loss: -0.0008088386384770274
        total_loss: 3013.821533203125
        vf_explained_var: 5.185604095458984e-06
        vf_loss: 3013.822509765625
    load_time_ms: 2.35
    num_steps_sampled: 400000
    num_steps_trained: 400000
    sample_time_ms: 100316.659
    update_time_ms: 2.327
  iterations_since_restore: 40
  node_ip: 10.4.1.36
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 2.6279720279720276
    ram_util_percent: 5.399999999999999
  pid: 385820
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 6.922968307299386
    mean_inference_ms: 0.5071671427698201
    mean_processing_ms: 2.616982623195072
  time_since_restore: 4035.7410876750946
  time_this_iter_s: 100.60242104530334
  time_total_s: 4035.7410876750946
  timestamp: 1585574508
  timesteps_since_restore: 400000
  timesteps_this_iter: 10000
  timesteps_total: 400000
  training_iteration: 40
  trial_id: fce6b7f4
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2/2 CPUs, 0/0 GPUs
Memory usage on this node: 10.8/201.2 GB
Result logdir: /users/PYS1027/chnrhughes/ray_results/simple_training_example_ring2_v1
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - PPO_WaveAttenuationPOEnv-v0_0:	RUNNING, [2 CPUs, 0 GPUs], [pid=385820], 4035 s, 40 iter, 400000 ts, 3.4e+03 rew

[2m[36m(pid=385820)[0m 2020-03-30 09:21:48,493	WARNING ppo.py:121 -- The magnitude of your environment rewards are more than 340.0x the scale of `vf_clip_param`. This means that it will take more than 340.0 iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.
[2m[36m(pid=385821)[0m 
[2m[36m(pid=385821)[0m -----------------------
[2m[36m(pid=385821)[0m ring length: 512
[2m[36m(pid=385821)[0m v_max: 3.139691674719026
[2m[36m(pid=385821)[0m -----------------------
[2m[36m(pid=385821)[0m 
[2m[36m(pid=385821)[0m -----------------------
[2m[36m(pid=385821)[0m ring length: 493
[2m[36m(pid=385821)[0m v_max: 2.759829537541262
[2m[36m(pid=385821)[0m -----------------------
[2m[36m(pid=385821)[0m 
[2m[36m(pid=385821)[0m -----------------------
[2m[36m(pid=385821)[0m ring length: 520
[2m[36m(pid=385821)[0m v_max: 3.2996121816646764
[2m[36m(pid=385821)[0m -----------------------
[2m[36m(pid=385821)[0m 
[2m[36m(pid=385821)[0m -----------------------
[2m[36m(pid=385821)[0m ring length: 505
[2m[36m(pid=385821)[0m v_max: 2.999750077051092
[2m[36m(pid=385821)[0m -----------------------
[2m[36m(pid=385821)[0m 
[2m[36m(pid=385821)[0m -----------------------
[2m[36m(pid=385821)[0m ring length: 511
[2m[36m(pid=385821)[0m v_max: 3.1197006223865698
[2m[36m(pid=385821)[0m -----------------------
Result for PPO_WaveAttenuationPOEnv-v0_0:
  custom_metrics: {}
  date: 2020-03-30_09-23-29
  done: false
  episode_len_mean: 2000.0
  episode_reward_max: 4056.1366254355803
  episode_reward_mean: 3437.31315515585
  episode_reward_min: 2461.572413150588
  episodes_this_iter: 5
  episodes_total: 205
  experiment_id: ba0edb931dde48dcb020df4b454540a2
  hostname: p0035.ten.osc.edu
  info:
    grad_time_ms: 220.981
    learner:
      default_policy:
        cur_kl_coeff: 1.8189894306509108e-13
        cur_lr: 4.999999873689376e-05
        entropy: 0.4466325640678406
        entropy_coeff: 0.0
        kl: 0.0010057426989078522
        policy_loss: -0.0011586772743612528
        total_loss: 2817.71923828125
        vf_explained_var: 6.312131881713867e-05
        vf_loss: 2817.720947265625
    load_time_ms: 2.343
    num_steps_sampled: 410000
    num_steps_trained: 410000
    sample_time_ms: 100391.011
    update_time_ms: 2.307
  iterations_since_restore: 41
  node_ip: 10.4.1.36
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 2.7006896551724138
    ram_util_percent: 5.3999999999999995
  pid: 385820
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 6.9214910506375285
    mean_inference_ms: 0.5075582556376294
    mean_processing_ms: 2.6169901960789423
  time_since_restore: 4137.13982462883
  time_this_iter_s: 101.39873695373535
  time_total_s: 4137.13982462883
  timestamp: 1585574609
  timesteps_since_restore: 410000
  timesteps_this_iter: 10000
  timesteps_total: 410000
  training_iteration: 41
  trial_id: fce6b7f4
  
[2m[36m(pid=385820)[0m 2020-03-30 09:23:29,929	WARNING ppo.py:121 -- The magnitude of your environment rewards are more than 344.0x the scale of `vf_clip_param`. This means that it will take more than 344.0 iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2/2 CPUs, 0/0 GPUs
Memory usage on this node: 10.8/201.2 GB
Result logdir: /users/PYS1027/chnrhughes/ray_results/simple_training_example_ring2_v1
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - PPO_WaveAttenuationPOEnv-v0_0:	RUNNING, [2 CPUs, 0 GPUs], [pid=385820], 4137 s, 41 iter, 410000 ts, 3.44e+03 rew

[2m[36m(pid=385821)[0m 
[2m[36m(pid=385821)[0m -----------------------
[2m[36m(pid=385821)[0m ring length: 501
[2m[36m(pid=385821)[0m v_max: 2.919779270736568
[2m[36m(pid=385821)[0m -----------------------
[2m[36m(pid=385821)[0m 
[2m[36m(pid=385821)[0m -----------------------
[2m[36m(pid=385821)[0m ring length: 516
[2m[36m(pid=385821)[0m v_max: 3.2196537366217006
[2m[36m(pid=385821)[0m -----------------------
[2m[36m(pid=385821)[0m 
[2m[36m(pid=385821)[0m -----------------------
[2m[36m(pid=385821)[0m ring length: 507
[2m[36m(pid=385821)[0m v_max: 3.0397343746587766
[2m[36m(pid=385821)[0m -----------------------
[2m[36m(pid=385821)[0m 
[2m[36m(pid=385821)[0m -----------------------
[2m[36m(pid=385821)[0m ring length: 515
[2m[36m(pid=385821)[0m v_max: 3.199663550695237
[2m[36m(pid=385821)[0m -----------------------
[2m[36m(pid=385821)[0m 
[2m[36m(pid=385821)[0m -----------------------
[2m[36m(pid=385821)[0m ring length: 494
[2m[36m(pid=385821)[0m v_max: 2.7798238064662253
[2m[36m(pid=385821)[0m -----------------------
Result for PPO_WaveAttenuationPOEnv-v0_0:
  custom_metrics: {}
  date: 2020-03-30_09-25-10
  done: false
  episode_len_mean: 2000.0
  episode_reward_max: 4056.1366254355803
  episode_reward_mean: 3470.5431723681704
  episode_reward_min: 2461.572413150588
  episodes_this_iter: 5
  episodes_total: 210
  experiment_id: ba0edb931dde48dcb020df4b454540a2
  hostname: p0035.ten.osc.edu
  info:
    grad_time_ms: 222.259
    learner:
      default_policy:
        cur_kl_coeff: 9.094947153254554e-14
        cur_lr: 4.999999873689376e-05
        entropy: 0.430922269821167
        entropy_coeff: 0.0
        kl: 0.004636002704501152
        policy_loss: -0.0015888363122940063
        total_loss: 2888.896484375
        vf_explained_var: 5.53131103515625e-05
        vf_loss: 2888.897705078125
    load_time_ms: 2.314
    num_steps_sampled: 420000
    num_steps_trained: 420000
    sample_time_ms: 100393.533
    update_time_ms: 2.353
  iterations_since_restore: 42
  node_ip: 10.4.1.36
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 2.6300699300699297
    ram_util_percent: 5.399999999999999
  pid: 385820
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 6.920132908586794
    mean_inference_ms: 0.5080369330029569
    mean_processing_ms: 2.6170544322929334
  time_since_restore: 4238.136951208115
  time_this_iter_s: 100.99712657928467
  time_total_s: 4238.136951208115
  timestamp: 1585574710
  timesteps_since_restore: 420000
  timesteps_this_iter: 10000
  timesteps_total: 420000
  training_iteration: 42
  trial_id: fce6b7f4
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2/2 CPUs, 0/0 GPUs
Memory usage on this node: 10.8/201.2 GB
Result logdir: /users/PYS1027/chnrhughes/ray_results/simple_training_example_ring2_v1
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - PPO_WaveAttenuationPOEnv-v0_0:	RUNNING, [2 CPUs, 0 GPUs], [pid=385820], 4238 s, 42 iter, 420000 ts, 3.47e+03 rew

[2m[36m(pid=385820)[0m 2020-03-30 09:25:10,938	WARNING ppo.py:121 -- The magnitude of your environment rewards are more than 347.0x the scale of `vf_clip_param`. This means that it will take more than 347.0 iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.
[2m[36m(pid=385821)[0m 
[2m[36m(pid=385821)[0m -----------------------
[2m[36m(pid=385821)[0m ring length: 518
[2m[36m(pid=385821)[0m v_max: 3.2596334266284783
[2m[36m(pid=385821)[0m -----------------------
[2m[36m(pid=385821)[0m 
[2m[36m(pid=385821)[0m -----------------------
[2m[36m(pid=385821)[0m ring length: 493
[2m[36m(pid=385821)[0m v_max: 2.759829537541262
[2m[36m(pid=385821)[0m -----------------------
[2m[36m(pid=385821)[0m 
[2m[36m(pid=385821)[0m -----------------------
[2m[36m(pid=385821)[0m ring length: 494
[2m[36m(pid=385821)[0m v_max: 2.7798238064662253
[2m[36m(pid=385821)[0m -----------------------
[2m[36m(pid=385821)[0m 
[2m[36m(pid=385821)[0m -----------------------
[2m[36m(pid=385821)[0m ring length: 511
[2m[36m(pid=385821)[0m v_max: 3.1197006223865698
[2m[36m(pid=385821)[0m -----------------------
[2m[36m(pid=385821)[0m 
[2m[36m(pid=385821)[0m -----------------------
[2m[36m(pid=385821)[0m ring length: 517
[2m[36m(pid=385821)[0m v_max: 3.2396436965475437
[2m[36m(pid=385821)[0m -----------------------
Result for PPO_WaveAttenuationPOEnv-v0_0:
  custom_metrics: {}
  date: 2020-03-30_09-26-51
  done: false
  episode_len_mean: 2000.0
  episode_reward_max: 4222.563871864863
  episode_reward_mean: 3503.9809211100405
  episode_reward_min: 2461.572413150588
  episodes_this_iter: 5
  episodes_total: 215
  experiment_id: ba0edb931dde48dcb020df4b454540a2
  hostname: p0035.ten.osc.edu
  info:
    grad_time_ms: 223.123
    learner:
      default_policy:
        cur_kl_coeff: 4.547473576627277e-14
        cur_lr: 4.999999873689376e-05
        entropy: 0.4193631410598755
        entropy_coeff: 0.0
        kl: 0.008510393090546131
        policy_loss: -0.0019704257138073444
        total_loss: 2996.350341796875
        vf_explained_var: 2.6941299438476562e-05
        vf_loss: 2996.35302734375
    load_time_ms: 2.004
    num_steps_sampled: 430000
    num_steps_trained: 430000
    sample_time_ms: 100341.745
    update_time_ms: 2.298
  iterations_since_restore: 43
  node_ip: 10.4.1.36
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 2.638461538461538
    ram_util_percent: 5.399999999999999
  pid: 385820
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 6.918858174754753
    mean_inference_ms: 0.5086073669346708
    mean_processing_ms: 2.617121296506982
  time_since_restore: 4338.244517803192
  time_this_iter_s: 100.10756659507751
  time_total_s: 4338.244517803192
  timestamp: 1585574811
  timesteps_since_restore: 430000
  timesteps_this_iter: 10000
  timesteps_total: 430000
  training_iteration: 43
  trial_id: fce6b7f4
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2/2 CPUs, 0/0 GPUs
Memory usage on this node: 10.8/201.2 GB
Result logdir: /users/PYS1027/chnrhughes/ray_results/simple_training_example_ring2_v1
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - PPO_WaveAttenuationPOEnv-v0_0:	RUNNING, [2 CPUs, 0 GPUs], [pid=385820], 4338 s, 43 iter, 430000 ts, 3.5e+03 rew

[2m[36m(pid=385820)[0m 2020-03-30 09:26:51,054	WARNING ppo.py:121 -- The magnitude of your environment rewards are more than 350.0x the scale of `vf_clip_param`. This means that it will take more than 350.0 iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.
[2m[36m(pid=385821)[0m 
[2m[36m(pid=385821)[0m -----------------------
[2m[36m(pid=385821)[0m ring length: 503
[2m[36m(pid=385821)[0m v_max: 2.9597650335315784
[2m[36m(pid=385821)[0m -----------------------
[2m[36m(pid=385821)[0m 
[2m[36m(pid=385821)[0m -----------------------
[2m[36m(pid=385821)[0m ring length: 510
[2m[36m(pid=385821)[0m v_max: 3.0997093626421153
[2m[36m(pid=385821)[0m -----------------------
[2m[36m(pid=385821)[0m 
[2m[36m(pid=385821)[0m -----------------------
[2m[36m(pid=385821)[0m ring length: 512
[2m[36m(pid=385821)[0m v_max: 3.139691674719026
[2m[36m(pid=385821)[0m -----------------------
[2m[36m(pid=385821)[0m 
[2m[36m(pid=385821)[0m -----------------------
[2m[36m(pid=385821)[0m ring length: 497
[2m[36m(pid=385821)[0m v_max: 2.839805690709741
[2m[36m(pid=385821)[0m -----------------------
[2m[36m(pid=385821)[0m 
[2m[36m(pid=385821)[0m -----------------------
[2m[36m(pid=385821)[0m ring length: 512
[2m[36m(pid=385821)[0m v_max: 3.139691674719026
[2m[36m(pid=385821)[0m -----------------------
Result for PPO_WaveAttenuationPOEnv-v0_0:
  custom_metrics: {}
  date: 2020-03-30_09-28-31
  done: false
  episode_len_mean: 2000.0
  episode_reward_max: 4222.563871864863
  episode_reward_mean: 3522.545926388468
  episode_reward_min: 2461.572413150588
  episodes_this_iter: 5
  episodes_total: 220
  experiment_id: ba0edb931dde48dcb020df4b454540a2
  hostname: p0035.ten.osc.edu
  info:
    grad_time_ms: 225.575
    learner:
      default_policy:
        cur_kl_coeff: 2.2737367883136385e-14
        cur_lr: 4.999999873689376e-05
        entropy: 0.4143858253955841
        entropy_coeff: 0.0
        kl: 0.008303994312882423
        policy_loss: -0.002329279901459813
        total_loss: 2747.26025390625
        vf_explained_var: 0.00011909008026123047
        vf_loss: 2747.262451171875
    load_time_ms: 2.126
    num_steps_sampled: 440000
    num_steps_trained: 440000
    sample_time_ms: 100330.341
    update_time_ms: 2.177
  iterations_since_restore: 44
  node_ip: 10.4.1.36
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 2.677464788732394
    ram_util_percent: 5.399999999999998
  pid: 385820
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 6.917633213082225
    mean_inference_ms: 0.5091688991560628
    mean_processing_ms: 2.61719575249952
  time_since_restore: 4438.536143779755
  time_this_iter_s: 100.2916259765625
  time_total_s: 4438.536143779755
  timestamp: 1585574911
  timesteps_since_restore: 440000
  timesteps_this_iter: 10000
  timesteps_total: 440000
  training_iteration: 44
  trial_id: fce6b7f4
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2/2 CPUs, 0/0 GPUs
Memory usage on this node: 10.8/201.2 GB
Result logdir: /users/PYS1027/chnrhughes/ray_results/simple_training_example_ring2_v1
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - PPO_WaveAttenuationPOEnv-v0_0:	RUNNING, [2 CPUs, 0 GPUs], [pid=385820], 4438 s, 44 iter, 440000 ts, 3.52e+03 rew

[2m[36m(pid=385820)[0m 2020-03-30 09:28:31,356	WARNING ppo.py:121 -- The magnitude of your environment rewards are more than 352.0x the scale of `vf_clip_param`. This means that it will take more than 352.0 iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.
[2m[36m(pid=385821)[0m 
[2m[36m(pid=385821)[0m -----------------------
[2m[36m(pid=385821)[0m ring length: 516
[2m[36m(pid=385821)[0m v_max: 3.2196537366217006
[2m[36m(pid=385821)[0m -----------------------
[2m[36m(pid=385821)[0m 
[2m[36m(pid=385821)[0m -----------------------
[2m[36m(pid=385821)[0m ring length: 499
[2m[36m(pid=385821)[0m v_max: 2.8797928146697993
[2m[36m(pid=385821)[0m -----------------------
[2m[36m(pid=385821)[0m 
[2m[36m(pid=385821)[0m -----------------------
[2m[36m(pid=385821)[0m ring length: 503
[2m[36m(pid=385821)[0m v_max: 2.9597650335315784
[2m[36m(pid=385821)[0m -----------------------
[2m[36m(pid=385821)[0m 
[2m[36m(pid=385821)[0m -----------------------
[2m[36m(pid=385821)[0m ring length: 518
[2m[36m(pid=385821)[0m v_max: 3.2596334266284783
[2m[36m(pid=385821)[0m -----------------------
[2m[36m(pid=385821)[0m 
[2m[36m(pid=385821)[0m -----------------------
[2m[36m(pid=385821)[0m ring length: 501
[2m[36m(pid=385821)[0m v_max: 2.919779270736568
[2m[36m(pid=385821)[0m -----------------------
Result for PPO_WaveAttenuationPOEnv-v0_0:
  custom_metrics: {}
  date: 2020-03-30_09-30-11
  done: false
  episode_len_mean: 2000.0
  episode_reward_max: 4222.563871864863
  episode_reward_mean: 3556.568813945955
  episode_reward_min: 2461.572413150588
  episodes_this_iter: 5
  episodes_total: 225
  experiment_id: ba0edb931dde48dcb020df4b454540a2
  hostname: p0035.ten.osc.edu
  info:
    grad_time_ms: 227.52
    learner:
      default_policy:
        cur_kl_coeff: 1.1368683941568192e-14
        cur_lr: 4.999999873689376e-05
        entropy: 0.39976927638053894
        entropy_coeff: 0.0
        kl: 0.004868555814027786
        policy_loss: -0.0008252666448242962
        total_loss: 3107.9990234375
        vf_explained_var: 2.104043960571289e-05
        vf_loss: 3107.99951171875
    load_time_ms: 2.123
    num_steps_sampled: 450000
    num_steps_trained: 450000
    sample_time_ms: 100280.466
    update_time_ms: 2.249
  iterations_since_restore: 45
  node_ip: 10.4.1.36
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 2.6496503496503494
    ram_util_percent: 5.399999999999999
  pid: 385820
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 6.916324746429455
    mean_inference_ms: 0.5096629054242137
    mean_processing_ms: 2.617221079790228
  time_since_restore: 4538.508203983307
  time_this_iter_s: 99.97206020355225
  time_total_s: 4538.508203983307
  timestamp: 1585575011
  timesteps_since_restore: 450000
  timesteps_this_iter: 10000
  timesteps_total: 450000
  training_iteration: 45
  trial_id: fce6b7f4
  
[2m[36m(pid=385820)[0m 2020-03-30 09:30:11,336	WARNING ppo.py:121 -- The magnitude of your environment rewards are more than 356.0x the scale of `vf_clip_param`. This means that it will take more than 356.0 iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2/2 CPUs, 0/0 GPUs
Memory usage on this node: 10.8/201.2 GB
Result logdir: /users/PYS1027/chnrhughes/ray_results/simple_training_example_ring2_v1
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - PPO_WaveAttenuationPOEnv-v0_0:	RUNNING, [2 CPUs, 0 GPUs], [pid=385820], 4538 s, 45 iter, 450000 ts, 3.56e+03 rew

[2m[36m(pid=385821)[0m 
[2m[36m(pid=385821)[0m -----------------------
[2m[36m(pid=385821)[0m ring length: 503
[2m[36m(pid=385821)[0m v_max: 2.9597650335315784
[2m[36m(pid=385821)[0m -----------------------
[2m[36m(pid=385821)[0m 
[2m[36m(pid=385821)[0m -----------------------
[2m[36m(pid=385821)[0m ring length: 490
[2m[36m(pid=385821)[0m v_max: 2.699845849180192
[2m[36m(pid=385821)[0m -----------------------
[2m[36m(pid=385821)[0m 
[2m[36m(pid=385821)[0m -----------------------
[2m[36m(pid=385821)[0m ring length: 517
[2m[36m(pid=385821)[0m v_max: 3.2396436965475437
[2m[36m(pid=385821)[0m -----------------------
[2m[36m(pid=385821)[0m 
[2m[36m(pid=385821)[0m -----------------------
[2m[36m(pid=385821)[0m ring length: 503
[2m[36m(pid=385821)[0m v_max: 2.9597650335315784
[2m[36m(pid=385821)[0m -----------------------
[2m[36m(pid=385821)[0m 
[2m[36m(pid=385821)[0m -----------------------
[2m[36m(pid=385821)[0m ring length: 513
[2m[36m(pid=385821)[0m v_max: 3.1596825160053825
[2m[36m(pid=385821)[0m -----------------------
Result for PPO_WaveAttenuationPOEnv-v0_0:
  custom_metrics: {}
  date: 2020-03-30_09-31-51
  done: false
  episode_len_mean: 2000.0
  episode_reward_max: 4284.998807002121
  episode_reward_mean: 3585.331234216814
  episode_reward_min: 2461.572413150588
  episodes_this_iter: 5
  episodes_total: 230
  experiment_id: ba0edb931dde48dcb020df4b454540a2
  hostname: p0035.ten.osc.edu
  info:
    grad_time_ms: 228.253
    learner:
      default_policy:
        cur_kl_coeff: 5.684341970784096e-15
        cur_lr: 4.999999873689376e-05
        entropy: 0.3817760646343231
        entropy_coeff: 0.0
        kl: 0.007177759427577257
        policy_loss: -0.0019524353556334972
        total_loss: 3247.137939453125
        vf_explained_var: 6.854534149169922e-06
        vf_loss: 3247.139892578125
    load_time_ms: 2.142
    num_steps_sampled: 460000
    num_steps_trained: 460000
    sample_time_ms: 100270.885
    update_time_ms: 2.227
  iterations_since_restore: 46
  node_ip: 10.4.1.36
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 2.612676056338028
    ram_util_percent: 5.399999999999998
  pid: 385820
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 6.914953479026974
    mean_inference_ms: 0.5101846459613855
    mean_processing_ms: 2.6172377451901276
  time_since_restore: 4638.720185518265
  time_this_iter_s: 100.21198153495789
  time_total_s: 4638.720185518265
  timestamp: 1585575111
  timesteps_since_restore: 460000
  timesteps_this_iter: 10000
  timesteps_total: 460000
  training_iteration: 46
  trial_id: fce6b7f4
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2/2 CPUs, 0/0 GPUs
Memory usage on this node: 10.8/201.2 GB
Result logdir: /users/PYS1027/chnrhughes/ray_results/simple_training_example_ring2_v1
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - PPO_WaveAttenuationPOEnv-v0_0:	RUNNING, [2 CPUs, 0 GPUs], [pid=385820], 4638 s, 46 iter, 460000 ts, 3.59e+03 rew

[2m[36m(pid=385820)[0m 2020-03-30 09:31:51,573	WARNING ppo.py:121 -- The magnitude of your environment rewards are more than 359.0x the scale of `vf_clip_param`. This means that it will take more than 359.0 iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.
[2m[36m(pid=385821)[0m 
[2m[36m(pid=385821)[0m -----------------------
[2m[36m(pid=385821)[0m ring length: 519
[2m[36m(pid=385821)[0m v_max: 3.2796229229775036
[2m[36m(pid=385821)[0m -----------------------
[2m[36m(pid=385821)[0m 
[2m[36m(pid=385821)[0m -----------------------
[2m[36m(pid=385821)[0m ring length: 514
[2m[36m(pid=385821)[0m v_max: 3.1796731425699525
[2m[36m(pid=385821)[0m -----------------------
[2m[36m(pid=385821)[0m 
[2m[36m(pid=385821)[0m -----------------------
[2m[36m(pid=385821)[0m ring length: 495
[2m[36m(pid=385821)[0m v_max: 2.79981792361692
[2m[36m(pid=385821)[0m -----------------------
[2m[36m(pid=385821)[0m 
[2m[36m(pid=385821)[0m -----------------------
[2m[36m(pid=385821)[0m ring length: 514
[2m[36m(pid=385821)[0m v_max: 3.1796731425699525
[2m[36m(pid=385821)[0m -----------------------
[2m[36m(pid=385821)[0m 
[2m[36m(pid=385821)[0m -----------------------
[2m[36m(pid=385821)[0m ring length: 512
[2m[36m(pid=385821)[0m v_max: 3.139691674719026
[2m[36m(pid=385821)[0m -----------------------
Result for PPO_WaveAttenuationPOEnv-v0_0:
  custom_metrics: {}
  date: 2020-03-30_09-33-32
  done: false
  episode_len_mean: 2000.0
  episode_reward_max: 4375.569003260175
  episode_reward_mean: 3652.8921135245055
  episode_reward_min: 2461.572413150588
  episodes_this_iter: 5
  episodes_total: 235
  experiment_id: ba0edb931dde48dcb020df4b454540a2
  hostname: p0035.ten.osc.edu
  info:
    grad_time_ms: 228.297
    learner:
      default_policy:
        cur_kl_coeff: 2.842170985392048e-15
        cur_lr: 4.999999873689376e-05
        entropy: 0.3700505495071411
        entropy_coeff: 0.0
        kl: 0.008212818764150143
        policy_loss: -0.00205252505838871
        total_loss: 3611.6201171875
        vf_explained_var: 2.2649765014648438e-06
        vf_loss: 3611.622314453125
    load_time_ms: 2.128
    num_steps_sampled: 470000
    num_steps_trained: 470000
    sample_time_ms: 100303.233
    update_time_ms: 2.214
  iterations_since_restore: 47
  node_ip: 10.4.1.36
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 2.6527777777777777
    ram_util_percent: 5.3999999999999995
  pid: 385820
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 6.913667062841305
    mean_inference_ms: 0.5107277893861459
    mean_processing_ms: 2.6172420204782583
  time_since_restore: 4739.609993934631
  time_this_iter_s: 100.88980841636658
  time_total_s: 4739.609993934631
  timestamp: 1585575212
  timesteps_since_restore: 470000
  timesteps_this_iter: 10000
  timesteps_total: 470000
  training_iteration: 47
  trial_id: fce6b7f4
  
[2m[36m(pid=385820)[0m 2020-03-30 09:33:32,472	WARNING ppo.py:121 -- The magnitude of your environment rewards are more than 365.0x the scale of `vf_clip_param`. This means that it will take more than 365.0 iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2/2 CPUs, 0/0 GPUs
Memory usage on this node: 10.8/201.2 GB
Result logdir: /users/PYS1027/chnrhughes/ray_results/simple_training_example_ring2_v1
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - PPO_WaveAttenuationPOEnv-v0_0:	RUNNING, [2 CPUs, 0 GPUs], [pid=385820], 4739 s, 47 iter, 470000 ts, 3.65e+03 rew

[2m[36m(pid=385821)[0m 
[2m[36m(pid=385821)[0m -----------------------
[2m[36m(pid=385821)[0m ring length: 495
[2m[36m(pid=385821)[0m v_max: 2.79981792361692
[2m[36m(pid=385821)[0m -----------------------
[2m[36m(pid=385821)[0m 
[2m[36m(pid=385821)[0m -----------------------
[2m[36m(pid=385821)[0m ring length: 494
[2m[36m(pid=385821)[0m v_max: 2.7798238064662253
[2m[36m(pid=385821)[0m -----------------------
[2m[36m(pid=385821)[0m 
[2m[36m(pid=385821)[0m -----------------------
[2m[36m(pid=385821)[0m ring length: 507
[2m[36m(pid=385821)[0m v_max: 3.0397343746587766
[2m[36m(pid=385821)[0m -----------------------
[2m[36m(pid=385821)[0m 
[2m[36m(pid=385821)[0m -----------------------
[2m[36m(pid=385821)[0m ring length: 512
[2m[36m(pid=385821)[0m v_max: 3.139691674719026
[2m[36m(pid=385821)[0m -----------------------
[2m[36m(pid=385821)[0m 
[2m[36m(pid=385821)[0m -----------------------
[2m[36m(pid=385821)[0m ring length: 520
[2m[36m(pid=385821)[0m v_max: 3.2996121816646764
[2m[36m(pid=385821)[0m -----------------------
Result for PPO_WaveAttenuationPOEnv-v0_0:
  custom_metrics: {}
  date: 2020-03-30_09-35-13
  done: false
  episode_len_mean: 2000.0
  episode_reward_max: 4375.569003260175
  episode_reward_mean: 3722.7558679830986
  episode_reward_min: 3021.1649041664764
  episodes_this_iter: 5
  episodes_total: 240
  experiment_id: ba0edb931dde48dcb020df4b454540a2
  hostname: p0035.ten.osc.edu
  info:
    grad_time_ms: 228.137
    learner:
      default_policy:
        cur_kl_coeff: 1.421085492696024e-15
        cur_lr: 4.999999873689376e-05
        entropy: 0.35763517022132874
        entropy_coeff: 0.0
        kl: 0.003919678274542093
        policy_loss: -0.0011633033864200115
        total_loss: 3338.765380859375
        vf_explained_var: 2.8014183044433594e-06
        vf_loss: 3338.767333984375
    load_time_ms: 2.13
    num_steps_sampled: 480000
    num_steps_trained: 480000
    sample_time_ms: 100353.885
    update_time_ms: 2.246
  iterations_since_restore: 48
  node_ip: 10.4.1.36
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 2.6762237762237757
    ram_util_percent: 5.399999999999999
  pid: 385820
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 6.912462103017739
    mean_inference_ms: 0.5113053501045092
    mean_processing_ms: 2.617241606677847
  time_since_restore: 4840.417490243912
  time_this_iter_s: 100.8074963092804
  time_total_s: 4840.417490243912
  timestamp: 1585575313
  timesteps_since_restore: 480000
  timesteps_this_iter: 10000
  timesteps_total: 480000
  training_iteration: 48
  trial_id: fce6b7f4
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2/2 CPUs, 0/0 GPUs
Memory usage on this node: 10.8/201.2 GB
Result logdir: /users/PYS1027/chnrhughes/ray_results/simple_training_example_ring2_v1
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - PPO_WaveAttenuationPOEnv-v0_0:	RUNNING, [2 CPUs, 0 GPUs], [pid=385820], 4840 s, 48 iter, 480000 ts, 3.72e+03 rew

[2m[36m(pid=385820)[0m 2020-03-30 09:35:13,289	WARNING ppo.py:121 -- The magnitude of your environment rewards are more than 372.0x the scale of `vf_clip_param`. This means that it will take more than 372.0 iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.
[2m[36m(pid=385821)[0m 
[2m[36m(pid=385821)[0m -----------------------
[2m[36m(pid=385821)[0m ring length: 519
[2m[36m(pid=385821)[0m v_max: 3.2796229229775036
[2m[36m(pid=385821)[0m -----------------------
[2m[36m(pid=385821)[0m 
[2m[36m(pid=385821)[0m -----------------------
[2m[36m(pid=385821)[0m ring length: 510
[2m[36m(pid=385821)[0m v_max: 3.0997093626421153
[2m[36m(pid=385821)[0m -----------------------
[2m[36m(pid=385821)[0m 
[2m[36m(pid=385821)[0m -----------------------
[2m[36m(pid=385821)[0m ring length: 498
[2m[36m(pid=385821)[0m v_max: 2.8597993346145016
[2m[36m(pid=385821)[0m -----------------------
[2m[36m(pid=385821)[0m 
[2m[36m(pid=385821)[0m -----------------------
[2m[36m(pid=385821)[0m ring length: 512
[2m[36m(pid=385821)[0m v_max: 3.139691674719026
[2m[36m(pid=385821)[0m -----------------------
[2m[36m(pid=385821)[0m 
[2m[36m(pid=385821)[0m -----------------------
[2m[36m(pid=385821)[0m ring length: 490
[2m[36m(pid=385821)[0m v_max: 2.699845849180192
[2m[36m(pid=385821)[0m -----------------------
Result for PPO_WaveAttenuationPOEnv-v0_0:
  custom_metrics: {}
  date: 2020-03-30_09-36-53
  done: false
  episode_len_mean: 2000.0
  episode_reward_max: 4375.569003260175
  episode_reward_mean: 3763.458531513985
  episode_reward_min: 3033.3599107756972
  episodes_this_iter: 5
  episodes_total: 245
  experiment_id: ba0edb931dde48dcb020df4b454540a2
  hostname: p0035.ten.osc.edu
  info:
    grad_time_ms: 227.783
    learner:
      default_policy:
        cur_kl_coeff: 7.10542746348012e-16
        cur_lr: 4.999999873689376e-05
        entropy: 0.34603041410446167
        entropy_coeff: 0.0
        kl: 0.0049902028404176235
        policy_loss: -0.0011309768306091428
        total_loss: 3359.387939453125
        vf_explained_var: 1.0013580322265625e-05
        vf_loss: 3359.3896484375
    load_time_ms: 2.129
    num_steps_sampled: 490000
    num_steps_trained: 490000
    sample_time_ms: 100306.061
    update_time_ms: 2.22
  iterations_since_restore: 49
  node_ip: 10.4.1.36
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 2.6314685314685313
    ram_util_percent: 5.399999999999999
  pid: 385820
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 6.911196814535993
    mean_inference_ms: 0.5119125792168292
    mean_processing_ms: 2.6172230573928577
  time_since_restore: 4940.595074415207
  time_this_iter_s: 100.17758417129517
  time_total_s: 4940.595074415207
  timestamp: 1585575413
  timesteps_since_restore: 490000
  timesteps_this_iter: 10000
  timesteps_total: 490000
  training_iteration: 49
  trial_id: fce6b7f4
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2/2 CPUs, 0/0 GPUs
Memory usage on this node: 10.8/201.2 GB
Result logdir: /users/PYS1027/chnrhughes/ray_results/simple_training_example_ring2_v1
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - PPO_WaveAttenuationPOEnv-v0_0:	RUNNING, [2 CPUs, 0 GPUs], [pid=385820], 4940 s, 49 iter, 490000 ts, 3.76e+03 rew

[2m[36m(pid=385820)[0m 2020-03-30 09:36:53,477	WARNING ppo.py:121 -- The magnitude of your environment rewards are more than 376.0x the scale of `vf_clip_param`. This means that it will take more than 376.0 iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.
[2m[36m(pid=385821)[0m 
[2m[36m(pid=385821)[0m -----------------------
[2m[36m(pid=385821)[0m ring length: 510
[2m[36m(pid=385821)[0m v_max: 3.0997093626421153
[2m[36m(pid=385821)[0m -----------------------
[2m[36m(pid=385821)[0m 
[2m[36m(pid=385821)[0m -----------------------
[2m[36m(pid=385821)[0m ring length: 506
[2m[36m(pid=385821)[0m v_max: 3.0197423207835943
[2m[36m(pid=385821)[0m -----------------------
[2m[36m(pid=385821)[0m 
[2m[36m(pid=385821)[0m -----------------------
[2m[36m(pid=385821)[0m ring length: 498
[2m[36m(pid=385821)[0m v_max: 2.8597993346145016
[2m[36m(pid=385821)[0m -----------------------
[2m[36m(pid=385821)[0m 
[2m[36m(pid=385821)[0m -----------------------
[2m[36m(pid=385821)[0m ring length: 498
[2m[36m(pid=385821)[0m v_max: 2.8597993346145016
[2m[36m(pid=385821)[0m -----------------------
[2m[36m(pid=385821)[0m 
[2m[36m(pid=385821)[0m -----------------------
[2m[36m(pid=385821)[0m ring length: 510
[2m[36m(pid=385821)[0m v_max: 3.0997093626421153
[2m[36m(pid=385821)[0m -----------------------
Result for PPO_WaveAttenuationPOEnv-v0_0:
  custom_metrics: {}
  date: 2020-03-30_09-38-33
  done: false
  episode_len_mean: 2000.0
  episode_reward_max: 4375.569003260175
  episode_reward_mean: 3801.263340723979
  episode_reward_min: 3219.537860246359
  episodes_this_iter: 5
  episodes_total: 250
  experiment_id: ba0edb931dde48dcb020df4b454540a2
  hostname: p0035.ten.osc.edu
  info:
    grad_time_ms: 228.855
    learner:
      default_policy:
        cur_kl_coeff: 3.55271373174006e-16
        cur_lr: 4.999999873689376e-05
        entropy: 0.3351278305053711
        entropy_coeff: 0.0
        kl: 0.0004888130933977664
        policy_loss: -0.0003547214437276125
        total_loss: 3323.94482421875
        vf_explained_var: 1.3113021850585938e-06
        vf_loss: 3323.9453125
    load_time_ms: 2.136
    num_steps_sampled: 500000
    num_steps_trained: 500000
    sample_time_ms: 100261.455
    update_time_ms: 2.23
  iterations_since_restore: 50
  node_ip: 10.4.1.36
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 2.6281690140845066
    ram_util_percent: 5.399999999999998
  pid: 385820
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 6.910032951740002
    mean_inference_ms: 0.5124336175481014
    mean_processing_ms: 2.6172092484997727
  time_since_restore: 5040.762880563736
  time_this_iter_s: 100.16780614852905
  time_total_s: 5040.762880563736
  timestamp: 1585575513
  timesteps_since_restore: 500000
  timesteps_this_iter: 10000
  timesteps_total: 500000
  training_iteration: 50
  trial_id: fce6b7f4
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2/2 CPUs, 0/0 GPUs
Memory usage on this node: 10.8/201.2 GB
Result logdir: /users/PYS1027/chnrhughes/ray_results/simple_training_example_ring2_v1
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - PPO_WaveAttenuationPOEnv-v0_0:	RUNNING, [2 CPUs, 0 GPUs], [pid=385820], 5040 s, 50 iter, 500000 ts, 3.8e+03 rew

[2m[36m(pid=385820)[0m 2020-03-30 09:38:33,653	WARNING ppo.py:121 -- The magnitude of your environment rewards are more than 380.0x the scale of `vf_clip_param`. This means that it will take more than 380.0 iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.
[2m[36m(pid=385821)[0m 
[2m[36m(pid=385821)[0m -----------------------
[2m[36m(pid=385821)[0m ring length: 514
[2m[36m(pid=385821)[0m v_max: 3.1796731425699525
[2m[36m(pid=385821)[0m -----------------------
[2m[36m(pid=385821)[0m 
[2m[36m(pid=385821)[0m -----------------------
[2m[36m(pid=385821)[0m ring length: 499
[2m[36m(pid=385821)[0m v_max: 2.8797928146697993
[2m[36m(pid=385821)[0m -----------------------
[2m[36m(pid=385821)[0m 
[2m[36m(pid=385821)[0m -----------------------
[2m[36m(pid=385821)[0m ring length: 498
[2m[36m(pid=385821)[0m v_max: 2.8597993346145016
[2m[36m(pid=385821)[0m -----------------------
[2m[36m(pid=385821)[0m 
[2m[36m(pid=385821)[0m -----------------------
[2m[36m(pid=385821)[0m ring length: 519
[2m[36m(pid=385821)[0m v_max: 3.2796229229775036
[2m[36m(pid=385821)[0m -----------------------
[2m[36m(pid=385821)[0m 
[2m[36m(pid=385821)[0m -----------------------
[2m[36m(pid=385821)[0m ring length: 507
[2m[36m(pid=385821)[0m v_max: 3.0397343746587766
[2m[36m(pid=385821)[0m -----------------------
Result for PPO_WaveAttenuationPOEnv-v0_0:
  custom_metrics: {}
  date: 2020-03-30_09-40-14
  done: false
  episode_len_mean: 2000.0
  episode_reward_max: 4465.613951529086
  episode_reward_mean: 3846.9725442370705
  episode_reward_min: 3275.0928241045704
  episodes_this_iter: 5
  episodes_total: 255
  experiment_id: ba0edb931dde48dcb020df4b454540a2
  hostname: p0035.ten.osc.edu
  info:
    grad_time_ms: 228.646
    learner:
      default_policy:
        cur_kl_coeff: 1.77635686587003e-16
        cur_lr: 4.999999873689376e-05
        entropy: 0.32580968737602234
        entropy_coeff: 0.0
        kl: 0.0055580781772732735
        policy_loss: -0.0007475082529708743
        total_loss: 3617.771240234375
        vf_explained_var: 3.7550926208496094e-06
        vf_loss: 3617.772705078125
    load_time_ms: 2.135
    num_steps_sampled: 510000
    num_steps_trained: 510000
    sample_time_ms: 100190.796
    update_time_ms: 2.226
  iterations_since_restore: 51
  node_ip: 10.4.1.36
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 2.6472222222222226
    ram_util_percent: 5.3999999999999995
  pid: 385820
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 6.9089598003702966
    mean_inference_ms: 0.5128970764943691
    mean_processing_ms: 2.617195699505998
  time_since_restore: 5141.448397159576
  time_this_iter_s: 100.68551659584045
  time_total_s: 5141.448397159576
  timestamp: 1585575614
  timesteps_since_restore: 510000
  timesteps_this_iter: 10000
  timesteps_total: 510000
  training_iteration: 51
  trial_id: fce6b7f4
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2/2 CPUs, 0/0 GPUs
Memory usage on this node: 10.8/201.2 GB
Result logdir: /users/PYS1027/chnrhughes/ray_results/simple_training_example_ring2_v1
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - PPO_WaveAttenuationPOEnv-v0_0:	RUNNING, [2 CPUs, 0 GPUs], [pid=385820], 5141 s, 51 iter, 510000 ts, 3.85e+03 rew

[2m[36m(pid=385820)[0m 2020-03-30 09:40:14,362	WARNING ppo.py:121 -- The magnitude of your environment rewards are more than 385.0x the scale of `vf_clip_param`. This means that it will take more than 385.0 iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.
[2m[36m(pid=385821)[0m 
[2m[36m(pid=385821)[0m -----------------------
[2m[36m(pid=385821)[0m ring length: 490
[2m[36m(pid=385821)[0m v_max: 2.699845849180192
[2m[36m(pid=385821)[0m -----------------------
[2m[36m(pid=385821)[0m 
[2m[36m(pid=385821)[0m -----------------------
[2m[36m(pid=385821)[0m ring length: 514
[2m[36m(pid=385821)[0m v_max: 3.1796731425699525
[2m[36m(pid=385821)[0m -----------------------
[2m[36m(pid=385821)[0m 
[2m[36m(pid=385821)[0m -----------------------
[2m[36m(pid=385821)[0m ring length: 503
[2m[36m(pid=385821)[0m v_max: 2.9597650335315784
[2m[36m(pid=385821)[0m -----------------------
[2m[36m(pid=385821)[0m 
[2m[36m(pid=385821)[0m -----------------------
[2m[36m(pid=385821)[0m ring length: 513
[2m[36m(pid=385821)[0m v_max: 3.1596825160053825
[2m[36m(pid=385821)[0m -----------------------
[2m[36m(pid=385821)[0m 
[2m[36m(pid=385821)[0m -----------------------
[2m[36m(pid=385821)[0m ring length: 499
[2m[36m(pid=385821)[0m v_max: 2.8797928146697993
[2m[36m(pid=385821)[0m -----------------------
Result for PPO_WaveAttenuationPOEnv-v0_0:
  custom_metrics: {}
  date: 2020-03-30_09-41-54
  done: false
  episode_len_mean: 2000.0
  episode_reward_max: 4465.613951529086
  episode_reward_mean: 3878.669153210518
  episode_reward_min: 3285.525969837912
  episodes_this_iter: 5
  episodes_total: 260
  experiment_id: ba0edb931dde48dcb020df4b454540a2
  hostname: p0035.ten.osc.edu
  info:
    grad_time_ms: 227.628
    learner:
      default_policy:
        cur_kl_coeff: 8.88178432935015e-17
        cur_lr: 4.999999873689376e-05
        entropy: 0.30879366397857666
        entropy_coeff: 0.0
        kl: 0.0015558106824755669
        policy_loss: -0.001362210139632225
        total_loss: 3336.37353515625
        vf_explained_var: 7.152557373046875e-06
        vf_loss: 3336.374755859375
    load_time_ms: 2.156
    num_steps_sampled: 520000
    num_steps_trained: 520000
    sample_time_ms: 100150.287
    update_time_ms: 2.145
  iterations_since_restore: 52
  node_ip: 10.4.1.36
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 2.6405594405594406
    ram_util_percent: 5.399999999999999
  pid: 385820
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 6.90787094438924
    mean_inference_ms: 0.5133646986069372
    mean_processing_ms: 2.617164910381047
  time_since_restore: 5242.029956817627
  time_this_iter_s: 100.58155965805054
  time_total_s: 5242.029956817627
  timestamp: 1585575714
  timesteps_since_restore: 520000
  timesteps_this_iter: 10000
  timesteps_total: 520000
  training_iteration: 52
  trial_id: fce6b7f4
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2/2 CPUs, 0/0 GPUs
Memory usage on this node: 10.8/201.2 GB
Result logdir: /users/PYS1027/chnrhughes/ray_results/simple_training_example_ring2_v1
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - PPO_WaveAttenuationPOEnv-v0_0:	RUNNING, [2 CPUs, 0 GPUs], [pid=385820], 5242 s, 52 iter, 520000 ts, 3.88e+03 rew

[2m[36m(pid=385820)[0m 2020-03-30 09:41:54,958	WARNING ppo.py:121 -- The magnitude of your environment rewards are more than 388.0x the scale of `vf_clip_param`. This means that it will take more than 388.0 iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.
[2m[36m(pid=385821)[0m 
[2m[36m(pid=385821)[0m -----------------------
[2m[36m(pid=385821)[0m ring length: 490
[2m[36m(pid=385821)[0m v_max: 2.699845849180192
[2m[36m(pid=385821)[0m -----------------------
2020-03-30 09:42:11,305	ERROR trial_runner.py:550 -- Error processing event.
Traceback (most recent call last):
  File "/users/PYS1027/chnrhughes/.local/lib/python3.5/site-packages/ray/tune/trial_runner.py", line 498, in _process_trial
    result = self.trial_executor.fetch_result(trial)
  File "/users/PYS1027/chnrhughes/.local/lib/python3.5/site-packages/ray/tune/ray_trial_executor.py", line 342, in fetch_result
    result = ray.get(trial_future[0])
  File "/users/PYS1027/chnrhughes/.local/lib/python3.5/site-packages/ray/worker.py", line 2247, in get
    raise value
ray.exceptions.RayTaskError: [36mray_PPO:train()[39m (pid=385820, host=p0035.ten.osc.edu)
  File "/users/PYS1027/chnrhughes/.local/lib/python3.5/site-packages/ray/rllib/agents/trainer.py", line 369, in train
    raise e
  File "/users/PYS1027/chnrhughes/.local/lib/python3.5/site-packages/ray/rllib/agents/trainer.py", line 358, in train
    result = Trainable.train(self)
  File "/users/PYS1027/chnrhughes/.local/lib/python3.5/site-packages/ray/tune/trainable.py", line 171, in train
    result = self._train()
  File "/users/PYS1027/chnrhughes/.local/lib/python3.5/site-packages/ray/rllib/agents/trainer_template.py", line 126, in _train
    fetches = self.optimizer.step()
  File "/users/PYS1027/chnrhughes/.local/lib/python3.5/site-packages/ray/rllib/optimizers/multi_gpu_optimizer.py", line 140, in step
    self.num_envs_per_worker, self.train_batch_size)
  File "/users/PYS1027/chnrhughes/.local/lib/python3.5/site-packages/ray/rllib/optimizers/rollout.py", line 29, in collect_samples
    next_sample = ray_get_and_free(fut_sample)
  File "/users/PYS1027/chnrhughes/.local/lib/python3.5/site-packages/ray/rllib/utils/memory.py", line 33, in ray_get_and_free
    result = ray.get(object_ids)
ray.exceptions.RayTaskError: [36mray_RolloutWorker:sample()[39m (pid=385821, host=p0035.ten.osc.edu)
  File "/users/PYS1027/chnrhughes/.local/lib/python3.5/site-packages/ray/rllib/evaluation/rollout_worker.py", line 453, in sample
    batches = [self.input_reader.next()]
  File "/users/PYS1027/chnrhughes/.local/lib/python3.5/site-packages/ray/rllib/evaluation/sampler.py", line 56, in next
    batches = [self.get_data()]
  File "/users/PYS1027/chnrhughes/.local/lib/python3.5/site-packages/ray/rllib/evaluation/sampler.py", line 97, in get_data
    item = next(self.rollout_provider)
  File "/users/PYS1027/chnrhughes/.local/lib/python3.5/site-packages/ray/rllib/evaluation/sampler.py", line 313, in _env_runner
    soft_horizon)
  File "/users/PYS1027/chnrhughes/.local/lib/python3.5/site-packages/ray/rllib/evaluation/sampler.py", line 473, in _process_observations
    resetted_obs = base_env.try_reset(env_id)
  File "/users/PYS1027/chnrhughes/.local/lib/python3.5/site-packages/ray/rllib/env/base_env.py", line 336, in try_reset
    return {_DUMMY_AGENT_ID: self.vector_env.reset_at(env_id)}
  File "/users/PYS1027/chnrhughes/.local/lib/python3.5/site-packages/ray/rllib/env/vector_env.py", line 104, in reset_at
    return self.envs[index].reset()
  File "/users/PYS1027/chnrhughes/work/flowtest/flow/flow/envs/ring/wave_attenuation.py", line 210, in reset
    observation = super().reset()
  File "/users/PYS1027/chnrhughes/work/flowtest/flow/flow/envs/base.py", line 528, in reset
    raise FatalFlowError(msg=msg)
flow.utils.exceptions.FatalFlowError: 
Not enough vehicles have spawned! Bad start?
Missing vehicles / initial state:
- rl_0: ('rl', 'left', 0, 115.23172929833133, 0)



2020-03-30 09:42:11,318	INFO trial_runner.py:587 -- Attempting to recover trial state from last checkpoint.
2020-03-30 09:42:11,321	WARNING signature.py:108 -- The function with_updates has a **kwargs argument, which is currently not supported.
[2m[36m(pid=385820)[0m 2020-03-30 09:42:11,284	INFO trainer.py:366 -- Worker crashed during call to train(). To attempt to continue training without the failed worker, set `'ignore_worker_failures': True`.
[2m[36m(pid=424867)[0m WARNING:tensorflow:From /users/PYS1027/chnrhughes/.local/lib/python3.5/site-packages/tensorflow/python/compat/v2_compat.py:61: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.
[2m[36m(pid=424867)[0m Instructions for updating:
[2m[36m(pid=424867)[0m non-resource variables are not supported in the long term
[2m[36m(pid=424867)[0m 2020-03-30 09:42:16,573	WARNING ppo.py:143 -- FYI: By default, the value function will not share layers with the policy model ('vf_share_layers': False).
[2m[36m(pid=424867)[0m 2020-03-30 09:42:17,716	INFO rollout_worker.py:319 -- Creating policy evaluation worker 0 on CPU (please ignore any CUDA init errors)
[2m[36m(pid=424867)[0m 2020-03-30 09:42:17.717823: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
[2m[36m(pid=424867)[0m 2020-03-30 09:42:17.722758: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2400000000 Hz
[2m[36m(pid=424867)[0m 2020-03-30 09:42:17.724363: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x28ed360 executing computations on platform Host. Devices:
[2m[36m(pid=424867)[0m 2020-03-30 09:42:17.724396: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
[2m[36m(pid=424867)[0m WARNING:tensorflow:From /users/PYS1027/chnrhughes/.local/lib/python3.5/site-packages/ray/rllib/models/tf/fcnet_v1.py:48: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.
[2m[36m(pid=424867)[0m Instructions for updating:
[2m[36m(pid=424867)[0m Use keras.layers.dense instead.
[2m[36m(pid=424867)[0m WARNING:tensorflow:From /users/PYS1027/chnrhughes/.local/lib/python3.5/site-packages/ray/rllib/models/tf/fcnet_v1.py:48: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.
[2m[36m(pid=424867)[0m Instructions for updating:
[2m[36m(pid=424867)[0m Use keras.layers.dense instead.
[2m[36m(pid=424867)[0m WARNING:tensorflow:From /users/PYS1027/chnrhughes/.local/lib/python3.5/site-packages/ray/rllib/models/tf/tf_action_dist.py:138: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
[2m[36m(pid=424867)[0m Instructions for updating:
[2m[36m(pid=424867)[0m Use `tf.cast` instead.
[2m[36m(pid=424867)[0m WARNING:tensorflow:From /users/PYS1027/chnrhughes/.local/lib/python3.5/site-packages/ray/rllib/models/tf/tf_action_dist.py:138: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
[2m[36m(pid=424867)[0m Instructions for updating:
[2m[36m(pid=424867)[0m Use `tf.cast` instead.
[2m[36m(pid=424867)[0m 2020-03-30 09:42:18.117016: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1412] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.
[2m[36m(pid=424867)[0m 2020-03-30 09:42:18,132	INFO dynamic_tf_policy.py:324 -- Initializing loss function with dummy input:
[2m[36m(pid=424867)[0m 
[2m[36m(pid=424867)[0m { 'action_prob': <tf.Tensor 'default_policy/action_prob:0' shape=(?,) dtype=float32>,
[2m[36m(pid=424867)[0m   'actions': <tf.Tensor 'default_policy/actions:0' shape=(?, 1) dtype=float32>,
[2m[36m(pid=424867)[0m   'advantages': <tf.Tensor 'default_policy/advantages:0' shape=(?,) dtype=float32>,
[2m[36m(pid=424867)[0m   'behaviour_logits': <tf.Tensor 'default_policy/behaviour_logits:0' shape=(?, 2) dtype=float32>,
[2m[36m(pid=424867)[0m   'dones': <tf.Tensor 'default_policy/dones:0' shape=(?,) dtype=bool>,
[2m[36m(pid=424867)[0m   'new_obs': <tf.Tensor 'default_policy/new_obs:0' shape=(?, 3) dtype=float32>,
[2m[36m(pid=424867)[0m   'obs': <tf.Tensor 'default_policy/observation:0' shape=(?, 3) dtype=float32>,
[2m[36m(pid=424867)[0m   'prev_actions': <tf.Tensor 'default_policy/action:0' shape=(?, 1) dtype=float32>,
[2m[36m(pid=424867)[0m   'prev_rewards': <tf.Tensor 'default_policy/prev_reward:0' shape=(?,) dtype=float32>,
[2m[36m(pid=424867)[0m   'rewards': <tf.Tensor 'default_policy/rewards:0' shape=(?,) dtype=float32>,
[2m[36m(pid=424867)[0m   'value_targets': <tf.Tensor 'default_policy/value_targets:0' shape=(?,) dtype=float32>,
[2m[36m(pid=424867)[0m   'vf_preds': <tf.Tensor 'default_policy/vf_preds:0' shape=(?,) dtype=float32>}
[2m[36m(pid=424867)[0m 
[2m[36m(pid=424867)[0m WARNING:tensorflow:From /users/PYS1027/chnrhughes/.local/lib/python3.5/site-packages/tensorflow/python/ops/array_ops.py:1354: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
[2m[36m(pid=424867)[0m Instructions for updating:
[2m[36m(pid=424867)[0m Use tf.where in 2.0, which has the same broadcast rule as np.where
[2m[36m(pid=424867)[0m WARNING:tensorflow:From /users/PYS1027/chnrhughes/.local/lib/python3.5/site-packages/tensorflow/python/ops/array_ops.py:1354: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
[2m[36m(pid=424867)[0m Instructions for updating:
[2m[36m(pid=424867)[0m Use tf.where in 2.0, which has the same broadcast rule as np.where
[2m[36m(pid=424867)[0m 2020-03-30 09:42:18,862	INFO rollout_worker.py:742 -- Built policy map: {'default_policy': <ray.rllib.policy.tf_policy_template.PPOTFPolicy object at 0x2b5db0e55198>}
[2m[36m(pid=424867)[0m 2020-03-30 09:42:18,862	INFO rollout_worker.py:743 -- Built preprocessor map: {'default_policy': <ray.rllib.models.preprocessors.NoPreprocessor object at 0x2b5db0e550b8>}
[2m[36m(pid=424867)[0m 2020-03-30 09:42:18,862	INFO rollout_worker.py:356 -- Built filter map: {'default_policy': <ray.rllib.utils.filter.NoFilter object at 0x2b6316825f28>}
[2m[36m(pid=424867)[0m 2020-03-30 09:42:18,882	INFO multi_gpu_optimizer.py:93 -- LocalMultiGPUOptimizer devices ['/cpu:0']
2020-03-30 09:42:21,297	WARNING util.py:145 -- The `get_current_ip` operation took 9.959716320037842 seconds to complete, which may be a performance bottleneck.
[2m[36m(pid=424867)[0m 2020-03-30 09:42:21,294	WARNING util.py:47 -- Install gputil for GPU system monitoring.
[2m[36m(pid=424867)[0m 2020-03-30 09:42:21,296	WARNING trainable.py:126 -- Getting current IP.
2020-03-30 09:42:21,351	WARNING util.py:145 -- The `process_trial` operation took 10.04809832572937 seconds to complete, which may be a performance bottleneck.
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2/2 CPUs, 0/0 GPUs
Memory usage on this node: 10.7/201.2 GB
Result logdir: /users/PYS1027/chnrhughes/ray_results/simple_training_example_ring2_v1
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - PPO_WaveAttenuationPOEnv-v0_0:	RUNNING, 1 failures: /users/PYS1027/chnrhughes/ray_results/simple_training_example_ring2_v1/PPO_WaveAttenuationPOEnv-v0_0_2020-03-30_08-14-21aa4md2pi/error_2020-03-30_09-42-11.txt, [2 CPUs, 0 GPUs], [pid=385820], 5040 s, 50 iter, 500000 ts, 3.8e+03 rew

[2m[36m(pid=424867)[0m WARNING:tensorflow:From /users/PYS1027/chnrhughes/.local/lib/python3.5/site-packages/ray/rllib/policy/tf_policy.py:570: Variable.load (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
[2m[36m(pid=424867)[0m Instructions for updating:
[2m[36m(pid=424867)[0m Prefer Variable.assign which has equivalent behavior in 2.X.
[2m[36m(pid=424867)[0m WARNING:tensorflow:From /users/PYS1027/chnrhughes/.local/lib/python3.5/site-packages/ray/rllib/policy/tf_policy.py:570: Variable.load (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
[2m[36m(pid=424867)[0m Instructions for updating:
[2m[36m(pid=424867)[0m Prefer Variable.assign which has equivalent behavior in 2.X.
[2m[36m(pid=425132)[0m WARNING:tensorflow:From /users/PYS1027/chnrhughes/.local/lib/python3.5/site-packages/tensorflow/python/compat/v2_compat.py:61: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.
[2m[36m(pid=425132)[0m Instructions for updating:
[2m[36m(pid=425132)[0m non-resource variables are not supported in the long term
[2m[36m(pid=425132)[0m 2020-03-30 09:42:24,445	INFO rollout_worker.py:319 -- Creating policy evaluation worker 1 on CPU (please ignore any CUDA init errors)
[2m[36m(pid=425132)[0m 2020-03-30 09:42:24.463117: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
[2m[36m(pid=425132)[0m 2020-03-30 09:42:24.467465: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2400000000 Hz
[2m[36m(pid=425132)[0m 2020-03-30 09:42:24.469036: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x294dfd0 executing computations on platform Host. Devices:
[2m[36m(pid=425132)[0m 2020-03-30 09:42:24.469068: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
[2m[36m(pid=425132)[0m WARNING:tensorflow:From /users/PYS1027/chnrhughes/.local/lib/python3.5/site-packages/ray/rllib/models/tf/fcnet_v1.py:48: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.
[2m[36m(pid=425132)[0m Instructions for updating:
[2m[36m(pid=425132)[0m Use keras.layers.dense instead.
[2m[36m(pid=425132)[0m WARNING:tensorflow:From /users/PYS1027/chnrhughes/.local/lib/python3.5/site-packages/ray/rllib/models/tf/fcnet_v1.py:48: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.
[2m[36m(pid=425132)[0m Instructions for updating:
[2m[36m(pid=425132)[0m Use keras.layers.dense instead.
[2m[36m(pid=425132)[0m WARNING:tensorflow:From /users/PYS1027/chnrhughes/.local/lib/python3.5/site-packages/ray/rllib/models/tf/tf_action_dist.py:138: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
[2m[36m(pid=425132)[0m Instructions for updating:
[2m[36m(pid=425132)[0m Use `tf.cast` instead.
[2m[36m(pid=425132)[0m WARNING:tensorflow:From /users/PYS1027/chnrhughes/.local/lib/python3.5/site-packages/ray/rllib/models/tf/tf_action_dist.py:138: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
[2m[36m(pid=425132)[0m Instructions for updating:
[2m[36m(pid=425132)[0m Use `tf.cast` instead.
[2m[36m(pid=425132)[0m 2020-03-30 09:42:24.855097: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1412] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.
[2m[36m(pid=425132)[0m 2020-03-30 09:42:24,871	INFO dynamic_tf_policy.py:324 -- Initializing loss function with dummy input:
[2m[36m(pid=425132)[0m 
[2m[36m(pid=425132)[0m { 'action_prob': <tf.Tensor 'default_policy/action_prob:0' shape=(?,) dtype=float32>,
[2m[36m(pid=425132)[0m   'actions': <tf.Tensor 'default_policy/actions:0' shape=(?, 1) dtype=float32>,
[2m[36m(pid=425132)[0m   'advantages': <tf.Tensor 'default_policy/advantages:0' shape=(?,) dtype=float32>,
[2m[36m(pid=425132)[0m   'behaviour_logits': <tf.Tensor 'default_policy/behaviour_logits:0' shape=(?, 2) dtype=float32>,
[2m[36m(pid=425132)[0m   'dones': <tf.Tensor 'default_policy/dones:0' shape=(?,) dtype=bool>,
[2m[36m(pid=425132)[0m   'new_obs': <tf.Tensor 'default_policy/new_obs:0' shape=(?, 3) dtype=float32>,
[2m[36m(pid=425132)[0m   'obs': <tf.Tensor 'default_policy/observation:0' shape=(?, 3) dtype=float32>,
[2m[36m(pid=425132)[0m   'prev_actions': <tf.Tensor 'default_policy/action:0' shape=(?, 1) dtype=float32>,
[2m[36m(pid=425132)[0m   'prev_rewards': <tf.Tensor 'default_policy/prev_reward:0' shape=(?,) dtype=float32>,
[2m[36m(pid=425132)[0m   'rewards': <tf.Tensor 'default_policy/rewards:0' shape=(?,) dtype=float32>,
[2m[36m(pid=425132)[0m   'value_targets': <tf.Tensor 'default_policy/value_targets:0' shape=(?,) dtype=float32>,
[2m[36m(pid=425132)[0m   'vf_preds': <tf.Tensor 'default_policy/vf_preds:0' shape=(?,) dtype=float32>}
[2m[36m(pid=425132)[0m 
[2m[36m(pid=425132)[0m WARNING:tensorflow:From /users/PYS1027/chnrhughes/.local/lib/python3.5/site-packages/tensorflow/python/ops/array_ops.py:1354: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
[2m[36m(pid=425132)[0m Instructions for updating:
[2m[36m(pid=425132)[0m Use tf.where in 2.0, which has the same broadcast rule as np.where
[2m[36m(pid=425132)[0m WARNING:tensorflow:From /users/PYS1027/chnrhughes/.local/lib/python3.5/site-packages/tensorflow/python/ops/array_ops.py:1354: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
[2m[36m(pid=425132)[0m Instructions for updating:
[2m[36m(pid=425132)[0m Use tf.where in 2.0, which has the same broadcast rule as np.where
[2m[36m(pid=425132)[0m WARNING:tensorflow:From /users/PYS1027/chnrhughes/.local/lib/python3.5/site-packages/ray/rllib/policy/tf_policy.py:570: Variable.load (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
[2m[36m(pid=425132)[0m Instructions for updating:
[2m[36m(pid=425132)[0m Prefer Variable.assign which has equivalent behavior in 2.X.
[2m[36m(pid=425132)[0m WARNING:tensorflow:From /users/PYS1027/chnrhughes/.local/lib/python3.5/site-packages/ray/rllib/policy/tf_policy.py:570: Variable.load (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
[2m[36m(pid=425132)[0m Instructions for updating:
[2m[36m(pid=425132)[0m Prefer Variable.assign which has equivalent behavior in 2.X.
[2m[36m(pid=425132)[0m 
[2m[36m(pid=425132)[0m -----------------------
[2m[36m(pid=425132)[0m ring length: 520
[2m[36m(pid=425132)[0m v_max: 3.2996121816646764
[2m[36m(pid=425132)[0m -----------------------
[2m[36m(pid=425132)[0m 2020-03-30 09:42:25,644	INFO rollout_worker.py:451 -- Generating sample batch of size 200
[2m[36m(pid=425132)[0m 2020-03-30 09:42:30,656	INFO sampler.py:304 -- Raw obs from env: { 0: { 'agent0': np.ndarray((3,), dtype=float64, min=-0.008, max=0.853, mean=0.295)}}
[2m[36m(pid=425132)[0m 2020-03-30 09:42:30,657	INFO sampler.py:305 -- Info return from env: {0: {'agent0': None}}
[2m[36m(pid=425132)[0m 2020-03-30 09:42:30,658	INFO sampler.py:403 -- Preprocessed obs: np.ndarray((3,), dtype=float64, min=-0.008, max=0.853, mean=0.295)
[2m[36m(pid=425132)[0m 2020-03-30 09:42:30,658	INFO sampler.py:407 -- Filtered obs: np.ndarray((3,), dtype=float64, min=-0.008, max=0.853, mean=0.295)
[2m[36m(pid=425132)[0m 2020-03-30 09:42:30,659	INFO sampler.py:521 -- Inputs to compute_actions():
[2m[36m(pid=425132)[0m 
[2m[36m(pid=425132)[0m { 'default_policy': [ { 'data': { 'agent_id': 'agent0',
[2m[36m(pid=425132)[0m                                   'env_id': 0,
[2m[36m(pid=425132)[0m                                   'info': None,
[2m[36m(pid=425132)[0m                                   'obs': np.ndarray((3,), dtype=float64, min=-0.008, max=0.853, mean=0.295),
[2m[36m(pid=425132)[0m                                   'prev_action': np.ndarray((1,), dtype=float32, min=0.0, max=0.0, mean=0.0),
[2m[36m(pid=425132)[0m                                   'prev_reward': 0.0,
[2m[36m(pid=425132)[0m                                   'rnn_state': []},
[2m[36m(pid=425132)[0m                         'type': 'PolicyEvalData'}]}
[2m[36m(pid=425132)[0m 
[2m[36m(pid=425132)[0m 2020-03-30 09:42:30,659	INFO tf_run_builder.py:92 -- Executing TF run without tracing. To dump TF timeline traces to disk, set the TF_TIMELINE_DIR environment variable.
[2m[36m(pid=425132)[0m 2020-03-30 09:42:30,707	INFO sampler.py:548 -- Outputs of compute_actions():
[2m[36m(pid=425132)[0m 
[2m[36m(pid=425132)[0m { 'default_policy': ( np.ndarray((1, 1), dtype=float32, min=0.094, max=0.094, mean=0.094),
[2m[36m(pid=425132)[0m                       [],
[2m[36m(pid=425132)[0m                       { 'action_prob': np.ndarray((1,), dtype=float32, min=2.587, max=2.587, mean=2.587),
[2m[36m(pid=425132)[0m                         'behaviour_logits': np.ndarray((1, 2), dtype=float32, min=-2.173, max=0.005, mean=-1.084),
[2m[36m(pid=425132)[0m                         'vf_preds': np.ndarray((1,), dtype=float32, min=4.478, max=4.478, mean=4.478)})}
[2m[36m(pid=425132)[0m 
[2m[36m(pid=425132)[0m 2020-03-30 09:42:32,042	INFO sample_batch_builder.py:161 -- Trajectory fragment after postprocess_trajectory():
[2m[36m(pid=425132)[0m 
[2m[36m(pid=425132)[0m { 'agent0': { 'data': { 'action_prob': np.ndarray((200,), dtype=float32, min=0.137, max=3.502, mean=2.506),
[2m[36m(pid=425132)[0m                         'actions': np.ndarray((200, 1), dtype=float32, min=-0.227, max=0.295, mean=0.019),
[2m[36m(pid=425132)[0m                         'advantages': np.ndarray((200,), dtype=float32, min=2.183, max=75.198, mean=61.698),
[2m[36m(pid=425132)[0m                         'agent_index': np.ndarray((200,), dtype=int64, min=0.0, max=0.0, mean=0.0),
[2m[36m(pid=425132)[0m                         'behaviour_logits': np.ndarray((200, 2), dtype=float32, min=-2.173, max=0.005, mean=-1.083),
[2m[36m(pid=425132)[0m                         'dones': np.ndarray((200,), dtype=bool, min=0.0, max=0.0, mean=0.0),
[2m[36m(pid=425132)[0m                         'eps_id': np.ndarray((200,), dtype=int64, min=1067815217.0, max=1067815217.0, mean=1067815217.0),
[2m[36m(pid=425132)[0m                         'infos': np.ndarray((200,), dtype=object, head={}),
[2m[36m(pid=425132)[0m                         'new_obs': np.ndarray((200, 3), dtype=float32, min=-0.011, max=0.853, mean=0.293),
[2m[36m(pid=425132)[0m                         'obs': np.ndarray((200, 3), dtype=float32, min=-0.011, max=0.853, mean=0.293),
[2m[36m(pid=425132)[0m                         'prev_actions': np.ndarray((200, 1), dtype=float32, min=-0.227, max=0.295, mean=0.019),
[2m[36m(pid=425132)[0m                         'prev_rewards': np.ndarray((200,), dtype=float32, min=0.0, max=2.618, mean=2.254),
[2m[36m(pid=425132)[0m                         'rewards': np.ndarray((200,), dtype=float32, min=1.44, max=2.618, mean=2.265),
[2m[36m(pid=425132)[0m                         't': np.ndarray((200,), dtype=int64, min=0.0, max=199.0, mean=99.5),
[2m[36m(pid=425132)[0m                         'unroll_id': np.ndarray((200,), dtype=int64, min=0.0, max=0.0, mean=0.0),
[2m[36m(pid=425132)[0m                         'value_targets': np.ndarray((200,), dtype=float32, min=6.661, max=79.677, mean=66.176),
[2m[36m(pid=425132)[0m                         'vf_preds': np.ndarray((200,), dtype=float32, min=4.478, max=4.478, mean=4.478)},
[2m[36m(pid=425132)[0m               'type': 'SampleBatch'}}
[2m[36m(pid=425132)[0m 
[2m[36m(pid=425132)[0m 2020-03-30 09:42:32,044	INFO rollout_worker.py:485 -- Completed sample batch:
[2m[36m(pid=425132)[0m 
[2m[36m(pid=425132)[0m { 'data': { 'action_prob': np.ndarray((200,), dtype=float32, min=0.137, max=3.502, mean=2.506),
[2m[36m(pid=425132)[0m             'actions': np.ndarray((200, 1), dtype=float32, min=-0.227, max=0.295, mean=0.019),
[2m[36m(pid=425132)[0m             'advantages': np.ndarray((200,), dtype=float32, min=2.183, max=75.198, mean=61.698),
[2m[36m(pid=425132)[0m             'agent_index': np.ndarray((200,), dtype=int64, min=0.0, max=0.0, mean=0.0),
[2m[36m(pid=425132)[0m             'behaviour_logits': np.ndarray((200, 2), dtype=float32, min=-2.173, max=0.005, mean=-1.083),
[2m[36m(pid=425132)[0m             'dones': np.ndarray((200,), dtype=bool, min=0.0, max=0.0, mean=0.0),
[2m[36m(pid=425132)[0m             'eps_id': np.ndarray((200,), dtype=int64, min=1067815217.0, max=1067815217.0, mean=1067815217.0),
[2m[36m(pid=425132)[0m             'infos': np.ndarray((200,), dtype=object, head={}),
[2m[36m(pid=425132)[0m             'new_obs': np.ndarray((200, 3), dtype=float32, min=-0.011, max=0.853, mean=0.293),
[2m[36m(pid=425132)[0m             'obs': np.ndarray((200, 3), dtype=float32, min=-0.011, max=0.853, mean=0.293),
[2m[36m(pid=425132)[0m             'prev_actions': np.ndarray((200, 1), dtype=float32, min=-0.227, max=0.295, mean=0.019),
[2m[36m(pid=425132)[0m             'prev_rewards': np.ndarray((200,), dtype=float32, min=0.0, max=2.618, mean=2.254),
[2m[36m(pid=425132)[0m             'rewards': np.ndarray((200,), dtype=float32, min=1.44, max=2.618, mean=2.265),
[2m[36m(pid=425132)[0m             't': np.ndarray((200,), dtype=int64, min=0.0, max=199.0, mean=99.5),
[2m[36m(pid=425132)[0m             'unroll_id': np.ndarray((200,), dtype=int64, min=0.0, max=0.0, mean=0.0),
[2m[36m(pid=425132)[0m             'value_targets': np.ndarray((200,), dtype=float32, min=6.661, max=79.677, mean=66.176),
[2m[36m(pid=425132)[0m             'vf_preds': np.ndarray((200,), dtype=float32, min=4.478, max=4.478, mean=4.478)},
[2m[36m(pid=425132)[0m   'type': 'SampleBatch'}
[2m[36m(pid=425132)[0m 
[2m[36m(pid=425132)[0m 
[2m[36m(pid=425132)[0m -----------------------
[2m[36m(pid=425132)[0m ring length: 491
[2m[36m(pid=425132)[0m v_max: 2.719840556029452
[2m[36m(pid=425132)[0m -----------------------
[2m[36m(pid=425132)[0m 
[2m[36m(pid=425132)[0m -----------------------
[2m[36m(pid=425132)[0m ring length: 490
[2m[36m(pid=425132)[0m v_max: 2.699845849180192
[2m[36m(pid=425132)[0m -----------------------
[2m[36m(pid=425132)[0m 
[2m[36m(pid=425132)[0m -----------------------
[2m[36m(pid=425132)[0m ring length: 517
[2m[36m(pid=425132)[0m v_max: 3.2396436965475437
[2m[36m(pid=425132)[0m -----------------------
[2m[36m(pid=425132)[0m 
[2m[36m(pid=425132)[0m -----------------------
[2m[36m(pid=425132)[0m ring length: 496
[2m[36m(pid=425132)[0m v_max: 2.819811886031332
[2m[36m(pid=425132)[0m -----------------------
[2m[36m(pid=425132)[0m 
[2m[36m(pid=425132)[0m -----------------------
[2m[36m(pid=425132)[0m ring length: 513
[2m[36m(pid=425132)[0m v_max: 3.1596825160053825
[2m[36m(pid=425132)[0m -----------------------
[2m[36m(pid=424867)[0m 2020-03-30 09:44:11,033	INFO tf_policy.py:355 -- Optimizing variable <tf.Variable 'default_policy/default_model/fc1/kernel:0' shape=(3, 32) dtype=float32_ref>
[2m[36m(pid=424867)[0m 2020-03-30 09:44:11,033	INFO tf_policy.py:355 -- Optimizing variable <tf.Variable 'default_policy/default_model/fc1/bias:0' shape=(32,) dtype=float32_ref>
[2m[36m(pid=424867)[0m 2020-03-30 09:44:11,033	INFO tf_policy.py:355 -- Optimizing variable <tf.Variable 'default_policy/default_model/fc2/kernel:0' shape=(32, 32) dtype=float32_ref>
[2m[36m(pid=424867)[0m 2020-03-30 09:44:11,033	INFO tf_policy.py:355 -- Optimizing variable <tf.Variable 'default_policy/default_model/fc2/bias:0' shape=(32,) dtype=float32_ref>
[2m[36m(pid=424867)[0m 2020-03-30 09:44:11,033	INFO tf_policy.py:355 -- Optimizing variable <tf.Variable 'default_policy/default_model/fc3/kernel:0' shape=(32, 32) dtype=float32_ref>
[2m[36m(pid=424867)[0m 2020-03-30 09:44:11,034	INFO tf_policy.py:355 -- Optimizing variable <tf.Variable 'default_policy/default_model/fc3/bias:0' shape=(32,) dtype=float32_ref>
[2m[36m(pid=424867)[0m 2020-03-30 09:44:11,034	INFO tf_policy.py:355 -- Optimizing variable <tf.Variable 'default_policy/default_model/fc_out/kernel:0' shape=(32, 2) dtype=float32_ref>
[2m[36m(pid=424867)[0m 2020-03-30 09:44:11,034	INFO tf_policy.py:355 -- Optimizing variable <tf.Variable 'default_policy/default_model/fc_out/bias:0' shape=(2,) dtype=float32_ref>
[2m[36m(pid=424867)[0m 2020-03-30 09:44:11,034	INFO tf_policy.py:355 -- Optimizing variable <tf.Variable 'default_policy/value_function/fc1/kernel:0' shape=(3, 32) dtype=float32_ref>
[2m[36m(pid=424867)[0m 2020-03-30 09:44:11,034	INFO tf_policy.py:355 -- Optimizing variable <tf.Variable 'default_policy/value_function/fc1/bias:0' shape=(32,) dtype=float32_ref>
[2m[36m(pid=424867)[0m 2020-03-30 09:44:11,034	INFO tf_policy.py:355 -- Optimizing variable <tf.Variable 'default_policy/value_function/fc2/kernel:0' shape=(32, 32) dtype=float32_ref>
[2m[36m(pid=424867)[0m 2020-03-30 09:44:11,034	INFO tf_policy.py:355 -- Optimizing variable <tf.Variable 'default_policy/value_function/fc2/bias:0' shape=(32,) dtype=float32_ref>
[2m[36m(pid=424867)[0m 2020-03-30 09:44:11,034	INFO tf_policy.py:355 -- Optimizing variable <tf.Variable 'default_policy/value_function/fc3/kernel:0' shape=(32, 32) dtype=float32_ref>
[2m[36m(pid=424867)[0m 2020-03-30 09:44:11,034	INFO tf_policy.py:355 -- Optimizing variable <tf.Variable 'default_policy/value_function/fc3/bias:0' shape=(32,) dtype=float32_ref>
[2m[36m(pid=424867)[0m 2020-03-30 09:44:11,034	INFO tf_policy.py:355 -- Optimizing variable <tf.Variable 'default_policy/value_function/fc_out/kernel:0' shape=(32, 1) dtype=float32_ref>
[2m[36m(pid=424867)[0m 2020-03-30 09:44:11,034	INFO tf_policy.py:355 -- Optimizing variable <tf.Variable 'default_policy/value_function/fc_out/bias:0' shape=(1,) dtype=float32_ref>
[2m[36m(pid=424867)[0m 2020-03-30 09:44:11,036	INFO multi_gpu_impl.py:146 -- Training on concatenated sample batches:
[2m[36m(pid=424867)[0m 
[2m[36m(pid=424867)[0m { 'inputs': [ np.ndarray((10000, 1), dtype=float32, min=-0.42, max=0.41, mean=0.004),
[2m[36m(pid=424867)[0m               np.ndarray((10000,), dtype=float32, min=0.0, max=2.618, mean=2.081),
[2m[36m(pid=424867)[0m               np.ndarray((10000, 3), dtype=float32, min=-0.057, max=0.858, mean=0.28),
[2m[36m(pid=424867)[0m               np.ndarray((10000, 1), dtype=float32, min=-0.42, max=0.41, mean=0.004),
[2m[36m(pid=424867)[0m               np.ndarray((10000,), dtype=float32, min=-3.731, max=1.169, mean=0.0),
[2m[36m(pid=424867)[0m               np.ndarray((10000, 2), dtype=float32, min=-2.173, max=0.005, mean=-1.082),
[2m[36m(pid=424867)[0m               np.ndarray((10000,), dtype=float32, min=1.548, max=79.677, mean=61.042),
[2m[36m(pid=424867)[0m               np.ndarray((10000,), dtype=float32, min=4.477, max=4.478, mean=4.478)],
[2m[36m(pid=424867)[0m   'placeholders': [ <tf.Tensor 'default_policy/action:0' shape=(?, 1) dtype=float32>,
[2m[36m(pid=424867)[0m                     <tf.Tensor 'default_policy/prev_reward:0' shape=(?,) dtype=float32>,
[2m[36m(pid=424867)[0m                     <tf.Tensor 'default_policy/observation:0' shape=(?, 3) dtype=float32>,
[2m[36m(pid=424867)[0m                     <tf.Tensor 'default_policy/actions:0' shape=(?, 1) dtype=float32>,
[2m[36m(pid=424867)[0m                     <tf.Tensor 'default_policy/advantages:0' shape=(?,) dtype=float32>,
[2m[36m(pid=424867)[0m                     <tf.Tensor 'default_policy/behaviour_logits:0' shape=(?, 2) dtype=float32>,
[2m[36m(pid=424867)[0m                     <tf.Tensor 'default_policy/value_targets:0' shape=(?,) dtype=float32>,
[2m[36m(pid=424867)[0m                     <tf.Tensor 'default_policy/vf_preds:0' shape=(?,) dtype=float32>],
[2m[36m(pid=424867)[0m   'state_inputs': []}
[2m[36m(pid=424867)[0m 
[2m[36m(pid=424867)[0m 2020-03-30 09:44:11,036	INFO multi_gpu_impl.py:191 -- Divided 10000 rollout sequences, each of length 1, among 1 devices.
Result for PPO_WaveAttenuationPOEnv-v0_0:
  custom_metrics: {}
  date: 2020-03-30_09-44-11
  done: false
  episode_len_mean: 2000.0
  episode_reward_max: 4485.814457907335
  episode_reward_mean: 4164.573704815861
  episode_reward_min: 3881.2596695791854
  episodes_this_iter: 5
  episodes_total: 255
  experiment_id: ba0edb931dde48dcb020df4b454540a2
  hostname: p0035.ten.osc.edu
  info:
    grad_time_ms: 552.634
    learner:
      default_policy:
        cur_kl_coeff: 1.77635686587003e-16
        cur_lr: 4.999999873689376e-05
        entropy: 0.30906957387924194
        entropy_coeff: 0.0
        kl: 0.0042187524959445
        policy_loss: -0.0016150951851159334
        total_loss: 3446.287109375
        vf_explained_var: 9.655952453613281e-06
        vf_loss: 3446.288330078125
    load_time_ms: 47.174
    num_steps_sampled: 510000
    num_steps_trained: 510000
    sample_time_ms: 109107.732
    update_time_ms: 538.612
  iterations_since_restore: 1
  node_ip: 10.4.1.36
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 2.6886075949367085
    ram_util_percent: 5.396202531645567
  pid: 424867
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 7.335738508287233
    mean_inference_ms: 0.5823782045547277
    mean_processing_ms: 2.6051777623293577
  time_since_restore: 110.28589916229248
  time_this_iter_s: 110.28589916229248
  time_total_s: 5151.048779726028
  timestamp: 1585575851
  timesteps_since_restore: 10000
  timesteps_this_iter: 10000
  timesteps_total: 510000
  training_iteration: 51
  trial_id: fce6b7f4
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2/2 CPUs, 0/0 GPUs
Memory usage on this node: 10.8/201.2 GB
Result logdir: /users/PYS1027/chnrhughes/ray_results/simple_training_example_ring2_v1
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - PPO_WaveAttenuationPOEnv-v0_0:	RUNNING, 1 failures: /users/PYS1027/chnrhughes/ray_results/simple_training_example_ring2_v1/PPO_WaveAttenuationPOEnv-v0_0_2020-03-30_08-14-21aa4md2pi/error_2020-03-30_09-42-11.txt, [2 CPUs, 0 GPUs], [pid=424867], 5151 s, 51 iter, 510000 ts, 4.16e+03 rew

[2m[36m(pid=424867)[0m 2020-03-30 09:44:11,672	WARNING ppo.py:121 -- The magnitude of your environment rewards are more than 416.0x the scale of `vf_clip_param`. This means that it will take more than 416.0 iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.
[2m[36m(pid=425132)[0m 
[2m[36m(pid=425132)[0m -----------------------
[2m[36m(pid=425132)[0m ring length: 506
[2m[36m(pid=425132)[0m v_max: 3.0197423207835943
[2m[36m(pid=425132)[0m -----------------------
[2m[36m(pid=425132)[0m 
[2m[36m(pid=425132)[0m -----------------------
[2m[36m(pid=425132)[0m ring length: 496
[2m[36m(pid=425132)[0m v_max: 2.819811886031332
[2m[36m(pid=425132)[0m -----------------------
[2m[36m(pid=425132)[0m 
[2m[36m(pid=425132)[0m -----------------------
[2m[36m(pid=425132)[0m ring length: 498
[2m[36m(pid=425132)[0m v_max: 2.8597993346145016
[2m[36m(pid=425132)[0m -----------------------
[2m[36m(pid=425132)[0m 
[2m[36m(pid=425132)[0m -----------------------
[2m[36m(pid=425132)[0m ring length: 511
[2m[36m(pid=425132)[0m v_max: 3.1197006223865698
[2m[36m(pid=425132)[0m -----------------------
[2m[36m(pid=425132)[0m 
[2m[36m(pid=425132)[0m -----------------------
[2m[36m(pid=425132)[0m ring length: 491
[2m[36m(pid=425132)[0m v_max: 2.719840556029452
[2m[36m(pid=425132)[0m -----------------------
Result for PPO_WaveAttenuationPOEnv-v0_0:
  custom_metrics: {}
  date: 2020-03-30_09-45-52
  done: false
  episode_len_mean: 2000.0
  episode_reward_max: 4485.814457907335
  episode_reward_mean: 4227.500830131405
  episode_reward_min: 3881.2596695791854
  episodes_this_iter: 5
  episodes_total: 260
  experiment_id: ba0edb931dde48dcb020df4b454540a2
  hostname: p0035.ten.osc.edu
  info:
    grad_time_ms: 392.13
    learner:
      default_policy:
        cur_kl_coeff: 0.10000000149011612
        cur_lr: 4.999999873689376e-05
        entropy: 0.29504045844078064
        entropy_coeff: 0.0
        kl: 0.006457007024437189
        policy_loss: -0.0021388388704508543
        total_loss: 3647.055908203125
        vf_explained_var: 8.344650268554688e-07
        vf_loss: 3647.0576171875
    load_time_ms: 24.495
    num_steps_sampled: 520000
    num_steps_trained: 520000
    sample_time_ms: 104635.462
    update_time_ms: 270.281
  iterations_since_restore: 2
  node_ip: 10.4.1.36
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 2.6223776223776225
    ram_util_percent: 5.399999999999999
  pid: 424867
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 7.212786367209015
    mean_inference_ms: 0.5749192986258226
    mean_processing_ms: 2.605491642024866
  time_since_restore: 210.6900908946991
  time_this_iter_s: 100.40419173240662
  time_total_s: 5251.452971458435
  timestamp: 1585575952
  timesteps_since_restore: 20000
  timesteps_this_iter: 10000
  timesteps_total: 520000
  training_iteration: 52
  trial_id: fce6b7f4
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2/2 CPUs, 0/0 GPUs
Memory usage on this node: 10.8/201.2 GB
Result logdir: /users/PYS1027/chnrhughes/ray_results/simple_training_example_ring2_v1
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - PPO_WaveAttenuationPOEnv-v0_0:	RUNNING, 1 failures: /users/PYS1027/chnrhughes/ray_results/simple_training_example_ring2_v1/PPO_WaveAttenuationPOEnv-v0_0_2020-03-30_08-14-21aa4md2pi/error_2020-03-30_09-42-11.txt, [2 CPUs, 0 GPUs], [pid=424867], 5251 s, 52 iter, 520000 ts, 4.23e+03 rew

[2m[36m(pid=424867)[0m 2020-03-30 09:45:52,087	WARNING ppo.py:121 -- The magnitude of your environment rewards are more than 423.0x the scale of `vf_clip_param`. This means that it will take more than 423.0 iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.
[2m[36m(pid=425132)[0m 
[2m[36m(pid=425132)[0m -----------------------
[2m[36m(pid=425132)[0m ring length: 516
[2m[36m(pid=425132)[0m v_max: 3.2196537366217006
[2m[36m(pid=425132)[0m -----------------------
[2m[36m(pid=425132)[0m 
[2m[36m(pid=425132)[0m -----------------------
[2m[36m(pid=425132)[0m ring length: 497
[2m[36m(pid=425132)[0m v_max: 2.839805690709741
[2m[36m(pid=425132)[0m -----------------------
[2m[36m(pid=425132)[0m 
[2m[36m(pid=425132)[0m -----------------------
[2m[36m(pid=425132)[0m ring length: 516
[2m[36m(pid=425132)[0m v_max: 3.2196537366217006
[2m[36m(pid=425132)[0m -----------------------
[2m[36m(pid=425132)[0m 
[2m[36m(pid=425132)[0m -----------------------
[2m[36m(pid=425132)[0m ring length: 501
[2m[36m(pid=425132)[0m v_max: 2.919779270736568
[2m[36m(pid=425132)[0m -----------------------
[2m[36m(pid=425132)[0m 
[2m[36m(pid=425132)[0m -----------------------
[2m[36m(pid=425132)[0m ring length: 509
[2m[36m(pid=425132)[0m v_max: 3.0797178990784078
[2m[36m(pid=425132)[0m -----------------------
Result for PPO_WaveAttenuationPOEnv-v0_0:
  custom_metrics: {}
  date: 2020-03-30_09-47-33
  done: false
  episode_len_mean: 2000.0
  episode_reward_max: 4485.814457907335
  episode_reward_mean: 4220.297908667406
  episode_reward_min: 3881.2596695791854
  episodes_this_iter: 5
  episodes_total: 265
  experiment_id: ba0edb931dde48dcb020df4b454540a2
  hostname: p0035.ten.osc.edu
  info:
    grad_time_ms: 337.471
    learner:
      default_policy:
        cur_kl_coeff: 0.05000000074505806
        cur_lr: 4.999999873689376e-05
        entropy: 0.2822302281856537
        entropy_coeff: 0.0
        kl: 0.0016057861503213644
        policy_loss: -0.0005291026900522411
        total_loss: 3503.396728515625
        vf_explained_var: 3.933906555175781e-06
        vf_loss: 3503.397216796875
    load_time_ms: 17.066
    num_steps_sampled: 530000
    num_steps_trained: 530000
    sample_time_ms: 103311.48
    update_time_ms: 180.829
  iterations_since_restore: 3
  node_ip: 10.4.1.36
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 2.6433566433566433
    ram_util_percent: 5.399999999999999
  pid: 424867
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 7.14970597368914
    mean_inference_ms: 0.5669743204616339
    mean_processing_ms: 2.6097336063554764
  time_since_restore: 311.5936048030853
  time_this_iter_s: 100.90351390838623
  time_total_s: 5352.356485366821
  timestamp: 1585576053
  timesteps_since_restore: 30000
  timesteps_this_iter: 10000
  timesteps_total: 530000
  training_iteration: 53
  trial_id: fce6b7f4
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2/2 CPUs, 0/0 GPUs
Memory usage on this node: 10.8/201.2 GB
Result logdir: /users/PYS1027/chnrhughes/ray_results/simple_training_example_ring2_v1
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - PPO_WaveAttenuationPOEnv-v0_0:	RUNNING, 1 failures: /users/PYS1027/chnrhughes/ray_results/simple_training_example_ring2_v1/PPO_WaveAttenuationPOEnv-v0_0_2020-03-30_08-14-21aa4md2pi/error_2020-03-30_09-42-11.txt, [2 CPUs, 0 GPUs], [pid=424867], 5352 s, 53 iter, 530000 ts, 4.22e+03 rew

[2m[36m(pid=424867)[0m 2020-03-30 09:47:32,999	WARNING ppo.py:121 -- The magnitude of your environment rewards are more than 422.0x the scale of `vf_clip_param`. This means that it will take more than 422.0 iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.
[2m[36m(pid=425132)[0m 
[2m[36m(pid=425132)[0m -----------------------
[2m[36m(pid=425132)[0m ring length: 510
[2m[36m(pid=425132)[0m v_max: 3.0997093626421153
[2m[36m(pid=425132)[0m -----------------------
[2m[36m(pid=425132)[0m 
[2m[36m(pid=425132)[0m -----------------------
[2m[36m(pid=425132)[0m ring length: 518
[2m[36m(pid=425132)[0m v_max: 3.2596334266284783
[2m[36m(pid=425132)[0m -----------------------
[2m[36m(pid=425132)[0m 
[2m[36m(pid=425132)[0m -----------------------
[2m[36m(pid=425132)[0m ring length: 501
[2m[36m(pid=425132)[0m v_max: 2.919779270736568
[2m[36m(pid=425132)[0m -----------------------
[2m[36m(pid=425132)[0m 
[2m[36m(pid=425132)[0m -----------------------
[2m[36m(pid=425132)[0m ring length: 500
[2m[36m(pid=425132)[0m v_max: 2.8997861277614296
[2m[36m(pid=425132)[0m -----------------------
[2m[36m(pid=425132)[0m 
[2m[36m(pid=425132)[0m -----------------------
[2m[36m(pid=425132)[0m ring length: 514
[2m[36m(pid=425132)[0m v_max: 3.1796731425699525
[2m[36m(pid=425132)[0m -----------------------
Result for PPO_WaveAttenuationPOEnv-v0_0:
  custom_metrics: {}
  date: 2020-03-30_09-49-13
  done: false
  episode_len_mean: 2000.0
  episode_reward_max: 4485.814457907335
  episode_reward_mean: 4225.221416569668
  episode_reward_min: 3881.2596695791854
  episodes_this_iter: 5
  episodes_total: 270
  experiment_id: ba0edb931dde48dcb020df4b454540a2
  hostname: p0035.ten.osc.edu
  info:
    grad_time_ms: 309.059
    learner:
      default_policy:
        cur_kl_coeff: 0.02500000037252903
        cur_lr: 4.999999873689376e-05
        entropy: 0.257178395986557
        entropy_coeff: 0.0
        kl: 0.00303757400251925
        policy_loss: -0.000557173159904778
        total_loss: 3554.8759765625
        vf_explained_var: 3.516674041748047e-06
        vf_loss: 3554.8759765625
    load_time_ms: 13.335
    num_steps_sampled: 540000
    num_steps_trained: 540000
    sample_time_ms: 102615.909
    update_time_ms: 136.197
  iterations_since_restore: 4
  node_ip: 10.4.1.36
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 2.627777777777778
    ram_util_percent: 5.3999999999999995
  pid: 424867
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 7.109808245367755
    mean_inference_ms: 0.5623486127987176
    mean_processing_ms: 2.6111451175677947
  time_since_restore: 412.35789942741394
  time_this_iter_s: 100.76429462432861
  time_total_s: 5453.12077999115
  timestamp: 1585576153
  timesteps_since_restore: 40000
  timesteps_this_iter: 10000
  timesteps_total: 540000
  training_iteration: 54
  trial_id: fce6b7f4
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2/2 CPUs, 0/0 GPUs
Memory usage on this node: 10.8/201.2 GB
Result logdir: /users/PYS1027/chnrhughes/ray_results/simple_training_example_ring2_v1
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - PPO_WaveAttenuationPOEnv-v0_0:	RUNNING, 1 failures: /users/PYS1027/chnrhughes/ray_results/simple_training_example_ring2_v1/PPO_WaveAttenuationPOEnv-v0_0_2020-03-30_08-14-21aa4md2pi/error_2020-03-30_09-42-11.txt, [2 CPUs, 0 GPUs], [pid=424867], 5453 s, 54 iter, 540000 ts, 4.23e+03 rew

[2m[36m(pid=424867)[0m 2020-03-30 09:49:13,774	WARNING ppo.py:121 -- The magnitude of your environment rewards are more than 423.0x the scale of `vf_clip_param`. This means that it will take more than 423.0 iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.
[2m[36m(pid=425132)[0m 
[2m[36m(pid=425132)[0m -----------------------
[2m[36m(pid=425132)[0m ring length: 519
[2m[36m(pid=425132)[0m v_max: 3.2796229229775036
[2m[36m(pid=425132)[0m -----------------------
[2m[36m(pid=425132)[0m 
[2m[36m(pid=425132)[0m -----------------------
[2m[36m(pid=425132)[0m ring length: 518
[2m[36m(pid=425132)[0m v_max: 3.2596334266284783
[2m[36m(pid=425132)[0m -----------------------
[2m[36m(pid=425132)[0m 
[2m[36m(pid=425132)[0m -----------------------
[2m[36m(pid=425132)[0m ring length: 495
[2m[36m(pid=425132)[0m v_max: 2.79981792361692
[2m[36m(pid=425132)[0m -----------------------
[2m[36m(pid=425132)[0m 
[2m[36m(pid=425132)[0m -----------------------
[2m[36m(pid=425132)[0m ring length: 512
[2m[36m(pid=425132)[0m v_max: 3.139691674719026
[2m[36m(pid=425132)[0m -----------------------
[2m[36m(pid=425132)[0m 
[2m[36m(pid=425132)[0m -----------------------
[2m[36m(pid=425132)[0m ring length: 495
[2m[36m(pid=425132)[0m v_max: 2.79981792361692
[2m[36m(pid=425132)[0m -----------------------
Result for PPO_WaveAttenuationPOEnv-v0_0:
  custom_metrics: {}
  date: 2020-03-30_09-50-55
  done: false
  episode_len_mean: 2000.0
  episode_reward_max: 4485.814457907335
  episode_reward_mean: 4233.841210291742
  episode_reward_min: 3881.2596695791854
  episodes_this_iter: 5
  episodes_total: 275
  experiment_id: ba0edb931dde48dcb020df4b454540a2
  hostname: p0035.ten.osc.edu
  info:
    grad_time_ms: 290.889
    learner:
      default_policy:
        cur_kl_coeff: 0.012500000186264515
        cur_lr: 4.999999873689376e-05
        entropy: 0.22518686950206757
        entropy_coeff: 0.0
        kl: 0.0043442812748253345
        policy_loss: -0.0018506220076233149
        total_loss: 3608.335693359375
        vf_explained_var: 2.9206275939941406e-06
        vf_loss: 3608.337646484375
    load_time_ms: 11.104
    num_steps_sampled: 550000
    num_steps_trained: 550000
    sample_time_ms: 102314.932
    update_time_ms: 109.401
  iterations_since_restore: 5
  node_ip: 10.4.1.36
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 2.604861111111111
    ram_util_percent: 5.3999999999999995
  pid: 424867
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 7.0811215042716915
    mean_inference_ms: 0.5612575687704449
    mean_processing_ms: 2.612756974696645
  time_since_restore: 513.6980719566345
  time_this_iter_s: 101.34017252922058
  time_total_s: 5554.4609525203705
  timestamp: 1585576255
  timesteps_since_restore: 50000
  timesteps_this_iter: 10000
  timesteps_total: 550000
  training_iteration: 55
  trial_id: fce6b7f4
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2/2 CPUs, 0/0 GPUs
Memory usage on this node: 10.8/201.2 GB
Result logdir: /users/PYS1027/chnrhughes/ray_results/simple_training_example_ring2_v1
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - PPO_WaveAttenuationPOEnv-v0_0:	RUNNING, 1 failures: /users/PYS1027/chnrhughes/ray_results/simple_training_example_ring2_v1/PPO_WaveAttenuationPOEnv-v0_0_2020-03-30_08-14-21aa4md2pi/error_2020-03-30_09-42-11.txt, [2 CPUs, 0 GPUs], [pid=424867], 5554 s, 55 iter, 550000 ts, 4.23e+03 rew

[2m[36m(pid=424867)[0m 2020-03-30 09:50:55,123	WARNING ppo.py:121 -- The magnitude of your environment rewards are more than 423.0x the scale of `vf_clip_param`. This means that it will take more than 423.0 iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.
[2m[36m(pid=425132)[0m 
[2m[36m(pid=425132)[0m -----------------------
[2m[36m(pid=425132)[0m ring length: 492
[2m[36m(pid=425132)[0m v_max: 2.739835119766572
[2m[36m(pid=425132)[0m -----------------------
[2m[36m(pid=425132)[0m 
[2m[36m(pid=425132)[0m -----------------------
[2m[36m(pid=425132)[0m ring length: 508
[2m[36m(pid=425132)[0m v_max: 3.059726235247059
[2m[36m(pid=425132)[0m -----------------------
[2m[36m(pid=425132)[0m 
[2m[36m(pid=425132)[0m -----------------------
[2m[36m(pid=425132)[0m ring length: 512
[2m[36m(pid=425132)[0m v_max: 3.139691674719026
[2m[36m(pid=425132)[0m -----------------------
[2m[36m(pid=425132)[0m 
[2m[36m(pid=425132)[0m -----------------------
[2m[36m(pid=425132)[0m ring length: 511
[2m[36m(pid=425132)[0m v_max: 3.1197006223865698
[2m[36m(pid=425132)[0m -----------------------
[2m[36m(pid=425132)[0m 
[2m[36m(pid=425132)[0m -----------------------
[2m[36m(pid=425132)[0m ring length: 501
[2m[36m(pid=425132)[0m v_max: 2.919779270736568
[2m[36m(pid=425132)[0m -----------------------
Result for PPO_WaveAttenuationPOEnv-v0_0:
  custom_metrics: {}
  date: 2020-03-30_09-52-35
  done: false
  episode_len_mean: 2000.0
  episode_reward_max: 4485.814457907335
  episode_reward_mean: 4220.055996377204
  episode_reward_min: 3881.2596695791854
  episodes_this_iter: 5
  episodes_total: 280
  experiment_id: ba0edb931dde48dcb020df4b454540a2
  hostname: p0035.ten.osc.edu
  info:
    grad_time_ms: 281.387
    learner:
      default_policy:
        cur_kl_coeff: 0.0062500000931322575
        cur_lr: 4.999999873689376e-05
        entropy: 0.18848617374897003
        entropy_coeff: 0.0
        kl: 0.006166982464492321
        policy_loss: -0.0018592182314023376
        total_loss: 3409.09765625
        vf_explained_var: 6.9141387939453125e-06
        vf_loss: 3409.09912109375
    load_time_ms: 9.583
    num_steps_sampled: 560000
    num_steps_trained: 560000
    sample_time_ms: 102009.411
    update_time_ms: 91.512
  iterations_since_restore: 6
  node_ip: 10.4.1.36
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 2.6538461538461537
    ram_util_percent: 5.399999999999999
  pid: 424867
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 7.059421364255404
    mean_inference_ms: 0.5600116299175274
    mean_processing_ms: 2.6139265635733566
  time_since_restore: 614.4236395359039
  time_this_iter_s: 100.72556757926941
  time_total_s: 5655.18652009964
  timestamp: 1585576355
  timesteps_since_restore: 60000
  timesteps_this_iter: 10000
  timesteps_total: 560000
  training_iteration: 56
  trial_id: fce6b7f4
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2/2 CPUs, 0/0 GPUs
Memory usage on this node: 10.8/201.2 GB
Result logdir: /users/PYS1027/chnrhughes/ray_results/simple_training_example_ring2_v1
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - PPO_WaveAttenuationPOEnv-v0_0:	RUNNING, 1 failures: /users/PYS1027/chnrhughes/ray_results/simple_training_example_ring2_v1/PPO_WaveAttenuationPOEnv-v0_0_2020-03-30_08-14-21aa4md2pi/error_2020-03-30_09-42-11.txt, [2 CPUs, 0 GPUs], [pid=424867], 5655 s, 56 iter, 560000 ts, 4.22e+03 rew

[2m[36m(pid=424867)[0m 2020-03-30 09:52:35,871	WARNING ppo.py:121 -- The magnitude of your environment rewards are more than 422.0x the scale of `vf_clip_param`. This means that it will take more than 422.0 iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.
[2m[36m(pid=425132)[0m 
[2m[36m(pid=425132)[0m -----------------------
[2m[36m(pid=425132)[0m ring length: 517
[2m[36m(pid=425132)[0m v_max: 3.2396436965475437
[2m[36m(pid=425132)[0m -----------------------
[2m[36m(pid=425132)[0m 
[2m[36m(pid=425132)[0m -----------------------
[2m[36m(pid=425132)[0m ring length: 501
[2m[36m(pid=425132)[0m v_max: 2.919779270736568
[2m[36m(pid=425132)[0m -----------------------
[2m[36m(pid=425132)[0m 
[2m[36m(pid=425132)[0m -----------------------
[2m[36m(pid=425132)[0m ring length: 493
[2m[36m(pid=425132)[0m v_max: 2.759829537541262
[2m[36m(pid=425132)[0m -----------------------
[2m[36m(pid=425132)[0m 
[2m[36m(pid=425132)[0m -----------------------
[2m[36m(pid=425132)[0m ring length: 505
[2m[36m(pid=425132)[0m v_max: 2.999750077051092
[2m[36m(pid=425132)[0m -----------------------
[2m[36m(pid=425132)[0m 
[2m[36m(pid=425132)[0m -----------------------
[2m[36m(pid=425132)[0m ring length: 497
[2m[36m(pid=425132)[0m v_max: 2.839805690709741
[2m[36m(pid=425132)[0m -----------------------
Result for PPO_WaveAttenuationPOEnv-v0_0:
  custom_metrics: {}
  date: 2020-03-30_09-54-17
  done: false
  episode_len_mean: 2000.0
  episode_reward_max: 4499.016862293675
  episode_reward_mean: 4224.496428529119
  episode_reward_min: 3881.2596695791854
  episodes_this_iter: 5
  episodes_total: 285
  experiment_id: ba0edb931dde48dcb020df4b454540a2
  hostname: p0035.ten.osc.edu
  info:
    grad_time_ms: 273.714
    learner:
      default_policy:
        cur_kl_coeff: 0.0031250000465661287
        cur_lr: 4.999999873689376e-05
        entropy: 0.16302913427352905
        entropy_coeff: 0.0
        kl: 0.002432701177895069
        policy_loss: -0.0006396278622560203
        total_loss: 3581.947998046875
        vf_explained_var: 4.708766937255859e-06
        vf_loss: 3581.947998046875
    load_time_ms: 8.577
    num_steps_sampled: 570000
    num_steps_trained: 570000
    sample_time_ms: 101849.943
    update_time_ms: 78.721
  iterations_since_restore: 7
  node_ip: 10.4.1.36
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 2.605555555555556
    ram_util_percent: 5.3999999999999995
  pid: 424867
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 7.041990482584337
    mean_inference_ms: 0.5600060265684758
    mean_processing_ms: 2.614815677739982
  time_since_restore: 715.5556817054749
  time_this_iter_s: 101.13204216957092
  time_total_s: 5756.318562269211
  timestamp: 1585576457
  timesteps_since_restore: 70000
  timesteps_this_iter: 10000
  timesteps_total: 570000
  training_iteration: 57
  trial_id: fce6b7f4
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2/2 CPUs, 0/0 GPUs
Memory usage on this node: 10.8/201.2 GB
Result logdir: /users/PYS1027/chnrhughes/ray_results/simple_training_example_ring2_v1
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - PPO_WaveAttenuationPOEnv-v0_0:	RUNNING, 1 failures: /users/PYS1027/chnrhughes/ray_results/simple_training_example_ring2_v1/PPO_WaveAttenuationPOEnv-v0_0_2020-03-30_08-14-21aa4md2pi/error_2020-03-30_09-42-11.txt, [2 CPUs, 0 GPUs], [pid=424867], 5756 s, 57 iter, 570000 ts, 4.22e+03 rew

[2m[36m(pid=424867)[0m 2020-03-30 09:54:17,013	WARNING ppo.py:121 -- The magnitude of your environment rewards are more than 422.0x the scale of `vf_clip_param`. This means that it will take more than 422.0 iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.
[2m[36m(pid=425132)[0m 
[2m[36m(pid=425132)[0m -----------------------
[2m[36m(pid=425132)[0m ring length: 490
[2m[36m(pid=425132)[0m v_max: 2.699845849180192
[2m[36m(pid=425132)[0m -----------------------
[2m[36m(pid=425132)[0m 
[2m[36m(pid=425132)[0m -----------------------
[2m[36m(pid=425132)[0m ring length: 513
[2m[36m(pid=425132)[0m v_max: 3.1596825160053825
[2m[36m(pid=425132)[0m -----------------------
[2m[36m(pid=425132)[0m 
[2m[36m(pid=425132)[0m -----------------------
[2m[36m(pid=425132)[0m ring length: 503
[2m[36m(pid=425132)[0m v_max: 2.9597650335315784
[2m[36m(pid=425132)[0m -----------------------
[2m[36m(pid=425132)[0m 
[2m[36m(pid=425132)[0m -----------------------
[2m[36m(pid=425132)[0m ring length: 499
[2m[36m(pid=425132)[0m v_max: 2.8797928146697993
[2m[36m(pid=425132)[0m -----------------------
[2m[36m(pid=425132)[0m 
[2m[36m(pid=425132)[0m -----------------------
[2m[36m(pid=425132)[0m ring length: 508
[2m[36m(pid=425132)[0m v_max: 3.059726235247059
[2m[36m(pid=425132)[0m -----------------------
Result for PPO_WaveAttenuationPOEnv-v0_0:
  custom_metrics: {}
  date: 2020-03-30_09-55-58
  done: false
  episode_len_mean: 2000.0
  episode_reward_max: 4499.016862293675
  episode_reward_mean: 4225.182715699004
  episode_reward_min: 3881.2596695791854
  episodes_this_iter: 5
  episodes_total: 290
  experiment_id: ba0edb931dde48dcb020df4b454540a2
  hostname: p0035.ten.osc.edu
  info:
    grad_time_ms: 267.394
    learner:
      default_policy:
        cur_kl_coeff: 0.0015625000232830644
        cur_lr: 4.999999873689376e-05
        entropy: 0.14131435751914978
        entropy_coeff: 0.0
        kl: 0.004804479423910379
        policy_loss: -0.0013529567513614893
        total_loss: 3536.115966796875
        vf_explained_var: 3.6954879760742188e-06
        vf_loss: 3536.11669921875
    load_time_ms: 7.778
    num_steps_sampled: 580000
    num_steps_trained: 580000
    sample_time_ms: 101772.757
    update_time_ms: 69.142
  iterations_since_restore: 8
  node_ip: 10.4.1.36
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 2.6289655172413795
    ram_util_percent: 5.3999999999999995
  pid: 424867
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 7.027928908190103
    mean_inference_ms: 0.5608192505474993
    mean_processing_ms: 2.615532530919743
  time_since_restore: 817.0219540596008
  time_this_iter_s: 101.46627235412598
  time_total_s: 5857.784834623337
  timestamp: 1585576558
  timesteps_since_restore: 80000
  timesteps_this_iter: 10000
  timesteps_total: 580000
  training_iteration: 58
  trial_id: fce6b7f4
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2/2 CPUs, 0/0 GPUs
Memory usage on this node: 10.8/201.2 GB
Result logdir: /users/PYS1027/chnrhughes/ray_results/simple_training_example_ring2_v1
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - PPO_WaveAttenuationPOEnv-v0_0:	RUNNING, 1 failures: /users/PYS1027/chnrhughes/ray_results/simple_training_example_ring2_v1/PPO_WaveAttenuationPOEnv-v0_0_2020-03-30_08-14-21aa4md2pi/error_2020-03-30_09-42-11.txt, [2 CPUs, 0 GPUs], [pid=424867], 5857 s, 58 iter, 580000 ts, 4.23e+03 rew

[2m[36m(pid=424867)[0m 2020-03-30 09:55:58,490	WARNING ppo.py:121 -- The magnitude of your environment rewards are more than 423.0x the scale of `vf_clip_param`. This means that it will take more than 423.0 iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.
[2m[36m(pid=425132)[0m 
[2m[36m(pid=425132)[0m -----------------------
[2m[36m(pid=425132)[0m ring length: 520
[2m[36m(pid=425132)[0m v_max: 3.2996121816646764
[2m[36m(pid=425132)[0m -----------------------
[2m[36m(pid=425132)[0m 
[2m[36m(pid=425132)[0m -----------------------
[2m[36m(pid=425132)[0m ring length: 503
[2m[36m(pid=425132)[0m v_max: 2.9597650335315784
[2m[36m(pid=425132)[0m -----------------------
[2m[36m(pid=425132)[0m 
[2m[36m(pid=425132)[0m -----------------------
[2m[36m(pid=425132)[0m ring length: 511
[2m[36m(pid=425132)[0m v_max: 3.1197006223865698
[2m[36m(pid=425132)[0m -----------------------
[2m[36m(pid=425132)[0m 
[2m[36m(pid=425132)[0m -----------------------
[2m[36m(pid=425132)[0m ring length: 518
[2m[36m(pid=425132)[0m v_max: 3.2596334266284783
[2m[36m(pid=425132)[0m -----------------------
[2m[36m(pid=425132)[0m 
[2m[36m(pid=425132)[0m -----------------------
[2m[36m(pid=425132)[0m ring length: 502
[2m[36m(pid=425132)[0m v_max: 2.9397722404035362
[2m[36m(pid=425132)[0m -----------------------
Result for PPO_WaveAttenuationPOEnv-v0_0:
  custom_metrics: {}
  date: 2020-03-30_09-57-39
  done: false
  episode_len_mean: 2000.0
  episode_reward_max: 4575.695196753363
  episode_reward_mean: 4253.478739837717
  episode_reward_min: 3881.2596695791854
  episodes_this_iter: 5
  episodes_total: 295
  experiment_id: ba0edb931dde48dcb020df4b454540a2
  hostname: p0035.ten.osc.edu
  info:
    grad_time_ms: 260.719
    learner:
      default_policy:
        cur_kl_coeff: 0.0007812500116415322
        cur_lr: 4.999999873689376e-05
        entropy: 0.13630671799182892
        entropy_coeff: 0.0
        kl: 0.005046716425567865
        policy_loss: -0.0005228336085565388
        total_loss: 3969.1328125
        vf_explained_var: 2.980232238769531e-07
        vf_loss: 3969.1328125
    load_time_ms: 7.168
    num_steps_sampled: 590000
    num_steps_trained: 590000
    sample_time_ms: 101643.848
    update_time_ms: 61.698
  iterations_since_restore: 9
  node_ip: 10.4.1.36
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 2.6132867132867137
    ram_util_percent: 5.399999999999999
  pid: 424867
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 7.016342444086353
    mean_inference_ms: 0.561274368434565
    mean_processing_ms: 2.6160687526502278
  time_since_restore: 917.8518712520599
  time_this_iter_s: 100.8299171924591
  time_total_s: 5958.614751815796
  timestamp: 1585576659
  timesteps_since_restore: 90000
  timesteps_this_iter: 10000
  timesteps_total: 590000
  training_iteration: 59
  trial_id: fce6b7f4
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2/2 CPUs, 0/0 GPUs
Memory usage on this node: 10.8/201.2 GB
Result logdir: /users/PYS1027/chnrhughes/ray_results/simple_training_example_ring2_v1
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - PPO_WaveAttenuationPOEnv-v0_0:	RUNNING, 1 failures: /users/PYS1027/chnrhughes/ray_results/simple_training_example_ring2_v1/PPO_WaveAttenuationPOEnv-v0_0_2020-03-30_08-14-21aa4md2pi/error_2020-03-30_09-42-11.txt, [2 CPUs, 0 GPUs], [pid=424867], 5958 s, 59 iter, 590000 ts, 4.25e+03 rew

[2m[36m(pid=424867)[0m 2020-03-30 09:57:39,330	WARNING ppo.py:121 -- The magnitude of your environment rewards are more than 425.0x the scale of `vf_clip_param`. This means that it will take more than 425.0 iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.
[2m[36m(pid=425132)[0m 
[2m[36m(pid=425132)[0m -----------------------
[2m[36m(pid=425132)[0m ring length: 492
[2m[36m(pid=425132)[0m v_max: 2.739835119766572
[2m[36m(pid=425132)[0m -----------------------
[2m[36m(pid=425132)[0m 
[2m[36m(pid=425132)[0m -----------------------
[2m[36m(pid=425132)[0m ring length: 514
[2m[36m(pid=425132)[0m v_max: 3.1796731425699525
[2m[36m(pid=425132)[0m -----------------------
[2m[36m(pid=425132)[0m 
[2m[36m(pid=425132)[0m -----------------------
[2m[36m(pid=425132)[0m ring length: 497
[2m[36m(pid=425132)[0m v_max: 2.839805690709741
[2m[36m(pid=425132)[0m -----------------------
[2m[36m(pid=425132)[0m 
[2m[36m(pid=425132)[0m -----------------------
[2m[36m(pid=425132)[0m ring length: 503
[2m[36m(pid=425132)[0m v_max: 2.9597650335315784
[2m[36m(pid=425132)[0m -----------------------
[2m[36m(pid=425132)[0m 
[2m[36m(pid=425132)[0m -----------------------
[2m[36m(pid=425132)[0m ring length: 515
[2m[36m(pid=425132)[0m v_max: 3.199663550695237
[2m[36m(pid=425132)[0m -----------------------
Result for PPO_WaveAttenuationPOEnv-v0_0:
  custom_metrics: {}
  date: 2020-03-30_09-59-19
  done: false
  episode_len_mean: 2000.0
  episode_reward_max: 4583.239803922101
  episode_reward_mean: 4271.135332789481
  episode_reward_min: 3881.2596695791854
  episodes_this_iter: 5
  episodes_total: 300
  experiment_id: ba0edb931dde48dcb020df4b454540a2
  hostname: p0035.ten.osc.edu
  info:
    grad_time_ms: 255.694
    learner:
      default_policy:
        cur_kl_coeff: 0.0003906250058207661
        cur_lr: 4.999999873689376e-05
        entropy: 0.13432182371616364
        entropy_coeff: 0.0
        kl: 0.00478622829541564
        policy_loss: -0.00019122868252452463
        total_loss: 3882.149169921875
        vf_explained_var: 3.5762786865234375e-07
        vf_loss: 3882.149658203125
    load_time_ms: 6.646
    num_steps_sampled: 600000
    num_steps_trained: 600000
    sample_time_ms: 101503.758
    update_time_ms: 55.744
  iterations_since_restore: 10
  node_ip: 10.4.1.36
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 2.63986013986014
    ram_util_percent: 5.399999999999999
  pid: 424867
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 7.006683809323403
    mean_inference_ms: 0.561031548449896
    mean_processing_ms: 2.616504404617327
  time_since_restore: 1018.3154761791229
  time_this_iter_s: 100.46360492706299
  time_total_s: 6059.078356742859
  timestamp: 1585576759
  timesteps_since_restore: 100000
  timesteps_this_iter: 10000
  timesteps_total: 600000
  training_iteration: 60
  trial_id: fce6b7f4
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2/2 CPUs, 0/0 GPUs
Memory usage on this node: 10.8/201.2 GB
Result logdir: /users/PYS1027/chnrhughes/ray_results/simple_training_example_ring2_v1
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - PPO_WaveAttenuationPOEnv-v0_0:	RUNNING, 1 failures: /users/PYS1027/chnrhughes/ray_results/simple_training_example_ring2_v1/PPO_WaveAttenuationPOEnv-v0_0_2020-03-30_08-14-21aa4md2pi/error_2020-03-30_09-42-11.txt, [2 CPUs, 0 GPUs], [pid=424867], 6059 s, 60 iter, 600000 ts, 4.27e+03 rew

[2m[36m(pid=424867)[0m 2020-03-30 09:59:19,803	WARNING ppo.py:121 -- The magnitude of your environment rewards are more than 427.0x the scale of `vf_clip_param`. This means that it will take more than 427.0 iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.
[2m[36m(pid=425132)[0m 
[2m[36m(pid=425132)[0m -----------------------
[2m[36m(pid=425132)[0m ring length: 493
[2m[36m(pid=425132)[0m v_max: 2.759829537541262
[2m[36m(pid=425132)[0m -----------------------
[2m[36m(pid=425132)[0m 
[2m[36m(pid=425132)[0m -----------------------
[2m[36m(pid=425132)[0m ring length: 513
[2m[36m(pid=425132)[0m v_max: 3.1596825160053825
[2m[36m(pid=425132)[0m -----------------------
[2m[36m(pid=425132)[0m 
[2m[36m(pid=425132)[0m -----------------------
[2m[36m(pid=425132)[0m ring length: 495
[2m[36m(pid=425132)[0m v_max: 2.79981792361692
[2m[36m(pid=425132)[0m -----------------------
[2m[36m(pid=425132)[0m 
[2m[36m(pid=425132)[0m -----------------------
[2m[36m(pid=425132)[0m ring length: 507
[2m[36m(pid=425132)[0m v_max: 3.0397343746587766
[2m[36m(pid=425132)[0m -----------------------
[2m[36m(pid=425132)[0m 
[2m[36m(pid=425132)[0m -----------------------
[2m[36m(pid=425132)[0m ring length: 490
[2m[36m(pid=425132)[0m v_max: 2.699845849180192
[2m[36m(pid=425132)[0m -----------------------
Result for PPO_WaveAttenuationPOEnv-v0_0:
  custom_metrics: {}
  date: 2020-03-30_10-00-59
  done: false
  episode_len_mean: 2000.0
  episode_reward_max: 4601.683842037137
  episode_reward_mean: 4285.165878303248
  episode_reward_min: 3881.2596695791854
  episodes_this_iter: 5
  episodes_total: 305
  experiment_id: ba0edb931dde48dcb020df4b454540a2
  hostname: p0035.ten.osc.edu
  info:
    grad_time_ms: 221.264
    learner:
      default_policy:
        cur_kl_coeff: 0.00019531250291038305
        cur_lr: 4.999999873689376e-05
        entropy: 0.12945544719696045
        entropy_coeff: 0.0
        kl: 0.003973655868321657
        policy_loss: -0.00012602729839272797
        total_loss: 3875.494384765625
        vf_explained_var: 5.364418029785156e-07
        vf_loss: 3875.494873046875
    load_time_ms: 2.126
    num_steps_sampled: 610000
    num_steps_trained: 610000
    sample_time_ms: 100579.149
    update_time_ms: 2.076
  iterations_since_restore: 11
  node_ip: 10.4.1.36
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 2.6237762237762237
    ram_util_percent: 5.399999999999999
  pid: 424867
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 6.9981753980605035
    mean_inference_ms: 0.5605073652220374
    mean_processing_ms: 2.6167324200936712
  time_since_restore: 1118.395699262619
  time_this_iter_s: 100.0802230834961
  time_total_s: 6159.158579826355
  timestamp: 1585576859
  timesteps_since_restore: 110000
  timesteps_this_iter: 10000
  timesteps_total: 610000
  training_iteration: 61
  trial_id: fce6b7f4
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2/2 CPUs, 0/0 GPUs
Memory usage on this node: 10.8/201.2 GB
Result logdir: /users/PYS1027/chnrhughes/ray_results/simple_training_example_ring2_v1
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - PPO_WaveAttenuationPOEnv-v0_0:	RUNNING, 1 failures: /users/PYS1027/chnrhughes/ray_results/simple_training_example_ring2_v1/PPO_WaveAttenuationPOEnv-v0_0_2020-03-30_08-14-21aa4md2pi/error_2020-03-30_09-42-11.txt, [2 CPUs, 0 GPUs], [pid=424867], 6159 s, 61 iter, 610000 ts, 4.29e+03 rew

[2m[36m(pid=424867)[0m 2020-03-30 10:00:59,905	WARNING ppo.py:121 -- The magnitude of your environment rewards are more than 429.0x the scale of `vf_clip_param`. This means that it will take more than 429.0 iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.
[2m[36m(pid=425132)[0m 
[2m[36m(pid=425132)[0m -----------------------
[2m[36m(pid=425132)[0m ring length: 512
[2m[36m(pid=425132)[0m v_max: 3.139691674719026
[2m[36m(pid=425132)[0m -----------------------
[2m[36m(pid=425132)[0m 
[2m[36m(pid=425132)[0m -----------------------
[2m[36m(pid=425132)[0m ring length: 520
[2m[36m(pid=425132)[0m v_max: 3.2996121816646764
[2m[36m(pid=425132)[0m -----------------------
[2m[36m(pid=425132)[0m 
[2m[36m(pid=425132)[0m -----------------------
[2m[36m(pid=425132)[0m ring length: 507
[2m[36m(pid=425132)[0m v_max: 3.0397343746587766
[2m[36m(pid=425132)[0m -----------------------
[2m[36m(pid=425132)[0m 
[2m[36m(pid=425132)[0m -----------------------
[2m[36m(pid=425132)[0m ring length: 500
[2m[36m(pid=425132)[0m v_max: 2.8997861277614296
[2m[36m(pid=425132)[0m -----------------------
[2m[36m(pid=425132)[0m 
[2m[36m(pid=425132)[0m -----------------------
[2m[36m(pid=425132)[0m ring length: 511
[2m[36m(pid=425132)[0m v_max: 3.1197006223865698
[2m[36m(pid=425132)[0m -----------------------
Result for PPO_WaveAttenuationPOEnv-v0_0:
  custom_metrics: {}
  date: 2020-03-30_10-02-40
  done: false
  episode_len_mean: 2000.0
  episode_reward_max: 4601.683842037137
  episode_reward_mean: 4289.4854464220425
  episode_reward_min: 3881.2596695791854
  episodes_this_iter: 5
  episodes_total: 310
  experiment_id: ba0edb931dde48dcb020df4b454540a2
  hostname: p0035.ten.osc.edu
  info:
    grad_time_ms: 219.214
    learner:
      default_policy:
        cur_kl_coeff: 9.765625145519152e-05
        cur_lr: 4.999999873689376e-05
        entropy: 0.12520134449005127
        entropy_coeff: 0.0
        kl: 0.008667762391269207
        policy_loss: -0.0024237860925495625
        total_loss: 3721.848388671875
        vf_explained_var: 2.1457672119140625e-06
        vf_loss: 3721.850341796875
    load_time_ms: 2.128
    num_steps_sampled: 620000
    num_steps_trained: 620000
    sample_time_ms: 100607.876
    update_time_ms: 2.094
  iterations_since_restore: 12
  node_ip: 10.4.1.36
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 2.6188811188811187
    ram_util_percent: 5.399999999999999
  pid: 424867
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 6.99069616289366
    mean_inference_ms: 0.5600216960509915
    mean_processing_ms: 2.616942232298561
  time_since_restore: 1219.0673968791962
  time_this_iter_s: 100.67169761657715
  time_total_s: 6259.830277442932
  timestamp: 1585576960
  timesteps_since_restore: 120000
  timesteps_this_iter: 10000
  timesteps_total: 620000
  training_iteration: 62
  trial_id: fce6b7f4
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2/2 CPUs, 0/0 GPUs
Memory usage on this node: 10.9/201.2 GB
Result logdir: /users/PYS1027/chnrhughes/ray_results/simple_training_example_ring2_v1
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - PPO_WaveAttenuationPOEnv-v0_0:	RUNNING, 1 failures: /users/PYS1027/chnrhughes/ray_results/simple_training_example_ring2_v1/PPO_WaveAttenuationPOEnv-v0_0_2020-03-30_08-14-21aa4md2pi/error_2020-03-30_09-42-11.txt, [2 CPUs, 0 GPUs], [pid=424867], 6259 s, 62 iter, 620000 ts, 4.29e+03 rew

[2m[36m(pid=424867)[0m 2020-03-30 10:02:40,587	WARNING ppo.py:121 -- The magnitude of your environment rewards are more than 429.0x the scale of `vf_clip_param`. This means that it will take more than 429.0 iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.
[2m[36m(pid=425132)[0m 
[2m[36m(pid=425132)[0m -----------------------
[2m[36m(pid=425132)[0m ring length: 494
[2m[36m(pid=425132)[0m v_max: 2.7798238064662253
[2m[36m(pid=425132)[0m -----------------------
[2m[36m(pid=425132)[0m 
[2m[36m(pid=425132)[0m -----------------------
[2m[36m(pid=425132)[0m ring length: 494
[2m[36m(pid=425132)[0m v_max: 2.7798238064662253
[2m[36m(pid=425132)[0m -----------------------
[2m[36m(pid=425132)[0m 
[2m[36m(pid=425132)[0m -----------------------
[2m[36m(pid=425132)[0m ring length: 511
[2m[36m(pid=425132)[0m v_max: 3.1197006223865698
[2m[36m(pid=425132)[0m -----------------------
[2m[36m(pid=425132)[0m 
[2m[36m(pid=425132)[0m -----------------------
[2m[36m(pid=425132)[0m ring length: 512
[2m[36m(pid=425132)[0m v_max: 3.139691674719026
[2m[36m(pid=425132)[0m -----------------------
[2m[36m(pid=425132)[0m 
[2m[36m(pid=425132)[0m -----------------------
[2m[36m(pid=425132)[0m ring length: 518
[2m[36m(pid=425132)[0m v_max: 3.2596334266284783
[2m[36m(pid=425132)[0m -----------------------
Result for PPO_WaveAttenuationPOEnv-v0_0:
  custom_metrics: {}
  date: 2020-03-30_10-04-21
  done: false
  episode_len_mean: 2000.0
  episode_reward_max: 4601.683842037137
  episode_reward_mean: 4282.550572854428
  episode_reward_min: 3881.2596695791854
  episodes_this_iter: 5
  episodes_total: 315
  experiment_id: ba0edb931dde48dcb020df4b454540a2
  hostname: p0035.ten.osc.edu
  info:
    grad_time_ms: 217.399
    learner:
      default_policy:
        cur_kl_coeff: 4.882812572759576e-05
        cur_lr: 4.999999873689376e-05
        entropy: 0.09417831152677536
        entropy_coeff: 0.0
        kl: 0.004355414770543575
        policy_loss: -0.0015534195117652416
        total_loss: 3488.925537109375
        vf_explained_var: 5.364418029785156e-06
        vf_loss: 3488.9267578125
    load_time_ms: 2.205
    num_steps_sampled: 630000
    num_steps_trained: 630000
    sample_time_ms: 100625.427
    update_time_ms: 2.094
  iterations_since_restore: 13
  node_ip: 10.4.1.36
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 2.6118055555555557
    ram_util_percent: 5.3999999999999995
  pid: 424867
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 6.984210137431394
    mean_inference_ms: 0.5595783661684256
    mean_processing_ms: 2.61722603813206
  time_since_restore: 1320.1279549598694
  time_this_iter_s: 101.06055808067322
  time_total_s: 6360.890835523605
  timestamp: 1585577061
  timesteps_since_restore: 130000
  timesteps_this_iter: 10000
  timesteps_total: 630000
  training_iteration: 63
  trial_id: fce6b7f4
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2/2 CPUs, 0/0 GPUs
Memory usage on this node: 10.8/201.2 GB
Result logdir: /users/PYS1027/chnrhughes/ray_results/simple_training_example_ring2_v1
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - PPO_WaveAttenuationPOEnv-v0_0:	RUNNING, 1 failures: /users/PYS1027/chnrhughes/ray_results/simple_training_example_ring2_v1/PPO_WaveAttenuationPOEnv-v0_0_2020-03-30_08-14-21aa4md2pi/error_2020-03-30_09-42-11.txt, [2 CPUs, 0 GPUs], [pid=424867], 6360 s, 63 iter, 630000 ts, 4.28e+03 rew

[2m[36m(pid=424867)[0m 2020-03-30 10:04:21,657	WARNING ppo.py:121 -- The magnitude of your environment rewards are more than 428.0x the scale of `vf_clip_param`. This means that it will take more than 428.0 iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.
[2m[36m(pid=425132)[0m 
[2m[36m(pid=425132)[0m -----------------------
[2m[36m(pid=425132)[0m ring length: 517
[2m[36m(pid=425132)[0m v_max: 3.2396436965475437
[2m[36m(pid=425132)[0m -----------------------
[2m[36m(pid=425132)[0m 
[2m[36m(pid=425132)[0m -----------------------
[2m[36m(pid=425132)[0m ring length: 498
[2m[36m(pid=425132)[0m v_max: 2.8597993346145016
[2m[36m(pid=425132)[0m -----------------------
[2m[36m(pid=425132)[0m 
[2m[36m(pid=425132)[0m -----------------------
[2m[36m(pid=425132)[0m ring length: 501
[2m[36m(pid=425132)[0m v_max: 2.919779270736568
[2m[36m(pid=425132)[0m -----------------------
[2m[36m(pid=425132)[0m 
[2m[36m(pid=425132)[0m -----------------------
[2m[36m(pid=425132)[0m ring length: 492
[2m[36m(pid=425132)[0m v_max: 2.739835119766572
[2m[36m(pid=425132)[0m -----------------------
[2m[36m(pid=425132)[0m 
[2m[36m(pid=425132)[0m -----------------------
[2m[36m(pid=425132)[0m ring length: 495
[2m[36m(pid=425132)[0m v_max: 2.79981792361692
[2m[36m(pid=425132)[0m -----------------------
Result for PPO_WaveAttenuationPOEnv-v0_0:
  custom_metrics: {}
  date: 2020-03-30_10-06-03
  done: false
  episode_len_mean: 2000.0
  episode_reward_max: 4601.683842037137
  episode_reward_mean: 4276.374493305457
  episode_reward_min: 3881.2596695791854
  episodes_this_iter: 5
  episodes_total: 320
  experiment_id: ba0edb931dde48dcb020df4b454540a2
  hostname: p0035.ten.osc.edu
  info:
    grad_time_ms: 216.24
    learner:
      default_policy:
        cur_kl_coeff: 2.441406286379788e-05
        cur_lr: 4.999999873689376e-05
        entropy: 0.11108100414276123
        entropy_coeff: 0.0
        kl: 0.0012857993133366108
        policy_loss: -0.0003778755199164152
        total_loss: 3485.4794921875
        vf_explained_var: 5.841255187988281e-06
        vf_loss: 3485.48046875
    load_time_ms: 2.18
    num_steps_sampled: 640000
    num_steps_trained: 640000
    sample_time_ms: 100748.748
    update_time_ms: 2.079
  iterations_since_restore: 14
  node_ip: 10.4.1.36
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 2.6489655172413795
    ram_util_percent: 5.3999999999999995
  pid: 424867
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 6.978863597726255
    mean_inference_ms: 0.5592512600175334
    mean_processing_ms: 2.617602819253123
  time_since_restore: 1422.1129553318024
  time_this_iter_s: 101.98500037193298
  time_total_s: 6462.875835895538
  timestamp: 1585577163
  timesteps_since_restore: 140000
  timesteps_this_iter: 10000
  timesteps_total: 640000
  training_iteration: 64
  trial_id: fce6b7f4
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2/2 CPUs, 0/0 GPUs
Memory usage on this node: 10.8/201.2 GB
Result logdir: /users/PYS1027/chnrhughes/ray_results/simple_training_example_ring2_v1
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - PPO_WaveAttenuationPOEnv-v0_0:	RUNNING, 1 failures: /users/PYS1027/chnrhughes/ray_results/simple_training_example_ring2_v1/PPO_WaveAttenuationPOEnv-v0_0_2020-03-30_08-14-21aa4md2pi/error_2020-03-30_09-42-11.txt, [2 CPUs, 0 GPUs], [pid=424867], 6462 s, 64 iter, 640000 ts, 4.28e+03 rew

[2m[36m(pid=424867)[0m 2020-03-30 10:06:03,652	WARNING ppo.py:121 -- The magnitude of your environment rewards are more than 428.0x the scale of `vf_clip_param`. This means that it will take more than 428.0 iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.
[2m[36m(pid=425132)[0m 
[2m[36m(pid=425132)[0m -----------------------
[2m[36m(pid=425132)[0m ring length: 491
[2m[36m(pid=425132)[0m v_max: 2.719840556029452
[2m[36m(pid=425132)[0m -----------------------
[2m[36m(pid=425132)[0m 
[2m[36m(pid=425132)[0m -----------------------
[2m[36m(pid=425132)[0m ring length: 519
[2m[36m(pid=425132)[0m v_max: 3.2796229229775036
[2m[36m(pid=425132)[0m -----------------------
[2m[36m(pid=425132)[0m 
[2m[36m(pid=425132)[0m -----------------------
[2m[36m(pid=425132)[0m ring length: 504
[2m[36m(pid=425132)[0m v_max: 2.979757646850631
[2m[36m(pid=425132)[0m -----------------------
[2m[36m(pid=425132)[0m 
[2m[36m(pid=425132)[0m -----------------------
[2m[36m(pid=425132)[0m ring length: 495
[2m[36m(pid=425132)[0m v_max: 2.79981792361692
[2m[36m(pid=425132)[0m -----------------------
[2m[36m(pid=425132)[0m 
[2m[36m(pid=425132)[0m -----------------------
[2m[36m(pid=425132)[0m ring length: 520
[2m[36m(pid=425132)[0m v_max: 3.2996121816646764
[2m[36m(pid=425132)[0m -----------------------
Result for PPO_WaveAttenuationPOEnv-v0_0:
  custom_metrics: {}
  date: 2020-03-30_10-07-44
  done: false
  episode_len_mean: 2000.0
  episode_reward_max: 4601.683842037137
  episode_reward_mean: 4270.16416107043
  episode_reward_min: 3881.2596695791854
  episodes_this_iter: 5
  episodes_total: 325
  experiment_id: ba0edb931dde48dcb020df4b454540a2
  hostname: p0035.ten.osc.edu
  info:
    grad_time_ms: 215.056
    learner:
      default_policy:
        cur_kl_coeff: 1.220703143189894e-05
        cur_lr: 4.999999873689376e-05
        entropy: 0.10539133101701736
        entropy_coeff: 0.0
        kl: 0.008309256285429
        policy_loss: -0.0014072456397116184
        total_loss: 3463.394775390625
        vf_explained_var: 5.304813385009766e-06
        vf_loss: 3463.395263671875
    load_time_ms: 2.146
    num_steps_sampled: 650000
    num_steps_trained: 650000
    sample_time_ms: 100743.051
    update_time_ms: 2.081
  iterations_since_restore: 15
  node_ip: 10.4.1.36
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 2.6337931034482756
    ram_util_percent: 5.3999999999999995
  pid: 424867
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 6.974107113722863
    mean_inference_ms: 0.5590643945873659
    mean_processing_ms: 2.617974779606509
  time_since_restore: 1523.3834717273712
  time_this_iter_s: 101.27051639556885
  time_total_s: 6564.146352291107
  timestamp: 1585577264
  timesteps_since_restore: 150000
  timesteps_this_iter: 10000
  timesteps_total: 650000
  training_iteration: 65
  trial_id: fce6b7f4
  
[2m[36m(pid=424867)[0m 2020-03-30 10:07:44,932	WARNING ppo.py:121 -- The magnitude of your environment rewards are more than 427.0x the scale of `vf_clip_param`. This means that it will take more than 427.0 iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2/2 CPUs, 0/0 GPUs
Memory usage on this node: 10.8/201.2 GB
Result logdir: /users/PYS1027/chnrhughes/ray_results/simple_training_example_ring2_v1
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - PPO_WaveAttenuationPOEnv-v0_0:	RUNNING, 1 failures: /users/PYS1027/chnrhughes/ray_results/simple_training_example_ring2_v1/PPO_WaveAttenuationPOEnv-v0_0_2020-03-30_08-14-21aa4md2pi/error_2020-03-30_09-42-11.txt, [2 CPUs, 0 GPUs], [pid=424867], 6564 s, 65 iter, 650000 ts, 4.27e+03 rew

[2m[36m(pid=425132)[0m 
[2m[36m(pid=425132)[0m -----------------------
[2m[36m(pid=425132)[0m ring length: 509
[2m[36m(pid=425132)[0m v_max: 3.0797178990784078
[2m[36m(pid=425132)[0m -----------------------
[2m[36m(pid=425132)[0m 
[2m[36m(pid=425132)[0m -----------------------
[2m[36m(pid=425132)[0m ring length: 499
[2m[36m(pid=425132)[0m v_max: 2.8797928146697993
[2m[36m(pid=425132)[0m -----------------------
[2m[36m(pid=425132)[0m 
[2m[36m(pid=425132)[0m -----------------------
[2m[36m(pid=425132)[0m ring length: 512
[2m[36m(pid=425132)[0m v_max: 3.139691674719026
[2m[36m(pid=425132)[0m -----------------------
[2m[36m(pid=425132)[0m 
[2m[36m(pid=425132)[0m -----------------------
[2m[36m(pid=425132)[0m ring length: 517
[2m[36m(pid=425132)[0m v_max: 3.2396436965475437
[2m[36m(pid=425132)[0m -----------------------
[2m[36m(pid=425132)[0m 
[2m[36m(pid=425132)[0m -----------------------
[2m[36m(pid=425132)[0m ring length: 495
[2m[36m(pid=425132)[0m v_max: 2.79981792361692
[2m[36m(pid=425132)[0m -----------------------
Result for PPO_WaveAttenuationPOEnv-v0_0:
  custom_metrics: {}
  date: 2020-03-30_10-09-25
  done: false
  episode_len_mean: 2000.0
  episode_reward_max: 4601.683842037137
  episode_reward_mean: 4281.1275117769455
  episode_reward_min: 3881.2596695791854
  episodes_this_iter: 5
  episodes_total: 330
  experiment_id: ba0edb931dde48dcb020df4b454540a2
  hostname: p0035.ten.osc.edu
  info:
    grad_time_ms: 212.294
    learner:
      default_policy:
        cur_kl_coeff: 6.10351571594947e-06
        cur_lr: 4.999999873689376e-05
        entropy: 0.09067093580961227
        entropy_coeff: 0.0
        kl: 0.006111243739724159
        policy_loss: -0.0017824313836172223
        total_loss: 3906.521484375
        vf_explained_var: 1.0132789611816406e-06
        vf_loss: 3906.523193359375
    load_time_ms: 2.135
    num_steps_sampled: 660000
    num_steps_trained: 660000
    sample_time_ms: 100740.966
    update_time_ms: 2.066
  iterations_since_restore: 16
  node_ip: 10.4.1.36
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 2.597202797202797
    ram_util_percent: 5.399999999999999
  pid: 424867
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 6.9696623877803034
    mean_inference_ms: 0.5590201378450613
    mean_processing_ms: 2.6182517324423786
  time_since_restore: 1624.0608246326447
  time_this_iter_s: 100.67735290527344
  time_total_s: 6664.823705196381
  timestamp: 1585577365
  timesteps_since_restore: 160000
  timesteps_this_iter: 10000
  timesteps_total: 660000
  training_iteration: 66
  trial_id: fce6b7f4
  
[2m[36m(pid=424867)[0m 2020-03-30 10:09:25,633	WARNING ppo.py:121 -- The magnitude of your environment rewards are more than 428.0x the scale of `vf_clip_param`. This means that it will take more than 428.0 iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2/2 CPUs, 0/0 GPUs
Memory usage on this node: 10.8/201.2 GB
Result logdir: /users/PYS1027/chnrhughes/ray_results/simple_training_example_ring2_v1
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - PPO_WaveAttenuationPOEnv-v0_0:	RUNNING, 1 failures: /users/PYS1027/chnrhughes/ray_results/simple_training_example_ring2_v1/PPO_WaveAttenuationPOEnv-v0_0_2020-03-30_08-14-21aa4md2pi/error_2020-03-30_09-42-11.txt, [2 CPUs, 0 GPUs], [pid=424867], 6664 s, 66 iter, 660000 ts, 4.28e+03 rew

[2m[36m(pid=425132)[0m 
[2m[36m(pid=425132)[0m -----------------------
[2m[36m(pid=425132)[0m ring length: 509
[2m[36m(pid=425132)[0m v_max: 3.0797178990784078
[2m[36m(pid=425132)[0m -----------------------
[2m[36m(pid=425132)[0m 
[2m[36m(pid=425132)[0m -----------------------
[2m[36m(pid=425132)[0m ring length: 503
[2m[36m(pid=425132)[0m v_max: 2.9597650335315784
[2m[36m(pid=425132)[0m -----------------------
[2m[36m(pid=425132)[0m 
[2m[36m(pid=425132)[0m -----------------------
[2m[36m(pid=425132)[0m ring length: 513
[2m[36m(pid=425132)[0m v_max: 3.1596825160053825
[2m[36m(pid=425132)[0m -----------------------
[2m[36m(pid=425132)[0m 
[2m[36m(pid=425132)[0m -----------------------
[2m[36m(pid=425132)[0m ring length: 501
[2m[36m(pid=425132)[0m v_max: 2.919779270736568
[2m[36m(pid=425132)[0m -----------------------
[2m[36m(pid=425132)[0m 
[2m[36m(pid=425132)[0m -----------------------
[2m[36m(pid=425132)[0m ring length: 514
[2m[36m(pid=425132)[0m v_max: 3.1796731425699525
[2m[36m(pid=425132)[0m -----------------------
Result for PPO_WaveAttenuationPOEnv-v0_0:
  custom_metrics: {}
  date: 2020-03-30_10-11-06
  done: false
  episode_len_mean: 2000.0
  episode_reward_max: 4601.683842037137
  episode_reward_mean: 4278.918084197158
  episode_reward_min: 3881.2596695791854
  episodes_this_iter: 5
  episodes_total: 335
  experiment_id: ba0edb931dde48dcb020df4b454540a2
  hostname: p0035.ten.osc.edu
  info:
    grad_time_ms: 210.631
    learner:
      default_policy:
        cur_kl_coeff: 3.051757857974735e-06
        cur_lr: 4.999999873689376e-05
        entropy: 0.08444470167160034
        entropy_coeff: 0.0
        kl: 0.0067206863313913345
        policy_loss: -0.0006600292399525642
        total_loss: 3559.512451171875
        vf_explained_var: 2.6226043701171875e-06
        vf_loss: 3559.5126953125
    load_time_ms: 2.065
    num_steps_sampled: 670000
    num_steps_trained: 670000
    sample_time_ms: 100673.901
    update_time_ms: 2.071
  iterations_since_restore: 17
  node_ip: 10.4.1.36
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 2.675524475524475
    ram_util_percent: 5.399999999999999
  pid: 424867
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 6.965519374777778
    mean_inference_ms: 0.5590082302070887
    mean_processing_ms: 2.6184314248953253
  time_since_restore: 1724.504240989685
  time_this_iter_s: 100.4434163570404
  time_total_s: 6765.267121553421
  timestamp: 1585577466
  timesteps_since_restore: 170000
  timesteps_this_iter: 10000
  timesteps_total: 670000
  training_iteration: 67
  trial_id: fce6b7f4
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2/2 CPUs, 0/0 GPUs
Memory usage on this node: 10.8/201.2 GB
Result logdir: /users/PYS1027/chnrhughes/ray_results/simple_training_example_ring2_v1
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - PPO_WaveAttenuationPOEnv-v0_0:	RUNNING, 1 failures: /users/PYS1027/chnrhughes/ray_results/simple_training_example_ring2_v1/PPO_WaveAttenuationPOEnv-v0_0_2020-03-30_08-14-21aa4md2pi/error_2020-03-30_09-42-11.txt, [2 CPUs, 0 GPUs], [pid=424867], 6765 s, 67 iter, 670000 ts, 4.28e+03 rew

[2m[36m(pid=424867)[0m 2020-03-30 10:11:06,086	WARNING ppo.py:121 -- The magnitude of your environment rewards are more than 428.0x the scale of `vf_clip_param`. This means that it will take more than 428.0 iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.
[2m[36m(pid=425132)[0m 
[2m[36m(pid=425132)[0m -----------------------
[2m[36m(pid=425132)[0m ring length: 520
[2m[36m(pid=425132)[0m v_max: 3.2996121816646764
[2m[36m(pid=425132)[0m -----------------------
[2m[36m(pid=425132)[0m 
[2m[36m(pid=425132)[0m -----------------------
[2m[36m(pid=425132)[0m ring length: 508
[2m[36m(pid=425132)[0m v_max: 3.059726235247059
[2m[36m(pid=425132)[0m -----------------------
[2m[36m(pid=425132)[0m 
[2m[36m(pid=425132)[0m -----------------------
[2m[36m(pid=425132)[0m ring length: 491
[2m[36m(pid=425132)[0m v_max: 2.719840556029452
[2m[36m(pid=425132)[0m -----------------------
[2m[36m(pid=425132)[0m 
[2m[36m(pid=425132)[0m -----------------------
[2m[36m(pid=425132)[0m ring length: 514
[2m[36m(pid=425132)[0m v_max: 3.1796731425699525
[2m[36m(pid=425132)[0m -----------------------
[2m[36m(pid=425132)[0m 
[2m[36m(pid=425132)[0m -----------------------
[2m[36m(pid=425132)[0m ring length: 498
[2m[36m(pid=425132)[0m v_max: 2.8597993346145016
[2m[36m(pid=425132)[0m -----------------------
Result for PPO_WaveAttenuationPOEnv-v0_0:
  custom_metrics: {}
  date: 2020-03-30_10-12-46
  done: false
  episode_len_mean: 2000.0
  episode_reward_max: 4601.683842037137
  episode_reward_mean: 4286.951055476583
  episode_reward_min: 3881.2596695791854
  episodes_this_iter: 5
  episodes_total: 340
  experiment_id: ba0edb931dde48dcb020df4b454540a2
  hostname: p0035.ten.osc.edu
  info:
    grad_time_ms: 209.725
    learner:
      default_policy:
        cur_kl_coeff: 1.5258789289873675e-06
        cur_lr: 4.999999873689376e-05
        entropy: 0.08124742656946182
        entropy_coeff: 0.0
        kl: 0.007076395209878683
        policy_loss: -0.0007847266970202327
        total_loss: 3872.089599609375
        vf_explained_var: 1.1920928955078125e-06
        vf_loss: 3872.09033203125
    load_time_ms: 2.032
    num_steps_sampled: 680000
    num_steps_trained: 680000
    sample_time_ms: 100590.223
    update_time_ms: 2.065
  iterations_since_restore: 18
  node_ip: 10.4.1.36
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 2.6202797202797203
    ram_util_percent: 5.399999999999999
  pid: 424867
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 6.961644696724923
    mean_inference_ms: 0.5589720306877357
    mean_processing_ms: 2.6186446531942416
  time_since_restore: 1825.123699426651
  time_this_iter_s: 100.61945843696594
  time_total_s: 6865.886579990387
  timestamp: 1585577566
  timesteps_since_restore: 180000
  timesteps_this_iter: 10000
  timesteps_total: 680000
  training_iteration: 68
  trial_id: fce6b7f4
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2/2 CPUs, 0/0 GPUs
Memory usage on this node: 10.8/201.2 GB
Result logdir: /users/PYS1027/chnrhughes/ray_results/simple_training_example_ring2_v1
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - PPO_WaveAttenuationPOEnv-v0_0:	RUNNING, 1 failures: /users/PYS1027/chnrhughes/ray_results/simple_training_example_ring2_v1/PPO_WaveAttenuationPOEnv-v0_0_2020-03-30_08-14-21aa4md2pi/error_2020-03-30_09-42-11.txt, [2 CPUs, 0 GPUs], [pid=424867], 6865 s, 68 iter, 680000 ts, 4.29e+03 rew

[2m[36m(pid=424867)[0m 2020-03-30 10:12:46,715	WARNING ppo.py:121 -- The magnitude of your environment rewards are more than 429.0x the scale of `vf_clip_param`. This means that it will take more than 429.0 iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.
[2m[36m(pid=425132)[0m 
[2m[36m(pid=425132)[0m -----------------------
[2m[36m(pid=425132)[0m ring length: 520
[2m[36m(pid=425132)[0m v_max: 3.2996121816646764
[2m[36m(pid=425132)[0m -----------------------
[2m[36m(pid=425132)[0m 
[2m[36m(pid=425132)[0m -----------------------
[2m[36m(pid=425132)[0m ring length: 495
[2m[36m(pid=425132)[0m v_max: 2.79981792361692
[2m[36m(pid=425132)[0m -----------------------
[2m[36m(pid=425132)[0m 
[2m[36m(pid=425132)[0m -----------------------
[2m[36m(pid=425132)[0m ring length: 517
[2m[36m(pid=425132)[0m v_max: 3.2396436965475437
[2m[36m(pid=425132)[0m -----------------------
[2m[36m(pid=425132)[0m 
[2m[36m(pid=425132)[0m -----------------------
[2m[36m(pid=425132)[0m ring length: 490
[2m[36m(pid=425132)[0m v_max: 2.699845849180192
[2m[36m(pid=425132)[0m -----------------------
[2m[36m(pid=425132)[0m 
[2m[36m(pid=425132)[0m -----------------------
[2m[36m(pid=425132)[0m ring length: 511
[2m[36m(pid=425132)[0m v_max: 3.1197006223865698
[2m[36m(pid=425132)[0m -----------------------
Result for PPO_WaveAttenuationPOEnv-v0_0:
  custom_metrics: {}
  date: 2020-03-30_10-14-26
  done: false
  episode_len_mean: 2000.0
  episode_reward_max: 4601.683842037137
  episode_reward_mean: 4285.342207619688
  episode_reward_min: 3881.2596695791854
  episodes_this_iter: 5
  episodes_total: 345
  experiment_id: ba0edb931dde48dcb020df4b454540a2
  hostname: p0035.ten.osc.edu
  info:
    grad_time_ms: 212.16
    learner:
      default_policy:
        cur_kl_coeff: 7.629394644936838e-07
        cur_lr: 4.999999873689376e-05
        entropy: 0.06477569043636322
        entropy_coeff: 0.0
        kl: 0.0030886696185916662
        policy_loss: -0.000791029364336282
        total_loss: 3582.93994140625
        vf_explained_var: 2.682209014892578e-06
        vf_loss: 3582.9404296875
    load_time_ms: 1.997
    num_steps_sampled: 690000
    num_steps_trained: 690000
    sample_time_ms: 100467.045
    update_time_ms: 2.05
  iterations_since_restore: 19
  node_ip: 10.4.1.36
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 2.6443661971830985
    ram_util_percent: 5.399999999999998
  pid: 424867
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 6.958044905739006
    mean_inference_ms: 0.5586756711447725
    mean_processing_ms: 2.6188124021936727
  time_since_restore: 1924.747134923935
  time_this_iter_s: 99.62343549728394
  time_total_s: 6965.510015487671
  timestamp: 1585577666
  timesteps_since_restore: 190000
  timesteps_this_iter: 10000
  timesteps_total: 690000
  training_iteration: 69
  trial_id: fce6b7f4
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2/2 CPUs, 0/0 GPUs
Memory usage on this node: 10.9/201.2 GB
Result logdir: /users/PYS1027/chnrhughes/ray_results/simple_training_example_ring2_v1
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - PPO_WaveAttenuationPOEnv-v0_0:	RUNNING, 1 failures: /users/PYS1027/chnrhughes/ray_results/simple_training_example_ring2_v1/PPO_WaveAttenuationPOEnv-v0_0_2020-03-30_08-14-21aa4md2pi/error_2020-03-30_09-42-11.txt, [2 CPUs, 0 GPUs], [pid=424867], 6965 s, 69 iter, 690000 ts, 4.29e+03 rew

[2m[36m(pid=424867)[0m 2020-03-30 10:14:26,348	WARNING ppo.py:121 -- The magnitude of your environment rewards are more than 429.0x the scale of `vf_clip_param`. This means that it will take more than 429.0 iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.
[2m[36m(pid=425132)[0m 
[2m[36m(pid=425132)[0m -----------------------
[2m[36m(pid=425132)[0m ring length: 512
[2m[36m(pid=425132)[0m v_max: 3.139691674719026
[2m[36m(pid=425132)[0m -----------------------
[2m[36m(pid=425132)[0m 
[2m[36m(pid=425132)[0m -----------------------
[2m[36m(pid=425132)[0m ring length: 505
[2m[36m(pid=425132)[0m v_max: 2.999750077051092
[2m[36m(pid=425132)[0m -----------------------
[2m[36m(pid=425132)[0m 
[2m[36m(pid=425132)[0m -----------------------
[2m[36m(pid=425132)[0m ring length: 520
[2m[36m(pid=425132)[0m v_max: 3.2996121816646764
[2m[36m(pid=425132)[0m -----------------------
[2m[36m(pid=425132)[0m 
[2m[36m(pid=425132)[0m -----------------------
[2m[36m(pid=425132)[0m ring length: 516
[2m[36m(pid=425132)[0m v_max: 3.2196537366217006
[2m[36m(pid=425132)[0m -----------------------
[2m[36m(pid=425132)[0m 
[2m[36m(pid=425132)[0m -----------------------
[2m[36m(pid=425132)[0m ring length: 510
[2m[36m(pid=425132)[0m v_max: 3.0997093626421153
[2m[36m(pid=425132)[0m -----------------------
Result for PPO_WaveAttenuationPOEnv-v0_0:
  custom_metrics: {}
  date: 2020-03-30_10-16-06
  done: false
  episode_len_mean: 2000.0
  episode_reward_max: 4619.8378080221
  episode_reward_mean: 4293.768468517014
  episode_reward_min: 3881.2596695791854
  episodes_this_iter: 5
  episodes_total: 350
  experiment_id: ba0edb931dde48dcb020df4b454540a2
  hostname: p0035.ten.osc.edu
  info:
    grad_time_ms: 212.368
    learner:
      default_policy:
        cur_kl_coeff: 3.814697322468419e-07
        cur_lr: 4.999999873689376e-05
        entropy: 0.0573970228433609
        entropy_coeff: 0.0
        kl: 0.004527408163994551
        policy_loss: -0.00036360035301186144
        total_loss: 3924.146484375
        vf_explained_var: 1.3113021850585938e-06
        vf_loss: 3924.147216796875
    load_time_ms: 2.0
    num_steps_sampled: 700000
    num_steps_trained: 700000
    sample_time_ms: 100423.729
    update_time_ms: 2.055
  iterations_since_restore: 20
  node_ip: 10.4.1.36
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 2.6049295774647887
    ram_util_percent: 5.399999999999998
  pid: 424867
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 6.954745313516439
    mean_inference_ms: 0.5582280173659379
    mean_processing_ms: 2.618951774391013
  time_since_restore: 2024.7796409130096
  time_this_iter_s: 100.0325059890747
  time_total_s: 7065.542521476746
  timestamp: 1585577766
  timesteps_since_restore: 200000
  timesteps_this_iter: 10000
  timesteps_total: 700000
  training_iteration: 70
  trial_id: fce6b7f4
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2/2 CPUs, 0/0 GPUs
Memory usage on this node: 10.8/201.2 GB
Result logdir: /users/PYS1027/chnrhughes/ray_results/simple_training_example_ring2_v1
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - PPO_WaveAttenuationPOEnv-v0_0:	RUNNING, 1 failures: /users/PYS1027/chnrhughes/ray_results/simple_training_example_ring2_v1/PPO_WaveAttenuationPOEnv-v0_0_2020-03-30_08-14-21aa4md2pi/error_2020-03-30_09-42-11.txt, [2 CPUs, 0 GPUs], [pid=424867], 7065 s, 70 iter, 700000 ts, 4.29e+03 rew

[2m[36m(pid=424867)[0m 2020-03-30 10:16:06,391	WARNING ppo.py:121 -- The magnitude of your environment rewards are more than 429.0x the scale of `vf_clip_param`. This means that it will take more than 429.0 iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.
[2m[36m(pid=425132)[0m 
[2m[36m(pid=425132)[0m -----------------------
[2m[36m(pid=425132)[0m ring length: 513
[2m[36m(pid=425132)[0m v_max: 3.1596825160053825
[2m[36m(pid=425132)[0m -----------------------
[2m[36m(pid=425132)[0m 
[2m[36m(pid=425132)[0m -----------------------
[2m[36m(pid=425132)[0m ring length: 509
[2m[36m(pid=425132)[0m v_max: 3.0797178990784078
[2m[36m(pid=425132)[0m -----------------------
[2m[36m(pid=425132)[0m 
[2m[36m(pid=425132)[0m -----------------------
[2m[36m(pid=425132)[0m ring length: 511
[2m[36m(pid=425132)[0m v_max: 3.1197006223865698
[2m[36m(pid=425132)[0m -----------------------
[2m[36m(pid=425132)[0m 
[2m[36m(pid=425132)[0m -----------------------
[2m[36m(pid=425132)[0m ring length: 499
[2m[36m(pid=425132)[0m v_max: 2.8797928146697993
[2m[36m(pid=425132)[0m -----------------------
[2m[36m(pid=425132)[0m 
[2m[36m(pid=425132)[0m -----------------------
[2m[36m(pid=425132)[0m ring length: 510
[2m[36m(pid=425132)[0m v_max: 3.0997093626421153
[2m[36m(pid=425132)[0m -----------------------
Result for PPO_WaveAttenuationPOEnv-v0_0:
  custom_metrics: {}
  date: 2020-03-30_10-17-46
  done: false
  episode_len_mean: 2000.0
  episode_reward_max: 4619.8378080221
  episode_reward_mean: 4310.973538228286
  episode_reward_min: 3942.7013057195923
  episodes_this_iter: 5
  episodes_total: 355
  experiment_id: ba0edb931dde48dcb020df4b454540a2
  hostname: p0035.ten.osc.edu
  info:
    grad_time_ms: 212.759
    learner:
      default_policy:
        cur_kl_coeff: 1.9073486612342094e-07
        cur_lr: 4.999999873689376e-05
        entropy: 0.04374447837471962
        entropy_coeff: 0.0
        kl: 0.003254995448514819
        policy_loss: -0.00020861740631517023
        total_loss: 4018.169189453125
        vf_explained_var: 2.384185791015625e-07
        vf_loss: 4018.169677734375
    load_time_ms: 1.99
    num_steps_sampled: 710000
    num_steps_trained: 710000
    sample_time_ms: 100409.843
    update_time_ms: 2.058
  iterations_since_restore: 21
  node_ip: 10.4.1.36
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 2.6839160839160834
    ram_util_percent: 5.399999999999999
  pid: 424867
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 6.932452364124638
    mean_inference_ms: 0.5564607346344661
    mean_processing_ms: 2.6197673120331926
  time_since_restore: 2124.7247474193573
  time_this_iter_s: 99.94510650634766
  time_total_s: 7165.487627983093
  timestamp: 1585577866
  timesteps_since_restore: 210000
  timesteps_this_iter: 10000
  timesteps_total: 710000
  training_iteration: 71
  trial_id: fce6b7f4
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2/2 CPUs, 0/0 GPUs
Memory usage on this node: 10.8/201.2 GB
Result logdir: /users/PYS1027/chnrhughes/ray_results/simple_training_example_ring2_v1
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - PPO_WaveAttenuationPOEnv-v0_0:	RUNNING, 1 failures: /users/PYS1027/chnrhughes/ray_results/simple_training_example_ring2_v1/PPO_WaveAttenuationPOEnv-v0_0_2020-03-30_08-14-21aa4md2pi/error_2020-03-30_09-42-11.txt, [2 CPUs, 0 GPUs], [pid=424867], 7165 s, 71 iter, 710000 ts, 4.31e+03 rew

[2m[36m(pid=424867)[0m 2020-03-30 10:17:46,360	WARNING ppo.py:121 -- The magnitude of your environment rewards are more than 431.0x the scale of `vf_clip_param`. This means that it will take more than 431.0 iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.
[2m[36m(pid=425132)[0m 
[2m[36m(pid=425132)[0m -----------------------
[2m[36m(pid=425132)[0m ring length: 497
[2m[36m(pid=425132)[0m v_max: 2.839805690709741
[2m[36m(pid=425132)[0m -----------------------
[2m[36m(pid=425132)[0m 
[2m[36m(pid=425132)[0m -----------------------
[2m[36m(pid=425132)[0m ring length: 505
[2m[36m(pid=425132)[0m v_max: 2.999750077051092
[2m[36m(pid=425132)[0m -----------------------
[2m[36m(pid=425132)[0m 
[2m[36m(pid=425132)[0m -----------------------
[2m[36m(pid=425132)[0m ring length: 517
[2m[36m(pid=425132)[0m v_max: 3.2396436965475437
[2m[36m(pid=425132)[0m -----------------------
[2m[36m(pid=425132)[0m 
[2m[36m(pid=425132)[0m -----------------------
[2m[36m(pid=425132)[0m ring length: 490
[2m[36m(pid=425132)[0m v_max: 2.699845849180192
[2m[36m(pid=425132)[0m -----------------------
[2m[36m(pid=425132)[0m 
[2m[36m(pid=425132)[0m -----------------------
[2m[36m(pid=425132)[0m ring length: 517
[2m[36m(pid=425132)[0m v_max: 3.2396436965475437
[2m[36m(pid=425132)[0m -----------------------
Result for PPO_WaveAttenuationPOEnv-v0_0:
  custom_metrics: {}
  date: 2020-03-30_10-19-27
  done: false
  episode_len_mean: 2000.0
  episode_reward_max: 4698.499703071983
  episode_reward_mean: 4322.31404495382
  episode_reward_min: 3942.7013057195923
  episodes_this_iter: 5
  episodes_total: 360
  experiment_id: ba0edb931dde48dcb020df4b454540a2
  hostname: p0035.ten.osc.edu
  info:
    grad_time_ms: 212.57
    learner:
      default_policy:
        cur_kl_coeff: 9.536743306171047e-08
        cur_lr: 4.999999873689376e-05
        entropy: 0.03550291806459427
        entropy_coeff: 0.0
        kl: 0.002753509907051921
        policy_loss: -0.00018525276391301304
        total_loss: 4032.54638671875
        vf_explained_var: 1.1920928955078125e-07
        vf_loss: 4032.546875
    load_time_ms: 2.059
    num_steps_sampled: 720000
    num_steps_trained: 720000
    sample_time_ms: 100407.215
    update_time_ms: 2.041
  iterations_since_restore: 22
  node_ip: 10.4.1.36
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 2.6090909090909093
    ram_util_percent: 5.399999999999999
  pid: 424867
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 6.9224802115081685
    mean_inference_ms: 0.5553424291368746
    mean_processing_ms: 2.6205562970482577
  time_since_restore: 2225.3692622184753
  time_this_iter_s: 100.64451479911804
  time_total_s: 7266.132142782211
  timestamp: 1585577967
  timesteps_since_restore: 220000
  timesteps_this_iter: 10000
  timesteps_total: 720000
  training_iteration: 72
  trial_id: fce6b7f4
  
[2m[36m(pid=424867)[0m 2020-03-30 10:19:27,015	WARNING ppo.py:121 -- The magnitude of your environment rewards are more than 432.0x the scale of `vf_clip_param`. This means that it will take more than 432.0 iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2/2 CPUs, 0/0 GPUs
Memory usage on this node: 10.8/201.2 GB
Result logdir: /users/PYS1027/chnrhughes/ray_results/simple_training_example_ring2_v1
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - PPO_WaveAttenuationPOEnv-v0_0:	RUNNING, 1 failures: /users/PYS1027/chnrhughes/ray_results/simple_training_example_ring2_v1/PPO_WaveAttenuationPOEnv-v0_0_2020-03-30_08-14-21aa4md2pi/error_2020-03-30_09-42-11.txt, [2 CPUs, 0 GPUs], [pid=424867], 7266 s, 72 iter, 720000 ts, 4.32e+03 rew

[2m[36m(pid=425132)[0m 
[2m[36m(pid=425132)[0m -----------------------
[2m[36m(pid=425132)[0m ring length: 500
[2m[36m(pid=425132)[0m v_max: 2.8997861277614296
[2m[36m(pid=425132)[0m -----------------------
[2m[36m(pid=425132)[0m 
[2m[36m(pid=425132)[0m -----------------------
[2m[36m(pid=425132)[0m ring length: 511
[2m[36m(pid=425132)[0m v_max: 3.1197006223865698
[2m[36m(pid=425132)[0m -----------------------
[2m[36m(pid=425132)[0m 
[2m[36m(pid=425132)[0m -----------------------
[2m[36m(pid=425132)[0m ring length: 520
[2m[36m(pid=425132)[0m v_max: 3.2996121816646764
[2m[36m(pid=425132)[0m -----------------------
[2m[36m(pid=425132)[0m 
[2m[36m(pid=425132)[0m -----------------------
[2m[36m(pid=425132)[0m ring length: 519
[2m[36m(pid=425132)[0m v_max: 3.2796229229775036
[2m[36m(pid=425132)[0m -----------------------
[2m[36m(pid=425132)[0m 
[2m[36m(pid=425132)[0m -----------------------
[2m[36m(pid=425132)[0m ring length: 497
[2m[36m(pid=425132)[0m v_max: 2.839805690709741
[2m[36m(pid=425132)[0m -----------------------
Result for PPO_WaveAttenuationPOEnv-v0_0:
  custom_metrics: {}
  date: 2020-03-30_10-21-07
  done: false
  episode_len_mean: 2000.0
  episode_reward_max: 4806.674192930748
  episode_reward_mean: 4345.92139929531
  episode_reward_min: 3974.181577274629
  episodes_this_iter: 5
  episodes_total: 365
  experiment_id: ba0edb931dde48dcb020df4b454540a2
  hostname: p0035.ten.osc.edu
  info:
    grad_time_ms: 212.389
    learner:
      default_policy:
        cur_kl_coeff: 4.7683716530855236e-08
        cur_lr: 4.999999873689376e-05
        entropy: 0.03218604251742363
        entropy_coeff: 0.0
        kl: 0.0062463972717523575
        policy_loss: -0.0011086359154433012
        total_loss: 4328.806640625
        vf_explained_var: 2.980232238769531e-07
        vf_loss: 4328.8076171875
    load_time_ms: 1.942
    num_steps_sampled: 730000
    num_steps_trained: 730000
    sample_time_ms: 100330.075
    update_time_ms: 2.071
  iterations_since_restore: 23
  node_ip: 10.4.1.36
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 2.6328671328671325
    ram_util_percent: 5.399999999999999
  pid: 424867
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 6.9157907866845285
    mean_inference_ms: 0.5549091643102128
    mean_processing_ms: 2.6207519941581445
  time_since_restore: 2325.6553905010223
  time_this_iter_s: 100.286128282547
  time_total_s: 7366.418271064758
  timestamp: 1585578067
  timesteps_since_restore: 230000
  timesteps_this_iter: 10000
  timesteps_total: 730000
  training_iteration: 73
  trial_id: fce6b7f4
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2/2 CPUs, 0/0 GPUs
Memory usage on this node: 10.8/201.2 GB
Result logdir: /users/PYS1027/chnrhughes/ray_results/simple_training_example_ring2_v1
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - PPO_WaveAttenuationPOEnv-v0_0:	RUNNING, 1 failures: /users/PYS1027/chnrhughes/ray_results/simple_training_example_ring2_v1/PPO_WaveAttenuationPOEnv-v0_0_2020-03-30_08-14-21aa4md2pi/error_2020-03-30_09-42-11.txt, [2 CPUs, 0 GPUs], [pid=424867], 7366 s, 73 iter, 730000 ts, 4.35e+03 rew

[2m[36m(pid=424867)[0m 2020-03-30 10:21:07,312	WARNING ppo.py:121 -- The magnitude of your environment rewards are more than 435.0x the scale of `vf_clip_param`. This means that it will take more than 435.0 iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.
[2m[36m(pid=425132)[0m 
[2m[36m(pid=425132)[0m -----------------------
[2m[36m(pid=425132)[0m ring length: 492
[2m[36m(pid=425132)[0m v_max: 2.739835119766572
[2m[36m(pid=425132)[0m -----------------------
[2m[36m(pid=425132)[0m 
[2m[36m(pid=425132)[0m -----------------------
[2m[36m(pid=425132)[0m ring length: 495
[2m[36m(pid=425132)[0m v_max: 2.79981792361692
[2m[36m(pid=425132)[0m -----------------------
[2m[36m(pid=425132)[0m 
[2m[36m(pid=425132)[0m -----------------------
[2m[36m(pid=425132)[0m ring length: 499
[2m[36m(pid=425132)[0m v_max: 2.8797928146697993
[2m[36m(pid=425132)[0m -----------------------
[2m[36m(pid=425132)[0m 
[2m[36m(pid=425132)[0m -----------------------
[2m[36m(pid=425132)[0m ring length: 496
[2m[36m(pid=425132)[0m v_max: 2.819811886031332
[2m[36m(pid=425132)[0m -----------------------
[2m[36m(pid=425132)[0m 
[2m[36m(pid=425132)[0m -----------------------
[2m[36m(pid=425132)[0m ring length: 496
[2m[36m(pid=425132)[0m v_max: 2.819811886031332
[2m[36m(pid=425132)[0m -----------------------
Result for PPO_WaveAttenuationPOEnv-v0_0:
  custom_metrics: {}
  date: 2020-03-30_10-22-46
  done: false
  episode_len_mean: 2000.0
  episode_reward_max: 4806.674192930748
  episode_reward_mean: 4356.152324223402
  episode_reward_min: 3974.181577274629
  episodes_this_iter: 5
  episodes_total: 370
  experiment_id: ba0edb931dde48dcb020df4b454540a2
  hostname: p0035.ten.osc.edu
  info:
    grad_time_ms: 212.266
    learner:
      default_policy:
        cur_kl_coeff: 2.3841858265427618e-08
        cur_lr: 4.999999873689376e-05
        entropy: 0.025100115686655045
        entropy_coeff: 0.0
        kl: 0.005773826036602259
        policy_loss: -0.00045039926772005856
        total_loss: 3901.25244140625
        vf_explained_var: -2.384185791015625e-07
        vf_loss: 3901.252685546875
    load_time_ms: 1.938
    num_steps_sampled: 740000
    num_steps_trained: 740000
    sample_time_ms: 100091.237
    update_time_ms: 2.057
  iterations_since_restore: 24
  node_ip: 10.4.1.36
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 2.648591549295775
    ram_util_percent: 5.399999999999998
  pid: 424867
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 6.910637601635744
    mean_inference_ms: 0.5544956465553996
    mean_processing_ms: 2.6210647024393627
  time_since_restore: 2425.250150203705
  time_this_iter_s: 99.5947597026825
  time_total_s: 7466.013030767441
  timestamp: 1585578166
  timesteps_since_restore: 240000
  timesteps_this_iter: 10000
  timesteps_total: 740000
  training_iteration: 74
  trial_id: fce6b7f4
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2/2 CPUs, 0/0 GPUs
Memory usage on this node: 10.8/201.2 GB
Result logdir: /users/PYS1027/chnrhughes/ray_results/simple_training_example_ring2_v1
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - PPO_WaveAttenuationPOEnv-v0_0:	RUNNING, 1 failures: /users/PYS1027/chnrhughes/ray_results/simple_training_example_ring2_v1/PPO_WaveAttenuationPOEnv-v0_0_2020-03-30_08-14-21aa4md2pi/error_2020-03-30_09-42-11.txt, [2 CPUs, 0 GPUs], [pid=424867], 7466 s, 74 iter, 740000 ts, 4.36e+03 rew

[2m[36m(pid=424867)[0m 2020-03-30 10:22:46,918	WARNING ppo.py:121 -- The magnitude of your environment rewards are more than 436.0x the scale of `vf_clip_param`. This means that it will take more than 436.0 iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.
[2m[36m(pid=425132)[0m 
[2m[36m(pid=425132)[0m -----------------------
[2m[36m(pid=425132)[0m ring length: 492
[2m[36m(pid=425132)[0m v_max: 2.739835119766572
[2m[36m(pid=425132)[0m -----------------------
[2m[36m(pid=425132)[0m 
[2m[36m(pid=425132)[0m -----------------------
[2m[36m(pid=425132)[0m ring length: 506
[2m[36m(pid=425132)[0m v_max: 3.0197423207835943
[2m[36m(pid=425132)[0m -----------------------
[2m[36m(pid=425132)[0m 
[2m[36m(pid=425132)[0m -----------------------
[2m[36m(pid=425132)[0m ring length: 515
[2m[36m(pid=425132)[0m v_max: 3.199663550695237
[2m[36m(pid=425132)[0m -----------------------
[2m[36m(pid=425132)[0m 
[2m[36m(pid=425132)[0m -----------------------
[2m[36m(pid=425132)[0m ring length: 495
[2m[36m(pid=425132)[0m v_max: 2.79981792361692
[2m[36m(pid=425132)[0m -----------------------
[2m[36m(pid=425132)[0m 
[2m[36m(pid=425132)[0m -----------------------
[2m[36m(pid=425132)[0m ring length: 491
[2m[36m(pid=425132)[0m v_max: 2.719840556029452
[2m[36m(pid=425132)[0m -----------------------
Result for PPO_WaveAttenuationPOEnv-v0_0:
  custom_metrics: {}
  date: 2020-03-30_10-24-27
  done: false
  episode_len_mean: 2000.0
  episode_reward_max: 4806.674192930748
  episode_reward_mean: 4368.671480859546
  episode_reward_min: 3974.181577274629
  episodes_this_iter: 5
  episodes_total: 375
  experiment_id: ba0edb931dde48dcb020df4b454540a2
  hostname: p0035.ten.osc.edu
  info:
    grad_time_ms: 213.141
    learner:
      default_policy:
        cur_kl_coeff: 1.1920929132713809e-08
        cur_lr: 4.999999873689376e-05
        entropy: 0.020449023693799973
        entropy_coeff: 0.0
        kl: 0.00523188803344965
        policy_loss: -0.0005736412131227553
        total_loss: 4036.910888671875
        vf_explained_var: 1.1920928955078125e-07
        vf_loss: 4036.9111328125
    load_time_ms: 1.938
    num_steps_sampled: 750000
    num_steps_trained: 750000
    sample_time_ms: 100019.949
    update_time_ms: 2.036
  iterations_since_restore: 25
  node_ip: 10.4.1.36
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 2.6524475524475526
    ram_util_percent: 5.399999999999999
  pid: 424867
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 6.906681214891062
    mean_inference_ms: 0.5535809180022826
    mean_processing_ms: 2.6212004798922215
  time_since_restore: 2525.8162190914154
  time_this_iter_s: 100.56606888771057
  time_total_s: 7566.579099655151
  timestamp: 1585578267
  timesteps_since_restore: 250000
  timesteps_this_iter: 10000
  timesteps_total: 750000
  training_iteration: 75
  trial_id: fce6b7f4
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2/2 CPUs, 0/0 GPUs
Memory usage on this node: 10.8/201.2 GB
Result logdir: /users/PYS1027/chnrhughes/ray_results/simple_training_example_ring2_v1
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - PPO_WaveAttenuationPOEnv-v0_0:	RUNNING, 1 failures: /users/PYS1027/chnrhughes/ray_results/simple_training_example_ring2_v1/PPO_WaveAttenuationPOEnv-v0_0_2020-03-30_08-14-21aa4md2pi/error_2020-03-30_09-42-11.txt, [2 CPUs, 0 GPUs], [pid=424867], 7566 s, 75 iter, 750000 ts, 4.37e+03 rew

[2m[36m(pid=424867)[0m 2020-03-30 10:24:27,493	WARNING ppo.py:121 -- The magnitude of your environment rewards are more than 437.0x the scale of `vf_clip_param`. This means that it will take more than 437.0 iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.
[2m[36m(pid=425132)[0m 
[2m[36m(pid=425132)[0m -----------------------
[2m[36m(pid=425132)[0m ring length: 500
[2m[36m(pid=425132)[0m v_max: 2.8997861277614296
[2m[36m(pid=425132)[0m -----------------------
[2m[36m(pid=425132)[0m 
[2m[36m(pid=425132)[0m -----------------------
[2m[36m(pid=425132)[0m ring length: 517
[2m[36m(pid=425132)[0m v_max: 3.2396436965475437
[2m[36m(pid=425132)[0m -----------------------
[2m[36m(pid=425132)[0m 
[2m[36m(pid=425132)[0m -----------------------
[2m[36m(pid=425132)[0m ring length: 491
[2m[36m(pid=425132)[0m v_max: 2.719840556029452
[2m[36m(pid=425132)[0m -----------------------
[2m[36m(pid=425132)[0m 
[2m[36m(pid=425132)[0m -----------------------
[2m[36m(pid=425132)[0m ring length: 502
[2m[36m(pid=425132)[0m v_max: 2.9397722404035362
[2m[36m(pid=425132)[0m -----------------------
[2m[36m(pid=425132)[0m 
[2m[36m(pid=425132)[0m -----------------------
[2m[36m(pid=425132)[0m ring length: 492
[2m[36m(pid=425132)[0m v_max: 2.739835119766572
[2m[36m(pid=425132)[0m -----------------------
Result for PPO_WaveAttenuationPOEnv-v0_0:
  custom_metrics: {}
  date: 2020-03-30_10-26-07
  done: false
  episode_len_mean: 2000.0
  episode_reward_max: 4806.674192930748
  episode_reward_mean: 4386.882091139719
  episode_reward_min: 4027.6480705708095
  episodes_this_iter: 5
  episodes_total: 380
  experiment_id: ba0edb931dde48dcb020df4b454540a2
  hostname: p0035.ten.osc.edu
  info:
    grad_time_ms: 214.729
    learner:
      default_policy:
        cur_kl_coeff: 5.9604645663569045e-09
        cur_lr: 4.999999873689376e-05
        entropy: 0.016433387994766235
        entropy_coeff: 0.0
        kl: 0.007695931475609541
        policy_loss: -0.0014043678529560566
        total_loss: 4030.210693359375
        vf_explained_var: 1.1920928955078125e-07
        vf_loss: 4030.2119140625
    load_time_ms: 1.955
    num_steps_sampled: 760000
    num_steps_trained: 760000
    sample_time_ms: 99982.08
    update_time_ms: 2.035
  iterations_since_restore: 26
  node_ip: 10.4.1.36
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 2.6622377622377615
    ram_util_percent: 5.399999999999999
  pid: 424867
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 6.903474574634093
    mean_inference_ms: 0.5527513748069502
    mean_processing_ms: 2.6212992640064847
  time_since_restore: 2626.1322178840637
  time_this_iter_s: 100.31599879264832
  time_total_s: 7666.8950984478
  timestamp: 1585578367
  timesteps_since_restore: 260000
  timesteps_this_iter: 10000
  timesteps_total: 760000
  training_iteration: 76
  trial_id: fce6b7f4
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2/2 CPUs, 0/0 GPUs
Memory usage on this node: 10.8/201.2 GB
Result logdir: /users/PYS1027/chnrhughes/ray_results/simple_training_example_ring2_v1
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - PPO_WaveAttenuationPOEnv-v0_0:	RUNNING, 1 failures: /users/PYS1027/chnrhughes/ray_results/simple_training_example_ring2_v1/PPO_WaveAttenuationPOEnv-v0_0_2020-03-30_08-14-21aa4md2pi/error_2020-03-30_09-42-11.txt, [2 CPUs, 0 GPUs], [pid=424867], 7666 s, 76 iter, 760000 ts, 4.39e+03 rew

[2m[36m(pid=424867)[0m 2020-03-30 10:26:07,833	WARNING ppo.py:121 -- The magnitude of your environment rewards are more than 439.0x the scale of `vf_clip_param`. This means that it will take more than 439.0 iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.
[2m[36m(pid=425132)[0m 
[2m[36m(pid=425132)[0m -----------------------
[2m[36m(pid=425132)[0m ring length: 519
[2m[36m(pid=425132)[0m v_max: 3.2796229229775036
[2m[36m(pid=425132)[0m -----------------------
[2m[36m(pid=425132)[0m 
[2m[36m(pid=425132)[0m -----------------------
[2m[36m(pid=425132)[0m ring length: 501
[2m[36m(pid=425132)[0m v_max: 2.919779270736568
[2m[36m(pid=425132)[0m -----------------------
[2m[36m(pid=425132)[0m 
[2m[36m(pid=425132)[0m -----------------------
[2m[36m(pid=425132)[0m ring length: 520
[2m[36m(pid=425132)[0m v_max: 3.2996121816646764
[2m[36m(pid=425132)[0m -----------------------
[2m[36m(pid=425132)[0m 
[2m[36m(pid=425132)[0m -----------------------
[2m[36m(pid=425132)[0m ring length: 518
[2m[36m(pid=425132)[0m v_max: 3.2596334266284783
[2m[36m(pid=425132)[0m -----------------------
[2m[36m(pid=425132)[0m 
[2m[36m(pid=425132)[0m -----------------------
[2m[36m(pid=425132)[0m ring length: 493
[2m[36m(pid=425132)[0m v_max: 2.759829537541262
[2m[36m(pid=425132)[0m -----------------------
Result for PPO_WaveAttenuationPOEnv-v0_0:
  custom_metrics: {}
  date: 2020-03-30_10-27-48
  done: false
  episode_len_mean: 2000.0
  episode_reward_max: 4840.647108336213
  episode_reward_mean: 4407.461380180444
  episode_reward_min: 4032.558780893003
  episodes_this_iter: 5
  episodes_total: 385
  experiment_id: ba0edb931dde48dcb020df4b454540a2
  hostname: p0035.ten.osc.edu
  info:
    grad_time_ms: 216.009
    learner:
      default_policy:
        cur_kl_coeff: 2.9802322831784522e-09
        cur_lr: 4.999999873689376e-05
        entropy: 0.01475078146904707
        entropy_coeff: 0.0
        kl: 0.0037331520579755306
        policy_loss: -0.00015390721091534942
        total_loss: 4302.2578125
        vf_explained_var: 4.172325134277344e-07
        vf_loss: 4302.25830078125
    load_time_ms: 1.968
    num_steps_sampled: 770000
    num_steps_trained: 770000
    sample_time_ms: 99994.793
    update_time_ms: 2.05
  iterations_since_restore: 27
  node_ip: 10.4.1.36
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 2.5965034965034963
    ram_util_percent: 5.399999999999999
  pid: 424867
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 6.900993153949502
    mean_inference_ms: 0.5515327780814182
    mean_processing_ms: 2.6213649104467174
  time_since_restore: 2726.715844631195
  time_this_iter_s: 100.58362674713135
  time_total_s: 7767.478725194931
  timestamp: 1585578468
  timesteps_since_restore: 270000
  timesteps_this_iter: 10000
  timesteps_total: 770000
  training_iteration: 77
  trial_id: fce6b7f4
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2/2 CPUs, 0/0 GPUs
Memory usage on this node: 10.8/201.2 GB
Result logdir: /users/PYS1027/chnrhughes/ray_results/simple_training_example_ring2_v1
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - PPO_WaveAttenuationPOEnv-v0_0:	RUNNING, 1 failures: /users/PYS1027/chnrhughes/ray_results/simple_training_example_ring2_v1/PPO_WaveAttenuationPOEnv-v0_0_2020-03-30_08-14-21aa4md2pi/error_2020-03-30_09-42-11.txt, [2 CPUs, 0 GPUs], [pid=424867], 7767 s, 77 iter, 770000 ts, 4.41e+03 rew

[2m[36m(pid=424867)[0m 2020-03-30 10:27:48,427	WARNING ppo.py:121 -- The magnitude of your environment rewards are more than 441.0x the scale of `vf_clip_param`. This means that it will take more than 441.0 iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.
[2m[36m(pid=425132)[0m 
[2m[36m(pid=425132)[0m -----------------------
[2m[36m(pid=425132)[0m ring length: 506
[2m[36m(pid=425132)[0m v_max: 3.0197423207835943
[2m[36m(pid=425132)[0m -----------------------
[2m[36m(pid=425132)[0m 
[2m[36m(pid=425132)[0m -----------------------
[2m[36m(pid=425132)[0m ring length: 512
[2m[36m(pid=425132)[0m v_max: 3.139691674719026
[2m[36m(pid=425132)[0m -----------------------
[2m[36m(pid=425132)[0m 
[2m[36m(pid=425132)[0m -----------------------
[2m[36m(pid=425132)[0m ring length: 500
[2m[36m(pid=425132)[0m v_max: 2.8997861277614296
[2m[36m(pid=425132)[0m -----------------------
[2m[36m(pid=425132)[0m 
[2m[36m(pid=425132)[0m -----------------------
[2m[36m(pid=425132)[0m ring length: 517
[2m[36m(pid=425132)[0m v_max: 3.2396436965475437
[2m[36m(pid=425132)[0m -----------------------
[2m[36m(pid=425132)[0m 
[2m[36m(pid=425132)[0m -----------------------
[2m[36m(pid=425132)[0m ring length: 518
[2m[36m(pid=425132)[0m v_max: 3.2596334266284783
[2m[36m(pid=425132)[0m -----------------------
Result for PPO_WaveAttenuationPOEnv-v0_0:
  custom_metrics: {}
  date: 2020-03-30_10-29-28
  done: false
  episode_len_mean: 2000.0
  episode_reward_max: 4840.647108336213
  episode_reward_mean: 4426.573005408268
  episode_reward_min: 4032.558780893003
  episodes_this_iter: 5
  episodes_total: 390
  experiment_id: ba0edb931dde48dcb020df4b454540a2
  hostname: p0035.ten.osc.edu
  info:
    grad_time_ms: 217.129
    learner:
      default_policy:
        cur_kl_coeff: 1.4901161415892261e-09
        cur_lr: 4.999999873689376e-05
        entropy: 0.010570927523076534
        entropy_coeff: 0.0
        kl: 0.006495124660432339
        policy_loss: -0.0006805412122048438
        total_loss: 4204.49755859375
        vf_explained_var: 2.980232238769531e-07
        vf_loss: 4204.4990234375
    load_time_ms: 2.057
    num_steps_sampled: 780000
    num_steps_trained: 780000
    sample_time_ms: 99975.829
    update_time_ms: 2.042
  iterations_since_restore: 28
  node_ip: 10.4.1.36
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 2.66013986013986
    ram_util_percent: 5.399999999999999
  pid: 424867
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 6.898915794937872
    mean_inference_ms: 0.5499251198853737
    mean_processing_ms: 2.621395647663071
  time_since_restore: 2827.1591851711273
  time_this_iter_s: 100.44334053993225
  time_total_s: 7867.922065734863
  timestamp: 1585578568
  timesteps_since_restore: 280000
  timesteps_this_iter: 10000
  timesteps_total: 780000
  training_iteration: 78
  trial_id: fce6b7f4
  
[2m[36m(pid=424867)[0m 2020-03-30 10:29:28,880	WARNING ppo.py:121 -- The magnitude of your environment rewards are more than 443.0x the scale of `vf_clip_param`. This means that it will take more than 443.0 iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2/2 CPUs, 0/0 GPUs
Memory usage on this node: 10.9/201.2 GB
Result logdir: /users/PYS1027/chnrhughes/ray_results/simple_training_example_ring2_v1
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - PPO_WaveAttenuationPOEnv-v0_0:	RUNNING, 1 failures: /users/PYS1027/chnrhughes/ray_results/simple_training_example_ring2_v1/PPO_WaveAttenuationPOEnv-v0_0_2020-03-30_08-14-21aa4md2pi/error_2020-03-30_09-42-11.txt, [2 CPUs, 0 GPUs], [pid=424867], 7867 s, 78 iter, 780000 ts, 4.43e+03 rew

[2m[36m(pid=425132)[0m 
[2m[36m(pid=425132)[0m -----------------------
[2m[36m(pid=425132)[0m ring length: 499
[2m[36m(pid=425132)[0m v_max: 2.8797928146697993
[2m[36m(pid=425132)[0m -----------------------
[2m[36m(pid=425132)[0m 
[2m[36m(pid=425132)[0m -----------------------
[2m[36m(pid=425132)[0m ring length: 509
[2m[36m(pid=425132)[0m v_max: 3.0797178990784078
[2m[36m(pid=425132)[0m -----------------------
[2m[36m(pid=425132)[0m 
[2m[36m(pid=425132)[0m -----------------------
[2m[36m(pid=425132)[0m ring length: 518
[2m[36m(pid=425132)[0m v_max: 3.2596334266284783
[2m[36m(pid=425132)[0m -----------------------
[2m[36m(pid=425132)[0m 
[2m[36m(pid=425132)[0m -----------------------
[2m[36m(pid=425132)[0m ring length: 512
[2m[36m(pid=425132)[0m v_max: 3.139691674719026
[2m[36m(pid=425132)[0m -----------------------
[2m[36m(pid=425132)[0m 
[2m[36m(pid=425132)[0m -----------------------
[2m[36m(pid=425132)[0m ring length: 511
[2m[36m(pid=425132)[0m v_max: 3.1197006223865698
[2m[36m(pid=425132)[0m -----------------------
Result for PPO_WaveAttenuationPOEnv-v0_0:
  custom_metrics: {}
  date: 2020-03-30_10-31-10
  done: false
  episode_len_mean: 2000.0
  episode_reward_max: 4840.647108336213
  episode_reward_mean: 4436.508962821323
  episode_reward_min: 4032.558780893003
  episodes_this_iter: 5
  episodes_total: 395
  experiment_id: ba0edb931dde48dcb020df4b454540a2
  hostname: p0035.ten.osc.edu
  info:
    grad_time_ms: 215.876
    learner:
      default_policy:
        cur_kl_coeff: 7.450580707946131e-10
        cur_lr: 4.999999873689376e-05
        entropy: -0.010772829875349998
        entropy_coeff: 0.0
        kl: 0.00282121729105711
        policy_loss: -0.0007760051521472633
        total_loss: 4328.56982421875
        vf_explained_var: 1.7881393432617188e-07
        vf_loss: 4328.56982421875
    load_time_ms: 2.12
    num_steps_sampled: 790000
    num_steps_trained: 790000
    sample_time_ms: 100144.817
    update_time_ms: 2.069
  iterations_since_restore: 29
  node_ip: 10.4.1.36
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 2.6243055555555554
    ram_util_percent: 5.3999999999999995
  pid: 424867
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 6.897160852334634
    mean_inference_ms: 0.5484458858856249
    mean_processing_ms: 2.6214366646913527
  time_since_restore: 2928.4610085487366
  time_this_iter_s: 101.30182337760925
  time_total_s: 7969.2238891124725
  timestamp: 1585578670
  timesteps_since_restore: 290000
  timesteps_this_iter: 10000
  timesteps_total: 790000
  training_iteration: 79
  trial_id: fce6b7f4
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2/2 CPUs, 0/0 GPUs
Memory usage on this node: 10.9/201.2 GB
Result logdir: /users/PYS1027/chnrhughes/ray_results/simple_training_example_ring2_v1
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - PPO_WaveAttenuationPOEnv-v0_0:	RUNNING, 1 failures: /users/PYS1027/chnrhughes/ray_results/simple_training_example_ring2_v1/PPO_WaveAttenuationPOEnv-v0_0_2020-03-30_08-14-21aa4md2pi/error_2020-03-30_09-42-11.txt, [2 CPUs, 0 GPUs], [pid=424867], 7969 s, 79 iter, 790000 ts, 4.44e+03 rew

[2m[36m(pid=424867)[0m 2020-03-30 10:31:10,192	WARNING ppo.py:121 -- The magnitude of your environment rewards are more than 444.0x the scale of `vf_clip_param`. This means that it will take more than 444.0 iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.
[2m[36m(pid=425132)[0m 
[2m[36m(pid=425132)[0m -----------------------
[2m[36m(pid=425132)[0m ring length: 512
[2m[36m(pid=425132)[0m v_max: 3.139691674719026
[2m[36m(pid=425132)[0m -----------------------
[2m[36m(pid=425132)[0m 
[2m[36m(pid=425132)[0m -----------------------
[2m[36m(pid=425132)[0m ring length: 510
[2m[36m(pid=425132)[0m v_max: 3.0997093626421153
[2m[36m(pid=425132)[0m -----------------------
[2m[36m(pid=425132)[0m 
[2m[36m(pid=425132)[0m -----------------------
[2m[36m(pid=425132)[0m ring length: 503
[2m[36m(pid=425132)[0m v_max: 2.9597650335315784
[2m[36m(pid=425132)[0m -----------------------
[2m[36m(pid=425132)[0m 
[2m[36m(pid=425132)[0m -----------------------
[2m[36m(pid=425132)[0m ring length: 490
[2m[36m(pid=425132)[0m v_max: 2.699845849180192
[2m[36m(pid=425132)[0m -----------------------
[2m[36m(pid=425132)[0m 
[2m[36m(pid=425132)[0m -----------------------
[2m[36m(pid=425132)[0m ring length: 506
[2m[36m(pid=425132)[0m v_max: 3.0197423207835943
[2m[36m(pid=425132)[0m -----------------------
Result for PPO_WaveAttenuationPOEnv-v0_0:
  custom_metrics: {}
  date: 2020-03-30_10-32-51
  done: false
  episode_len_mean: 2000.0
  episode_reward_max: 4840.647108336213
  episode_reward_mean: 4443.755878889881
  episode_reward_min: 4032.558780893003
  episodes_this_iter: 5
  episodes_total: 400
  experiment_id: ba0edb931dde48dcb020df4b454540a2
  hostname: p0035.ten.osc.edu
  info:
    grad_time_ms: 215.844
    learner:
      default_policy:
        cur_kl_coeff: 3.7252903539730653e-10
        cur_lr: 4.999999873689376e-05
        entropy: -0.04280327633023262
        entropy_coeff: 0.0
        kl: 0.004942769650369883
        policy_loss: -0.0015627315733581781
        total_loss: 4134.408203125
        vf_explained_var: 0.0
        vf_loss: 4134.40869140625
    load_time_ms: 2.11
    num_steps_sampled: 800000
    num_steps_trained: 800000
    sample_time_ms: 100290.548
    update_time_ms: 2.06
  iterations_since_restore: 30
  node_ip: 10.4.1.36
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 2.6544827586206896
    ram_util_percent: 5.3999999999999995
  pid: 424867
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 6.895628744013598
    mean_inference_ms: 0.5473589638805701
    mean_processing_ms: 2.6214699763733393
  time_since_restore: 3029.9501953125
  time_this_iter_s: 101.48918676376343
  time_total_s: 8070.713075876236
  timestamp: 1585578771
  timesteps_since_restore: 300000
  timesteps_this_iter: 10000
  timesteps_total: 800000
  training_iteration: 80
  trial_id: fce6b7f4
  
[2m[36m(pid=424867)[0m 2020-03-30 10:32:51,690	WARNING ppo.py:121 -- The magnitude of your environment rewards are more than 444.0x the scale of `vf_clip_param`. This means that it will take more than 444.0 iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2/2 CPUs, 0/0 GPUs
Memory usage on this node: 10.9/201.2 GB
Result logdir: /users/PYS1027/chnrhughes/ray_results/simple_training_example_ring2_v1
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - PPO_WaveAttenuationPOEnv-v0_0:	RUNNING, 1 failures: /users/PYS1027/chnrhughes/ray_results/simple_training_example_ring2_v1/PPO_WaveAttenuationPOEnv-v0_0_2020-03-30_08-14-21aa4md2pi/error_2020-03-30_09-42-11.txt, [2 CPUs, 0 GPUs], [pid=424867], 8070 s, 80 iter, 800000 ts, 4.44e+03 rew

[2m[36m(pid=425132)[0m 
[2m[36m(pid=425132)[0m -----------------------
[2m[36m(pid=425132)[0m ring length: 514
[2m[36m(pid=425132)[0m v_max: 3.1796731425699525
[2m[36m(pid=425132)[0m -----------------------
[2m[36m(pid=425132)[0m 
[2m[36m(pid=425132)[0m -----------------------
[2m[36m(pid=425132)[0m ring length: 491
[2m[36m(pid=425132)[0m v_max: 2.719840556029452
[2m[36m(pid=425132)[0m -----------------------
[2m[36m(pid=425132)[0m 
[2m[36m(pid=425132)[0m -----------------------
[2m[36m(pid=425132)[0m ring length: 494
[2m[36m(pid=425132)[0m v_max: 2.7798238064662253
[2m[36m(pid=425132)[0m -----------------------
[2m[36m(pid=425132)[0m 
[2m[36m(pid=425132)[0m -----------------------
[2m[36m(pid=425132)[0m ring length: 490
[2m[36m(pid=425132)[0m v_max: 2.699845849180192
[2m[36m(pid=425132)[0m -----------------------
[2m[36m(pid=425132)[0m 
[2m[36m(pid=425132)[0m -----------------------
[2m[36m(pid=425132)[0m ring length: 502
[2m[36m(pid=425132)[0m v_max: 2.9397722404035362
[2m[36m(pid=425132)[0m -----------------------
Result for PPO_WaveAttenuationPOEnv-v0_0:
  custom_metrics: {}
  date: 2020-03-30_10-34-31
  done: false
  episode_len_mean: 2000.0
  episode_reward_max: 4840.647108336213
  episode_reward_mean: 4447.673522984605
  episode_reward_min: 4032.558780893003
  episodes_this_iter: 5
  episodes_total: 405
  experiment_id: ba0edb931dde48dcb020df4b454540a2
  hostname: p0035.ten.osc.edu
  info:
    grad_time_ms: 216.299
    learner:
      default_policy:
        cur_kl_coeff: 1.8626451769865326e-10
        cur_lr: 4.999999873689376e-05
        entropy: -0.06273004412651062
        entropy_coeff: 0.0
        kl: 0.0017529851756989956
        policy_loss: -0.0005462158005684614
        total_loss: 4005.1640625
        vf_explained_var: 0.0
        vf_loss: 4005.164794921875
    load_time_ms: 2.105
    num_steps_sampled: 810000
    num_steps_trained: 810000
    sample_time_ms: 100321.724
    update_time_ms: 2.054
  iterations_since_restore: 31
  node_ip: 10.4.1.36
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 2.604225352112676
    ram_util_percent: 5.399999999999998
  pid: 424867
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 6.89444494566716
    mean_inference_ms: 0.5463626736428017
    mean_processing_ms: 2.621555105615289
  time_since_restore: 3130.2122383117676
  time_this_iter_s: 100.26204299926758
  time_total_s: 8170.9751188755035
  timestamp: 1585578871
  timesteps_since_restore: 310000
  timesteps_this_iter: 10000
  timesteps_total: 810000
  training_iteration: 81
  trial_id: fce6b7f4
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2/2 CPUs, 0/0 GPUs
Memory usage on this node: 10.8/201.2 GB
Result logdir: /users/PYS1027/chnrhughes/ray_results/simple_training_example_ring2_v1
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - PPO_WaveAttenuationPOEnv-v0_0:	RUNNING, 1 failures: /users/PYS1027/chnrhughes/ray_results/simple_training_example_ring2_v1/PPO_WaveAttenuationPOEnv-v0_0_2020-03-30_08-14-21aa4md2pi/error_2020-03-30_09-42-11.txt, [2 CPUs, 0 GPUs], [pid=424867], 8170 s, 81 iter, 810000 ts, 4.45e+03 rew

[2m[36m(pid=424867)[0m 2020-03-30 10:34:31,993	WARNING ppo.py:121 -- The magnitude of your environment rewards are more than 445.0x the scale of `vf_clip_param`. This means that it will take more than 445.0 iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.
[2m[36m(pid=425132)[0m 
[2m[36m(pid=425132)[0m -----------------------
[2m[36m(pid=425132)[0m ring length: 517
[2m[36m(pid=425132)[0m v_max: 3.2396436965475437
[2m[36m(pid=425132)[0m -----------------------
[2m[36m(pid=425132)[0m 
[2m[36m(pid=425132)[0m -----------------------
[2m[36m(pid=425132)[0m ring length: 502
[2m[36m(pid=425132)[0m v_max: 2.9397722404035362
[2m[36m(pid=425132)[0m -----------------------
[2m[36m(pid=425132)[0m 
[2m[36m(pid=425132)[0m -----------------------
[2m[36m(pid=425132)[0m ring length: 516
[2m[36m(pid=425132)[0m v_max: 3.2196537366217006
[2m[36m(pid=425132)[0m -----------------------
[2m[36m(pid=425132)[0m 
[2m[36m(pid=425132)[0m -----------------------
[2m[36m(pid=425132)[0m ring length: 500
[2m[36m(pid=425132)[0m v_max: 2.8997861277614296
[2m[36m(pid=425132)[0m -----------------------
[2m[36m(pid=425132)[0m 
[2m[36m(pid=425132)[0m -----------------------
[2m[36m(pid=425132)[0m ring length: 490
[2m[36m(pid=425132)[0m v_max: 2.699845849180192
[2m[36m(pid=425132)[0m -----------------------
Result for PPO_WaveAttenuationPOEnv-v0_0:
  custom_metrics: {}
  date: 2020-03-30_10-36-12
  done: false
  episode_len_mean: 2000.0
  episode_reward_max: 4840.647108336213
  episode_reward_mean: 4463.482399183369
  episode_reward_min: 4032.558780893003
  episodes_this_iter: 5
  episodes_total: 410
  experiment_id: ba0edb931dde48dcb020df4b454540a2
  hostname: p0035.ten.osc.edu
  info:
    grad_time_ms: 217.479
    learner:
      default_policy:
        cur_kl_coeff: 9.313225884932663e-11
        cur_lr: 4.999999873689376e-05
        entropy: -0.08071288466453552
        entropy_coeff: 0.0
        kl: 0.00327999796718359
        policy_loss: -0.0007026508101262152
        total_loss: 4278.392578125
        vf_explained_var: 0.0
        vf_loss: 4278.3935546875
    load_time_ms: 2.052
    num_steps_sampled: 820000
    num_steps_trained: 820000
    sample_time_ms: 100328.642
    update_time_ms: 2.068
  iterations_since_restore: 32
  node_ip: 10.4.1.36
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 2.6611111111111114
    ram_util_percent: 5.3999999999999995
  pid: 424867
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 6.893548143220066
    mean_inference_ms: 0.5453319673495977
    mean_processing_ms: 2.6216237772860365
  time_since_restore: 3230.9364540576935
  time_this_iter_s: 100.7242157459259
  time_total_s: 8271.69933462143
  timestamp: 1585578972
  timesteps_since_restore: 320000
  timesteps_this_iter: 10000
  timesteps_total: 820000
  training_iteration: 82
  trial_id: fce6b7f4
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2/2 CPUs, 0/0 GPUs
Memory usage on this node: 10.8/201.2 GB
Result logdir: /users/PYS1027/chnrhughes/ray_results/simple_training_example_ring2_v1
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - PPO_WaveAttenuationPOEnv-v0_0:	RUNNING, 1 failures: /users/PYS1027/chnrhughes/ray_results/simple_training_example_ring2_v1/PPO_WaveAttenuationPOEnv-v0_0_2020-03-30_08-14-21aa4md2pi/error_2020-03-30_09-42-11.txt, [2 CPUs, 0 GPUs], [pid=424867], 8271 s, 82 iter, 820000 ts, 4.46e+03 rew

[2m[36m(pid=424867)[0m 2020-03-30 10:36:12,728	WARNING ppo.py:121 -- The magnitude of your environment rewards are more than 446.0x the scale of `vf_clip_param`. This means that it will take more than 446.0 iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.
[2m[36m(pid=425132)[0m 
[2m[36m(pid=425132)[0m -----------------------
[2m[36m(pid=425132)[0m ring length: 513
[2m[36m(pid=425132)[0m v_max: 3.1596825160053825
[2m[36m(pid=425132)[0m -----------------------
[2m[36m(pid=425132)[0m 
[2m[36m(pid=425132)[0m -----------------------
[2m[36m(pid=425132)[0m ring length: 491
[2m[36m(pid=425132)[0m v_max: 2.719840556029452
[2m[36m(pid=425132)[0m -----------------------
[2m[36m(pid=425132)[0m 
[2m[36m(pid=425132)[0m -----------------------
[2m[36m(pid=425132)[0m ring length: 498
[2m[36m(pid=425132)[0m v_max: 2.8597993346145016
[2m[36m(pid=425132)[0m -----------------------
[2m[36m(pid=425132)[0m 
[2m[36m(pid=425132)[0m -----------------------
[2m[36m(pid=425132)[0m ring length: 501
[2m[36m(pid=425132)[0m v_max: 2.919779270736568
[2m[36m(pid=425132)[0m -----------------------
[2m[36m(pid=425132)[0m 
[2m[36m(pid=425132)[0m -----------------------
[2m[36m(pid=425132)[0m ring length: 493
[2m[36m(pid=425132)[0m v_max: 2.759829537541262
[2m[36m(pid=425132)[0m -----------------------
Result for PPO_WaveAttenuationPOEnv-v0_0:
  custom_metrics: {}
  date: 2020-03-30_10-37-52
  done: false
  episode_len_mean: 2000.0
  episode_reward_max: 4840.647108336213
  episode_reward_mean: 4478.105534704245
  episode_reward_min: 4032.558780893003
  episodes_this_iter: 5
  episodes_total: 415
  experiment_id: ba0edb931dde48dcb020df4b454540a2
  hostname: p0035.ten.osc.edu
  info:
    grad_time_ms: 219.008
    learner:
      default_policy:
        cur_kl_coeff: 4.6566129424663316e-11
        cur_lr: 4.999999873689376e-05
        entropy: -0.10434543341398239
        entropy_coeff: 0.0
        kl: 0.0027836307417601347
        policy_loss: -0.0006732061156071723
        total_loss: 3983.919189453125
        vf_explained_var: 2.384185791015625e-07
        vf_loss: 3983.919189453125
    load_time_ms: 2.065
    num_steps_sampled: 830000
    num_steps_trained: 830000
    sample_time_ms: 100319.003
    update_time_ms: 2.041
  iterations_since_restore: 33
  node_ip: 10.4.1.36
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 2.638461538461538
    ram_util_percent: 5.399999999999999
  pid: 424867
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 6.892726370217655
    mean_inference_ms: 0.5442584023675394
    mean_processing_ms: 2.621622241181797
  time_since_restore: 3331.1409521102905
  time_this_iter_s: 100.20449805259705
  time_total_s: 8371.903832674026
  timestamp: 1585579072
  timesteps_since_restore: 330000
  timesteps_this_iter: 10000
  timesteps_total: 830000
  training_iteration: 83
  trial_id: fce6b7f4
  
[2m[36m(pid=424867)[0m 2020-03-30 10:37:52,941	WARNING ppo.py:121 -- The magnitude of your environment rewards are more than 448.0x the scale of `vf_clip_param`. This means that it will take more than 448.0 iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2/2 CPUs, 0/0 GPUs
Memory usage on this node: 10.8/201.2 GB
Result logdir: /users/PYS1027/chnrhughes/ray_results/simple_training_example_ring2_v1
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - PPO_WaveAttenuationPOEnv-v0_0:	RUNNING, 1 failures: /users/PYS1027/chnrhughes/ray_results/simple_training_example_ring2_v1/PPO_WaveAttenuationPOEnv-v0_0_2020-03-30_08-14-21aa4md2pi/error_2020-03-30_09-42-11.txt, [2 CPUs, 0 GPUs], [pid=424867], 8371 s, 83 iter, 830000 ts, 4.48e+03 rew

[2m[36m(pid=425132)[0m 
[2m[36m(pid=425132)[0m -----------------------
[2m[36m(pid=425132)[0m ring length: 508
[2m[36m(pid=425132)[0m v_max: 3.059726235247059
[2m[36m(pid=425132)[0m -----------------------
[2m[36m(pid=425132)[0m 
[2m[36m(pid=425132)[0m -----------------------
[2m[36m(pid=425132)[0m ring length: 491
[2m[36m(pid=425132)[0m v_max: 2.719840556029452
[2m[36m(pid=425132)[0m -----------------------
[2m[36m(pid=425132)[0m 
[2m[36m(pid=425132)[0m -----------------------
[2m[36m(pid=425132)[0m ring length: 493
[2m[36m(pid=425132)[0m v_max: 2.759829537541262
[2m[36m(pid=425132)[0m -----------------------
[2m[36m(pid=425132)[0m 
[2m[36m(pid=425132)[0m -----------------------
[2m[36m(pid=425132)[0m ring length: 492
[2m[36m(pid=425132)[0m v_max: 2.739835119766572
[2m[36m(pid=425132)[0m -----------------------
[2m[36m(pid=425132)[0m 
[2m[36m(pid=425132)[0m -----------------------
[2m[36m(pid=425132)[0m ring length: 503
[2m[36m(pid=425132)[0m v_max: 2.9597650335315784
[2m[36m(pid=425132)[0m -----------------------
Result for PPO_WaveAttenuationPOEnv-v0_0:
  custom_metrics: {}
  date: 2020-03-30_10-39-32
  done: false
  episode_len_mean: 2000.0
  episode_reward_max: 4840.647108336213
  episode_reward_mean: 4491.945553088224
  episode_reward_min: 4032.558780893003
  episodes_this_iter: 5
  episodes_total: 420
  experiment_id: ba0edb931dde48dcb020df4b454540a2
  hostname: p0035.ten.osc.edu
  info:
    grad_time_ms: 220.488
    learner:
      default_policy:
        cur_kl_coeff: 2.3283064712331658e-11
        cur_lr: 4.999999873689376e-05
        entropy: -0.13711780309677124
        entropy_coeff: 0.0
        kl: 0.004339553881436586
        policy_loss: -0.00131503539159894
        total_loss: 3952.654052734375
        vf_explained_var: 1.1920928955078125e-07
        vf_loss: 3952.6552734375
    load_time_ms: 2.129
    num_steps_sampled: 840000
    num_steps_trained: 840000
    sample_time_ms: 100338.483
    update_time_ms: 2.039
  iterations_since_restore: 34
  node_ip: 10.4.1.36
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 2.6161971830985915
    ram_util_percent: 5.399999999999998
  pid: 424867
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 6.891694027460646
    mean_inference_ms: 0.5430922326996847
    mean_processing_ms: 2.6214981283059875
  time_since_restore: 3430.946659564972
  time_this_iter_s: 99.8057074546814
  time_total_s: 8471.709540128708
  timestamp: 1585579172
  timesteps_since_restore: 340000
  timesteps_this_iter: 10000
  timesteps_total: 840000
  training_iteration: 84
  trial_id: fce6b7f4
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2/2 CPUs, 0/0 GPUs
Memory usage on this node: 10.8/201.2 GB
Result logdir: /users/PYS1027/chnrhughes/ray_results/simple_training_example_ring2_v1
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - PPO_WaveAttenuationPOEnv-v0_0:	RUNNING, 1 failures: /users/PYS1027/chnrhughes/ray_results/simple_training_example_ring2_v1/PPO_WaveAttenuationPOEnv-v0_0_2020-03-30_08-14-21aa4md2pi/error_2020-03-30_09-42-11.txt, [2 CPUs, 0 GPUs], [pid=424867], 8471 s, 84 iter, 840000 ts, 4.49e+03 rew

[2m[36m(pid=424867)[0m 2020-03-30 10:39:32,766	WARNING ppo.py:121 -- The magnitude of your environment rewards are more than 449.0x the scale of `vf_clip_param`. This means that it will take more than 449.0 iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.
[2m[36m(pid=425132)[0m 
[2m[36m(pid=425132)[0m -----------------------
[2m[36m(pid=425132)[0m ring length: 499
[2m[36m(pid=425132)[0m v_max: 2.8797928146697993
[2m[36m(pid=425132)[0m -----------------------
[2m[36m(pid=425132)[0m 
[2m[36m(pid=425132)[0m -----------------------
[2m[36m(pid=425132)[0m ring length: 520
[2m[36m(pid=425132)[0m v_max: 3.2996121816646764
[2m[36m(pid=425132)[0m -----------------------
[2m[36m(pid=425132)[0m 
[2m[36m(pid=425132)[0m -----------------------
[2m[36m(pid=425132)[0m ring length: 515
[2m[36m(pid=425132)[0m v_max: 3.199663550695237
[2m[36m(pid=425132)[0m -----------------------
[2m[36m(pid=425132)[0m 
[2m[36m(pid=425132)[0m -----------------------
[2m[36m(pid=425132)[0m ring length: 502
[2m[36m(pid=425132)[0m v_max: 2.9397722404035362
[2m[36m(pid=425132)[0m -----------------------
[2m[36m(pid=425132)[0m 
[2m[36m(pid=425132)[0m -----------------------
[2m[36m(pid=425132)[0m ring length: 504
[2m[36m(pid=425132)[0m v_max: 2.979757646850631
[2m[36m(pid=425132)[0m -----------------------
Result for PPO_WaveAttenuationPOEnv-v0_0:
  custom_metrics: {}
  date: 2020-03-30_10-41-12
  done: false
  episode_len_mean: 2000.0
  episode_reward_max: 4840.647108336213
  episode_reward_mean: 4516.518661371962
  episode_reward_min: 4056.3964828541866
  episodes_this_iter: 5
  episodes_total: 425
  experiment_id: ba0edb931dde48dcb020df4b454540a2
  hostname: p0035.ten.osc.edu
  info:
    grad_time_ms: 221.442
    learner:
      default_policy:
        cur_kl_coeff: 1.1641532356165829e-11
        cur_lr: 4.999999873689376e-05
        entropy: -0.15795791149139404
        entropy_coeff: 0.0
        kl: 0.00239715538918972
        policy_loss: -0.0005361553048714995
        total_loss: 4316.16259765625
        vf_explained_var: 0.0
        vf_loss: 4316.1630859375
    load_time_ms: 2.128
    num_steps_sampled: 850000
    num_steps_trained: 850000
    sample_time_ms: 100264.946
    update_time_ms: 2.053
  iterations_since_restore: 35
  node_ip: 10.4.1.36
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 2.5999999999999996
    ram_util_percent: 5.399999999999998
  pid: 424867
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 6.890715728320745
    mean_inference_ms: 0.5418011013119833
    mean_processing_ms: 2.6212976820878917
  time_since_restore: 3530.7869534492493
  time_this_iter_s: 99.84029388427734
  time_total_s: 8571.549834012985
  timestamp: 1585579272
  timesteps_since_restore: 350000
  timesteps_this_iter: 10000
  timesteps_total: 850000
  training_iteration: 85
  trial_id: fce6b7f4
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2/2 CPUs, 0/0 GPUs
Memory usage on this node: 10.8/201.2 GB
Result logdir: /users/PYS1027/chnrhughes/ray_results/simple_training_example_ring2_v1
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - PPO_WaveAttenuationPOEnv-v0_0:	RUNNING, 1 failures: /users/PYS1027/chnrhughes/ray_results/simple_training_example_ring2_v1/PPO_WaveAttenuationPOEnv-v0_0_2020-03-30_08-14-21aa4md2pi/error_2020-03-30_09-42-11.txt, [2 CPUs, 0 GPUs], [pid=424867], 8571 s, 85 iter, 850000 ts, 4.52e+03 rew

[2m[36m(pid=424867)[0m 2020-03-30 10:41:12,616	WARNING ppo.py:121 -- The magnitude of your environment rewards are more than 452.0x the scale of `vf_clip_param`. This means that it will take more than 452.0 iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.
[2m[36m(pid=425132)[0m 
[2m[36m(pid=425132)[0m -----------------------
[2m[36m(pid=425132)[0m ring length: 493
[2m[36m(pid=425132)[0m v_max: 2.759829537541262
[2m[36m(pid=425132)[0m -----------------------
[2m[36m(pid=425132)[0m 
[2m[36m(pid=425132)[0m -----------------------
[2m[36m(pid=425132)[0m ring length: 492
[2m[36m(pid=425132)[0m v_max: 2.739835119766572
[2m[36m(pid=425132)[0m -----------------------
[2m[36m(pid=425132)[0m 
[2m[36m(pid=425132)[0m -----------------------
[2m[36m(pid=425132)[0m ring length: 493
[2m[36m(pid=425132)[0m v_max: 2.759829537541262
[2m[36m(pid=425132)[0m -----------------------
[2m[36m(pid=425132)[0m 
[2m[36m(pid=425132)[0m -----------------------
[2m[36m(pid=425132)[0m ring length: 515
[2m[36m(pid=425132)[0m v_max: 3.199663550695237
[2m[36m(pid=425132)[0m -----------------------
[2m[36m(pid=425132)[0m 
[2m[36m(pid=425132)[0m -----------------------
[2m[36m(pid=425132)[0m ring length: 509
[2m[36m(pid=425132)[0m v_max: 3.0797178990784078
[2m[36m(pid=425132)[0m -----------------------
Result for PPO_WaveAttenuationPOEnv-v0_0:
  custom_metrics: {}
  date: 2020-03-30_10-42-52
  done: false
  episode_len_mean: 2000.0
  episode_reward_max: 4840.647108336213
  episode_reward_mean: 4520.911696492263
  episode_reward_min: 4056.3964828541866
  episodes_this_iter: 5
  episodes_total: 430
  experiment_id: ba0edb931dde48dcb020df4b454540a2
  hostname: p0035.ten.osc.edu
  info:
    grad_time_ms: 220.883
    learner:
      default_policy:
        cur_kl_coeff: 5.8207661780829145e-12
        cur_lr: 4.999999873689376e-05
        entropy: -0.17568466067314148
        entropy_coeff: 0.0
        kl: 0.0032745650969445705
        policy_loss: -0.0005585715989582241
        total_loss: 4059.76708984375
        vf_explained_var: 2.384185791015625e-07
        vf_loss: 4059.76806640625
    load_time_ms: 2.118
    num_steps_sampled: 860000
    num_steps_trained: 860000
    sample_time_ms: 100211.798
    update_time_ms: 2.055
  iterations_since_restore: 36
  node_ip: 10.4.1.36
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 2.6795774647887325
    ram_util_percent: 5.399999999999998
  pid: 424867
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 6.889904428874611
    mean_inference_ms: 0.5403565316456074
    mean_processing_ms: 2.6211203861458756
  time_since_restore: 3630.565102815628
  time_this_iter_s: 99.77814936637878
  time_total_s: 8671.327983379364
  timestamp: 1585579372
  timesteps_since_restore: 360000
  timesteps_this_iter: 10000
  timesteps_total: 860000
  training_iteration: 86
  trial_id: fce6b7f4
  
[2m[36m(pid=424867)[0m 2020-03-30 10:42:52,415	WARNING ppo.py:121 -- The magnitude of your environment rewards are more than 452.0x the scale of `vf_clip_param`. This means that it will take more than 452.0 iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2/2 CPUs, 0/0 GPUs
Memory usage on this node: 10.8/201.2 GB
Result logdir: /users/PYS1027/chnrhughes/ray_results/simple_training_example_ring2_v1
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - PPO_WaveAttenuationPOEnv-v0_0:	RUNNING, 1 failures: /users/PYS1027/chnrhughes/ray_results/simple_training_example_ring2_v1/PPO_WaveAttenuationPOEnv-v0_0_2020-03-30_08-14-21aa4md2pi/error_2020-03-30_09-42-11.txt, [2 CPUs, 0 GPUs], [pid=424867], 8671 s, 86 iter, 860000 ts, 4.52e+03 rew

[2m[36m(pid=425132)[0m 
[2m[36m(pid=425132)[0m -----------------------
[2m[36m(pid=425132)[0m ring length: 505
[2m[36m(pid=425132)[0m v_max: 2.999750077051092
[2m[36m(pid=425132)[0m -----------------------
[2m[36m(pid=425132)[0m 
[2m[36m(pid=425132)[0m -----------------------
[2m[36m(pid=425132)[0m ring length: 506
[2m[36m(pid=425132)[0m v_max: 3.0197423207835943
[2m[36m(pid=425132)[0m -----------------------
[2m[36m(pid=425132)[0m 
[2m[36m(pid=425132)[0m -----------------------
[2m[36m(pid=425132)[0m ring length: 501
[2m[36m(pid=425132)[0m v_max: 2.919779270736568
[2m[36m(pid=425132)[0m -----------------------
[2m[36m(pid=425132)[0m 
[2m[36m(pid=425132)[0m -----------------------
[2m[36m(pid=425132)[0m ring length: 513
[2m[36m(pid=425132)[0m v_max: 3.1596825160053825
[2m[36m(pid=425132)[0m -----------------------
[2m[36m(pid=425132)[0m 
[2m[36m(pid=425132)[0m -----------------------
[2m[36m(pid=425132)[0m ring length: 515
[2m[36m(pid=425132)[0m v_max: 3.199663550695237
[2m[36m(pid=425132)[0m -----------------------
Result for PPO_WaveAttenuationPOEnv-v0_0:
  custom_metrics: {}
  date: 2020-03-30_10-44-32
  done: false
  episode_len_mean: 2000.0
  episode_reward_max: 4840.647108336213
  episode_reward_mean: 4541.617714342079
  episode_reward_min: 4056.3964828541866
  episodes_this_iter: 5
  episodes_total: 435
  experiment_id: ba0edb931dde48dcb020df4b454540a2
  hostname: p0035.ten.osc.edu
  info:
    grad_time_ms: 220.154
    learner:
      default_policy:
        cur_kl_coeff: 2.9103830890414573e-12
        cur_lr: 4.999999873689376e-05
        entropy: -0.18187831342220306
        entropy_coeff: 0.0
        kl: 0.009342090226709843
        policy_loss: -0.001472820295020938
        total_loss: 4279.3017578125
        vf_explained_var: 0.0
        vf_loss: 4279.3037109375
    load_time_ms: 2.118
    num_steps_sampled: 870000
    num_steps_trained: 870000
    sample_time_ms: 100167.913
    update_time_ms: 2.046
  iterations_since_restore: 37
  node_ip: 10.4.1.36
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 2.6225352112676057
    ram_util_percent: 5.399999999999998
  pid: 424867
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 6.889265130484364
    mean_inference_ms: 0.538833937120819
    mean_processing_ms: 2.6209920314307675
  time_since_restore: 3730.702395439148
  time_this_iter_s: 100.1372926235199
  time_total_s: 8771.465276002884
  timestamp: 1585579472
  timesteps_since_restore: 370000
  timesteps_this_iter: 10000
  timesteps_total: 870000
  training_iteration: 87
  trial_id: fce6b7f4
  
[2m[36m(pid=424867)[0m 2020-03-30 10:44:32,563	WARNING ppo.py:121 -- The magnitude of your environment rewards are more than 454.0x the scale of `vf_clip_param`. This means that it will take more than 454.0 iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2/2 CPUs, 0/0 GPUs
Memory usage on this node: 10.9/201.2 GB
Result logdir: /users/PYS1027/chnrhughes/ray_results/simple_training_example_ring2_v1
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - PPO_WaveAttenuationPOEnv-v0_0:	RUNNING, 1 failures: /users/PYS1027/chnrhughes/ray_results/simple_training_example_ring2_v1/PPO_WaveAttenuationPOEnv-v0_0_2020-03-30_08-14-21aa4md2pi/error_2020-03-30_09-42-11.txt, [2 CPUs, 0 GPUs], [pid=424867], 8771 s, 87 iter, 870000 ts, 4.54e+03 rew

[2m[36m(pid=425132)[0m 
[2m[36m(pid=425132)[0m -----------------------
[2m[36m(pid=425132)[0m ring length: 518
[2m[36m(pid=425132)[0m v_max: 3.2596334266284783
[2m[36m(pid=425132)[0m -----------------------
[2m[36m(pid=425132)[0m 
[2m[36m(pid=425132)[0m -----------------------
[2m[36m(pid=425132)[0m ring length: 508
[2m[36m(pid=425132)[0m v_max: 3.059726235247059
[2m[36m(pid=425132)[0m -----------------------
[2m[36m(pid=425132)[0m 
[2m[36m(pid=425132)[0m -----------------------
[2m[36m(pid=425132)[0m ring length: 491
[2m[36m(pid=425132)[0m v_max: 2.719840556029452
[2m[36m(pid=425132)[0m -----------------------
[2m[36m(pid=425132)[0m 
[2m[36m(pid=425132)[0m -----------------------
[2m[36m(pid=425132)[0m ring length: 494
[2m[36m(pid=425132)[0m v_max: 2.7798238064662253
[2m[36m(pid=425132)[0m -----------------------
[2m[36m(pid=425132)[0m 
[2m[36m(pid=425132)[0m -----------------------
[2m[36m(pid=425132)[0m ring length: 506
[2m[36m(pid=425132)[0m v_max: 3.0197423207835943
[2m[36m(pid=425132)[0m -----------------------
Result for PPO_WaveAttenuationPOEnv-v0_0:
  custom_metrics: {}
  date: 2020-03-30_10-46-12
  done: false
  episode_len_mean: 2000.0
  episode_reward_max: 4926.46371924862
  episode_reward_mean: 4555.349082874565
  episode_reward_min: 4056.3964828541866
  episodes_this_iter: 5
  episodes_total: 440
  experiment_id: ba0edb931dde48dcb020df4b454540a2
  hostname: p0035.ten.osc.edu
  info:
    grad_time_ms: 219.296
    learner:
      default_policy:
        cur_kl_coeff: 1.4551915445207286e-12
        cur_lr: 4.999999873689376e-05
        entropy: -0.18819139897823334
        entropy_coeff: 0.0
        kl: 0.010180167853832245
        policy_loss: -0.0017160808201879263
        total_loss: 4363.3818359375
        vf_explained_var: 2.980232238769531e-07
        vf_loss: 4363.3837890625
    load_time_ms: 2.024
    num_steps_sampled: 880000
    num_steps_trained: 880000
    sample_time_ms: 100128.604
    update_time_ms: 2.04
  iterations_since_restore: 38
  node_ip: 10.4.1.36
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 2.6370629370629364
    ram_util_percent: 5.399999999999999
  pid: 424867
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 6.888776612271366
    mean_inference_ms: 0.5372922994543299
    mean_processing_ms: 2.620793838404156
  time_since_restore: 3830.741595506668
  time_this_iter_s: 100.03920006752014
  time_total_s: 8871.504476070404
  timestamp: 1585579572
  timesteps_since_restore: 380000
  timesteps_this_iter: 10000
  timesteps_total: 880000
  training_iteration: 88
  trial_id: fce6b7f4
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2/2 CPUs, 0/0 GPUs
Memory usage on this node: 10.9/201.2 GB
Result logdir: /users/PYS1027/chnrhughes/ray_results/simple_training_example_ring2_v1
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - PPO_WaveAttenuationPOEnv-v0_0:	RUNNING, 1 failures: /users/PYS1027/chnrhughes/ray_results/simple_training_example_ring2_v1/PPO_WaveAttenuationPOEnv-v0_0_2020-03-30_08-14-21aa4md2pi/error_2020-03-30_09-42-11.txt, [2 CPUs, 0 GPUs], [pid=424867], 8871 s, 88 iter, 880000 ts, 4.56e+03 rew

[2m[36m(pid=424867)[0m 2020-03-30 10:46:12,612	WARNING ppo.py:121 -- The magnitude of your environment rewards are more than 456.0x the scale of `vf_clip_param`. This means that it will take more than 456.0 iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.
[2m[36m(pid=425132)[0m 
[2m[36m(pid=425132)[0m -----------------------
[2m[36m(pid=425132)[0m ring length: 515
[2m[36m(pid=425132)[0m v_max: 3.199663550695237
[2m[36m(pid=425132)[0m -----------------------
[2m[36m(pid=425132)[0m 
[2m[36m(pid=425132)[0m -----------------------
[2m[36m(pid=425132)[0m ring length: 492
[2m[36m(pid=425132)[0m v_max: 2.739835119766572
[2m[36m(pid=425132)[0m -----------------------
[2m[36m(pid=425132)[0m 
[2m[36m(pid=425132)[0m -----------------------
[2m[36m(pid=425132)[0m ring length: 505
[2m[36m(pid=425132)[0m v_max: 2.999750077051092
[2m[36m(pid=425132)[0m -----------------------
[2m[36m(pid=425132)[0m 
[2m[36m(pid=425132)[0m -----------------------
[2m[36m(pid=425132)[0m ring length: 493
[2m[36m(pid=425132)[0m v_max: 2.759829537541262
[2m[36m(pid=425132)[0m -----------------------
[2m[36m(pid=425132)[0m 
[2m[36m(pid=425132)[0m -----------------------
[2m[36m(pid=425132)[0m ring length: 517
[2m[36m(pid=425132)[0m v_max: 3.2396436965475437
[2m[36m(pid=425132)[0m -----------------------
Result for PPO_WaveAttenuationPOEnv-v0_0:
  custom_metrics: {}
  date: 2020-03-30_10-47-52
  done: false
  episode_len_mean: 2000.0
  episode_reward_max: 4926.46371924862
  episode_reward_mean: 4576.585376188261
  episode_reward_min: 4349.858819737117
  episodes_this_iter: 5
  episodes_total: 445
  experiment_id: ba0edb931dde48dcb020df4b454540a2
  hostname: p0035.ten.osc.edu
  info:
    grad_time_ms: 218.665
    learner:
      default_policy:
        cur_kl_coeff: 1.4551915445207286e-12
        cur_lr: 4.999999873689376e-05
        entropy: -0.19268471002578735
        entropy_coeff: 0.0
        kl: 0.0068763610906898975
        policy_loss: -0.0010144797852262855
        total_loss: 4326.89453125
        vf_explained_var: 0.0
        vf_loss: 4326.8955078125
    load_time_ms: 1.954
    num_steps_sampled: 890000
    num_steps_trained: 890000
    sample_time_ms: 100000.019
    update_time_ms: 2.019
  iterations_since_restore: 39
  node_ip: 10.4.1.36
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 2.6725352112676055
    ram_util_percent: 5.399999999999998
  pid: 424867
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 6.888355558644448
    mean_inference_ms: 0.5359981557464848
    mean_processing_ms: 2.6205932553556317
  time_since_restore: 3930.74947309494
  time_this_iter_s: 100.0078775882721
  time_total_s: 8971.512353658676
  timestamp: 1585579672
  timesteps_since_restore: 390000
  timesteps_this_iter: 10000
  timesteps_total: 890000
  training_iteration: 89
  trial_id: fce6b7f4
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2/2 CPUs, 0/0 GPUs
Memory usage on this node: 10.8/201.2 GB
Result logdir: /users/PYS1027/chnrhughes/ray_results/simple_training_example_ring2_v1
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - PPO_WaveAttenuationPOEnv-v0_0:	RUNNING, 1 failures: /users/PYS1027/chnrhughes/ray_results/simple_training_example_ring2_v1/PPO_WaveAttenuationPOEnv-v0_0_2020-03-30_08-14-21aa4md2pi/error_2020-03-30_09-42-11.txt, [2 CPUs, 0 GPUs], [pid=424867], 8971 s, 89 iter, 890000 ts, 4.58e+03 rew

[2m[36m(pid=424867)[0m 2020-03-30 10:47:52,628	WARNING ppo.py:121 -- The magnitude of your environment rewards are more than 458.0x the scale of `vf_clip_param`. This means that it will take more than 458.0 iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.
[2m[36m(pid=425132)[0m 
[2m[36m(pid=425132)[0m -----------------------
[2m[36m(pid=425132)[0m ring length: 508
[2m[36m(pid=425132)[0m v_max: 3.059726235247059
[2m[36m(pid=425132)[0m -----------------------
[2m[36m(pid=425132)[0m 
[2m[36m(pid=425132)[0m -----------------------
[2m[36m(pid=425132)[0m ring length: 507
[2m[36m(pid=425132)[0m v_max: 3.0397343746587766
[2m[36m(pid=425132)[0m -----------------------
[2m[36m(pid=425132)[0m 
[2m[36m(pid=425132)[0m -----------------------
[2m[36m(pid=425132)[0m ring length: 515
[2m[36m(pid=425132)[0m v_max: 3.199663550695237
[2m[36m(pid=425132)[0m -----------------------
[2m[36m(pid=425132)[0m 
[2m[36m(pid=425132)[0m -----------------------
[2m[36m(pid=425132)[0m ring length: 492
[2m[36m(pid=425132)[0m v_max: 2.739835119766572
[2m[36m(pid=425132)[0m -----------------------
[2m[36m(pid=425132)[0m 
[2m[36m(pid=425132)[0m -----------------------
[2m[36m(pid=425132)[0m ring length: 508
[2m[36m(pid=425132)[0m v_max: 3.059726235247059
[2m[36m(pid=425132)[0m -----------------------
Result for PPO_WaveAttenuationPOEnv-v0_0:
  custom_metrics: {}
  date: 2020-03-30_10-49-33
  done: false
  episode_len_mean: 2000.0
  episode_reward_max: 4926.46371924862
  episode_reward_mean: 4592.1928635535405
  episode_reward_min: 4351.814508430616
  episodes_this_iter: 5
  episodes_total: 450
  experiment_id: ba0edb931dde48dcb020df4b454540a2
  hostname: p0035.ten.osc.edu
  info:
    grad_time_ms: 218.967
    learner:
      default_policy:
        cur_kl_coeff: 7.275957722603643e-13
        cur_lr: 4.999999873689376e-05
        entropy: -0.21026144921779633
        entropy_coeff: 0.0
        kl: 0.0019036247394979
        policy_loss: -0.0005746898823417723
        total_loss: 4486.82080078125
        vf_explained_var: 1.1920928955078125e-07
        vf_loss: 4486.82177734375
    load_time_ms: 1.95
    num_steps_sampled: 900000
    num_steps_trained: 900000
    sample_time_ms: 99948.893
    update_time_ms: 2.001
  iterations_since_restore: 40
  node_ip: 10.4.1.36
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 2.6284722222222223
    ram_util_percent: 5.3999999999999995
  pid: 424867
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 6.888034550745811
    mean_inference_ms: 0.5348929712931546
    mean_processing_ms: 2.6203951747385292
  time_since_restore: 4031.730354785919
  time_this_iter_s: 100.980881690979
  time_total_s: 9072.493235349655
  timestamp: 1585579773
  timesteps_since_restore: 400000
  timesteps_this_iter: 10000
  timesteps_total: 900000
  training_iteration: 90
  trial_id: fce6b7f4
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2/2 CPUs, 0/0 GPUs
Memory usage on this node: 10.8/201.2 GB
Result logdir: /users/PYS1027/chnrhughes/ray_results/simple_training_example_ring2_v1
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - PPO_WaveAttenuationPOEnv-v0_0:	RUNNING, 1 failures: /users/PYS1027/chnrhughes/ray_results/simple_training_example_ring2_v1/PPO_WaveAttenuationPOEnv-v0_0_2020-03-30_08-14-21aa4md2pi/error_2020-03-30_09-42-11.txt, [2 CPUs, 0 GPUs], [pid=424867], 9072 s, 90 iter, 900000 ts, 4.59e+03 rew

[2m[36m(pid=424867)[0m 2020-03-30 10:49:33,618	WARNING ppo.py:121 -- The magnitude of your environment rewards are more than 459.0x the scale of `vf_clip_param`. This means that it will take more than 459.0 iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.
[2m[36m(pid=425132)[0m 
[2m[36m(pid=425132)[0m -----------------------
[2m[36m(pid=425132)[0m ring length: 507
[2m[36m(pid=425132)[0m v_max: 3.0397343746587766
[2m[36m(pid=425132)[0m -----------------------
[2m[36m(pid=425132)[0m 
[2m[36m(pid=425132)[0m -----------------------
[2m[36m(pid=425132)[0m ring length: 498
[2m[36m(pid=425132)[0m v_max: 2.8597993346145016
[2m[36m(pid=425132)[0m -----------------------
[2m[36m(pid=425132)[0m 
[2m[36m(pid=425132)[0m -----------------------
[2m[36m(pid=425132)[0m ring length: 505
[2m[36m(pid=425132)[0m v_max: 2.999750077051092
[2m[36m(pid=425132)[0m -----------------------
[2m[36m(pid=425132)[0m 
[2m[36m(pid=425132)[0m -----------------------
[2m[36m(pid=425132)[0m ring length: 503
[2m[36m(pid=425132)[0m v_max: 2.9597650335315784
[2m[36m(pid=425132)[0m -----------------------
[2m[36m(pid=425132)[0m 
[2m[36m(pid=425132)[0m -----------------------
[2m[36m(pid=425132)[0m ring length: 519
[2m[36m(pid=425132)[0m v_max: 3.2796229229775036
[2m[36m(pid=425132)[0m -----------------------
Result for PPO_WaveAttenuationPOEnv-v0_0:
  custom_metrics: {}
  date: 2020-03-30_10-51-14
  done: false
  episode_len_mean: 2000.0
  episode_reward_max: 4926.46371924862
  episode_reward_mean: 4602.680341322059
  episode_reward_min: 4351.814508430616
  episodes_this_iter: 5
  episodes_total: 455
  experiment_id: ba0edb931dde48dcb020df4b454540a2
  hostname: p0035.ten.osc.edu
  info:
    grad_time_ms: 219.227
    learner:
      default_policy:
        cur_kl_coeff: 3.6379788613018216e-13
        cur_lr: 4.999999873689376e-05
        entropy: -0.21822324395179749
        entropy_coeff: 0.0
        kl: 0.005681825801730156
        policy_loss: -0.0005006298306398094
        total_loss: 4394.75341796875
        vf_explained_var: 0.0
        vf_loss: 4394.75244140625
    load_time_ms: 1.939
    num_steps_sampled: 910000
    num_steps_trained: 910000
    sample_time_ms: 99978.213
    update_time_ms: 2.0
  iterations_since_restore: 41
  node_ip: 10.4.1.36
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 2.6279720279720276
    ram_util_percent: 5.399999999999999
  pid: 424867
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 6.88787711646773
    mean_inference_ms: 0.533858009335762
    mean_processing_ms: 2.620198306629574
  time_since_restore: 4132.287025690079
  time_this_iter_s: 100.55667090415955
  time_total_s: 9173.049906253815
  timestamp: 1585579874
  timesteps_since_restore: 410000
  timesteps_this_iter: 10000
  timesteps_total: 910000
  training_iteration: 91
  trial_id: fce6b7f4
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2/2 CPUs, 0/0 GPUs
Memory usage on this node: 10.8/201.2 GB
Result logdir: /users/PYS1027/chnrhughes/ray_results/simple_training_example_ring2_v1
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - PPO_WaveAttenuationPOEnv-v0_0:	RUNNING, 1 failures: /users/PYS1027/chnrhughes/ray_results/simple_training_example_ring2_v1/PPO_WaveAttenuationPOEnv-v0_0_2020-03-30_08-14-21aa4md2pi/error_2020-03-30_09-42-11.txt, [2 CPUs, 0 GPUs], [pid=424867], 9173 s, 91 iter, 910000 ts, 4.6e+03 rew

[2m[36m(pid=424867)[0m 2020-03-30 10:51:14,197	WARNING ppo.py:121 -- The magnitude of your environment rewards are more than 460.0x the scale of `vf_clip_param`. This means that it will take more than 460.0 iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.
[2m[36m(pid=425132)[0m 
[2m[36m(pid=425132)[0m -----------------------
[2m[36m(pid=425132)[0m ring length: 506
[2m[36m(pid=425132)[0m v_max: 3.0197423207835943
[2m[36m(pid=425132)[0m -----------------------
[2m[36m(pid=425132)[0m 
[2m[36m(pid=425132)[0m -----------------------
[2m[36m(pid=425132)[0m ring length: 493
[2m[36m(pid=425132)[0m v_max: 2.759829537541262
[2m[36m(pid=425132)[0m -----------------------
[2m[36m(pid=425132)[0m 
[2m[36m(pid=425132)[0m -----------------------
[2m[36m(pid=425132)[0m ring length: 520
[2m[36m(pid=425132)[0m v_max: 3.2996121816646764
[2m[36m(pid=425132)[0m -----------------------
[2m[36m(pid=425132)[0m 
[2m[36m(pid=425132)[0m -----------------------
[2m[36m(pid=425132)[0m ring length: 496
[2m[36m(pid=425132)[0m v_max: 2.819811886031332
[2m[36m(pid=425132)[0m -----------------------
[2m[36m(pid=425132)[0m 
[2m[36m(pid=425132)[0m -----------------------
[2m[36m(pid=425132)[0m ring length: 493
[2m[36m(pid=425132)[0m v_max: 2.759829537541262
[2m[36m(pid=425132)[0m -----------------------
Result for PPO_WaveAttenuationPOEnv-v0_0:
  custom_metrics: {}
  date: 2020-03-30_10-52-54
  done: false
  episode_len_mean: 2000.0
  episode_reward_max: 4949.432659911163
  episode_reward_mean: 4614.583039828594
  episode_reward_min: 4351.814508430616
  episodes_this_iter: 5
  episodes_total: 460
  experiment_id: ba0edb931dde48dcb020df4b454540a2
  hostname: p0035.ten.osc.edu
  info:
    grad_time_ms: 219.856
    learner:
      default_policy:
        cur_kl_coeff: 1.8189894306509108e-13
        cur_lr: 4.999999873689376e-05
        entropy: -0.2525700330734253
        entropy_coeff: 0.0
        kl: 0.005214361008256674
        policy_loss: -0.001649361802265048
        total_loss: 4469.62255859375
        vf_explained_var: 1.1920928955078125e-07
        vf_loss: 4469.625
    load_time_ms: 1.928
    num_steps_sampled: 920000
    num_steps_trained: 920000
    sample_time_ms: 99966.649
    update_time_ms: 1.999
  iterations_since_restore: 42
  node_ip: 10.4.1.36
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 2.654861111111111
    ram_util_percent: 5.3999999999999995
  pid: 424867
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 6.887709367729939
    mean_inference_ms: 0.5328903688867997
    mean_processing_ms: 2.6200031412610385
  time_since_restore: 4232.9032554626465
  time_this_iter_s: 100.61622977256775
  time_total_s: 9273.666136026382
  timestamp: 1585579974
  timesteps_since_restore: 420000
  timesteps_this_iter: 10000
  timesteps_total: 920000
  training_iteration: 92
  trial_id: fce6b7f4
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2/2 CPUs, 0/0 GPUs
Memory usage on this node: 10.8/201.2 GB
Result logdir: /users/PYS1027/chnrhughes/ray_results/simple_training_example_ring2_v1
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - PPO_WaveAttenuationPOEnv-v0_0:	RUNNING, 1 failures: /users/PYS1027/chnrhughes/ray_results/simple_training_example_ring2_v1/PPO_WaveAttenuationPOEnv-v0_0_2020-03-30_08-14-21aa4md2pi/error_2020-03-30_09-42-11.txt, [2 CPUs, 0 GPUs], [pid=424867], 9273 s, 92 iter, 920000 ts, 4.61e+03 rew

[2m[36m(pid=424867)[0m 2020-03-30 10:52:54,822	WARNING ppo.py:121 -- The magnitude of your environment rewards are more than 461.0x the scale of `vf_clip_param`. This means that it will take more than 461.0 iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.
[2m[36m(pid=425132)[0m 
[2m[36m(pid=425132)[0m -----------------------
[2m[36m(pid=425132)[0m ring length: 505
[2m[36m(pid=425132)[0m v_max: 2.999750077051092
[2m[36m(pid=425132)[0m -----------------------
[2m[36m(pid=425132)[0m 
[2m[36m(pid=425132)[0m -----------------------
[2m[36m(pid=425132)[0m ring length: 508
[2m[36m(pid=425132)[0m v_max: 3.059726235247059
[2m[36m(pid=425132)[0m -----------------------
[2m[36m(pid=425132)[0m 
[2m[36m(pid=425132)[0m -----------------------
[2m[36m(pid=425132)[0m ring length: 517
[2m[36m(pid=425132)[0m v_max: 3.2396436965475437
[2m[36m(pid=425132)[0m -----------------------
[2m[36m(pid=425132)[0m 
[2m[36m(pid=425132)[0m -----------------------
[2m[36m(pid=425132)[0m ring length: 519
[2m[36m(pid=425132)[0m v_max: 3.2796229229775036
[2m[36m(pid=425132)[0m -----------------------
[2m[36m(pid=425132)[0m 
[2m[36m(pid=425132)[0m -----------------------
[2m[36m(pid=425132)[0m ring length: 518
[2m[36m(pid=425132)[0m v_max: 3.2596334266284783
[2m[36m(pid=425132)[0m -----------------------
Result for PPO_WaveAttenuationPOEnv-v0_0:
  custom_metrics: {}
  date: 2020-03-30_10-54-36
  done: false
  episode_len_mean: 2000.0
  episode_reward_max: 4949.432659911163
  episode_reward_mean: 4620.441879332309
  episode_reward_min: 4351.814508430616
  episodes_this_iter: 5
  episodes_total: 465
  experiment_id: ba0edb931dde48dcb020df4b454540a2
  hostname: p0035.ten.osc.edu
  info:
    grad_time_ms: 218.66
    learner:
      default_policy:
        cur_kl_coeff: 9.094947153254554e-14
        cur_lr: 4.999999873689376e-05
        entropy: -0.25753119587898254
        entropy_coeff: 0.0
        kl: 0.008243967778980732
        policy_loss: -0.0012619232293218374
        total_loss: 4540.806640625
        vf_explained_var: 1.1920928955078125e-07
        vf_loss: 4540.80712890625
    load_time_ms: 1.936
    num_steps_sampled: 930000
    num_steps_trained: 930000
    sample_time_ms: 100064.545
    update_time_ms: 2.023
  iterations_since_restore: 43
  node_ip: 10.4.1.36
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 2.6694444444444443
    ram_util_percent: 5.3999999999999995
  pid: 424867
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 6.8876435078576375
    mean_inference_ms: 0.5320264278242058
    mean_processing_ms: 2.619800228734693
  time_since_restore: 4334.075073480606
  time_this_iter_s: 101.1718180179596
  time_total_s: 9374.837954044342
  timestamp: 1585580076
  timesteps_since_restore: 430000
  timesteps_this_iter: 10000
  timesteps_total: 930000
  training_iteration: 93
  trial_id: fce6b7f4
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2/2 CPUs, 0/0 GPUs
Memory usage on this node: 10.8/201.2 GB
Result logdir: /users/PYS1027/chnrhughes/ray_results/simple_training_example_ring2_v1
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - PPO_WaveAttenuationPOEnv-v0_0:	RUNNING, 1 failures: /users/PYS1027/chnrhughes/ray_results/simple_training_example_ring2_v1/PPO_WaveAttenuationPOEnv-v0_0_2020-03-30_08-14-21aa4md2pi/error_2020-03-30_09-42-11.txt, [2 CPUs, 0 GPUs], [pid=424867], 9374 s, 93 iter, 930000 ts, 4.62e+03 rew

[2m[36m(pid=424867)[0m 2020-03-30 10:54:36,004	WARNING ppo.py:121 -- The magnitude of your environment rewards are more than 462.0x the scale of `vf_clip_param`. This means that it will take more than 462.0 iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.
[2m[36m(pid=425132)[0m 
[2m[36m(pid=425132)[0m -----------------------
[2m[36m(pid=425132)[0m ring length: 502
[2m[36m(pid=425132)[0m v_max: 2.9397722404035362
[2m[36m(pid=425132)[0m -----------------------
[2m[36m(pid=425132)[0m 
[2m[36m(pid=425132)[0m -----------------------
[2m[36m(pid=425132)[0m ring length: 509
[2m[36m(pid=425132)[0m v_max: 3.0797178990784078
[2m[36m(pid=425132)[0m -----------------------
[2m[36m(pid=425132)[0m 
[2m[36m(pid=425132)[0m -----------------------
[2m[36m(pid=425132)[0m ring length: 518
[2m[36m(pid=425132)[0m v_max: 3.2596334266284783
[2m[36m(pid=425132)[0m -----------------------
[2m[36m(pid=425132)[0m 
[2m[36m(pid=425132)[0m -----------------------
[2m[36m(pid=425132)[0m ring length: 495
[2m[36m(pid=425132)[0m v_max: 2.79981792361692
[2m[36m(pid=425132)[0m -----------------------
[2m[36m(pid=425132)[0m 
[2m[36m(pid=425132)[0m -----------------------
[2m[36m(pid=425132)[0m ring length: 493
[2m[36m(pid=425132)[0m v_max: 2.759829537541262
[2m[36m(pid=425132)[0m -----------------------
Result for PPO_WaveAttenuationPOEnv-v0_0:
  custom_metrics: {}
  date: 2020-03-30_10-56-17
  done: false
  episode_len_mean: 2000.0
  episode_reward_max: 4949.432659911163
  episode_reward_mean: 4637.176905287487
  episode_reward_min: 4351.814508430616
  episodes_this_iter: 5
  episodes_total: 470
  experiment_id: ba0edb931dde48dcb020df4b454540a2
  hostname: p0035.ten.osc.edu
  info:
    grad_time_ms: 218.052
    learner:
      default_policy:
        cur_kl_coeff: 4.547473576627277e-14
        cur_lr: 4.999999873689376e-05
        entropy: -0.2616671025753021
        entropy_coeff: 0.0
        kl: 0.006163756363093853
        policy_loss: -0.0007916290196590126
        total_loss: 4512.4921875
        vf_explained_var: 1.7881393432617188e-07
        vf_loss: 4512.49267578125
    load_time_ms: 1.868
    num_steps_sampled: 940000
    num_steps_trained: 940000
    sample_time_ms: 100193.86
    update_time_ms: 2.026
  iterations_since_restore: 44
  node_ip: 10.4.1.36
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 2.6409722222222225
    ram_util_percent: 5.3999999999999995
  pid: 424867
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 6.887797279146738
    mean_inference_ms: 0.5312179004032662
    mean_processing_ms: 2.6196402797930385
  time_since_restore: 4435.1666123867035
  time_this_iter_s: 101.09153890609741
  time_total_s: 9475.92949295044
  timestamp: 1585580177
  timesteps_since_restore: 440000
  timesteps_this_iter: 10000
  timesteps_total: 940000
  training_iteration: 94
  trial_id: fce6b7f4
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2/2 CPUs, 0/0 GPUs
Memory usage on this node: 10.9/201.2 GB
Result logdir: /users/PYS1027/chnrhughes/ray_results/simple_training_example_ring2_v1
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - PPO_WaveAttenuationPOEnv-v0_0:	RUNNING, 1 failures: /users/PYS1027/chnrhughes/ray_results/simple_training_example_ring2_v1/PPO_WaveAttenuationPOEnv-v0_0_2020-03-30_08-14-21aa4md2pi/error_2020-03-30_09-42-11.txt, [2 CPUs, 0 GPUs], [pid=424867], 9475 s, 94 iter, 940000 ts, 4.64e+03 rew

[2m[36m(pid=424867)[0m 2020-03-30 10:56:17,104	WARNING ppo.py:121 -- The magnitude of your environment rewards are more than 464.0x the scale of `vf_clip_param`. This means that it will take more than 464.0 iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.
[2m[36m(pid=425132)[0m 
[2m[36m(pid=425132)[0m -----------------------
[2m[36m(pid=425132)[0m ring length: 492
[2m[36m(pid=425132)[0m v_max: 2.739835119766572
[2m[36m(pid=425132)[0m -----------------------
[2m[36m(pid=425132)[0m 
[2m[36m(pid=425132)[0m -----------------------
[2m[36m(pid=425132)[0m ring length: 504
[2m[36m(pid=425132)[0m v_max: 2.979757646850631
[2m[36m(pid=425132)[0m -----------------------
[2m[36m(pid=425132)[0m 
[2m[36m(pid=425132)[0m -----------------------
[2m[36m(pid=425132)[0m ring length: 495
[2m[36m(pid=425132)[0m v_max: 2.79981792361692
[2m[36m(pid=425132)[0m -----------------------
[2m[36m(pid=425132)[0m 
[2m[36m(pid=425132)[0m -----------------------
[2m[36m(pid=425132)[0m ring length: 504
[2m[36m(pid=425132)[0m v_max: 2.979757646850631
[2m[36m(pid=425132)[0m -----------------------
[2m[36m(pid=425132)[0m 
[2m[36m(pid=425132)[0m -----------------------
[2m[36m(pid=425132)[0m ring length: 511
[2m[36m(pid=425132)[0m v_max: 3.1197006223865698
[2m[36m(pid=425132)[0m -----------------------
Result for PPO_WaveAttenuationPOEnv-v0_0:
  custom_metrics: {}
  date: 2020-03-30_10-57-57
  done: false
  episode_len_mean: 2000.0
  episode_reward_max: 4949.432659911163
  episode_reward_mean: 4643.175498906652
  episode_reward_min: 4351.814508430616
  episodes_this_iter: 5
  episodes_total: 475
  experiment_id: ba0edb931dde48dcb020df4b454540a2
  hostname: p0035.ten.osc.edu
  info:
    grad_time_ms: 217.37
    learner:
      default_policy:
        cur_kl_coeff: 2.2737367883136385e-14
        cur_lr: 4.999999873689376e-05
        entropy: -0.287507563829422
        entropy_coeff: 0.0
        kl: 0.003053112654015422
        policy_loss: -0.0007268997142091393
        total_loss: 4245.02197265625
        vf_explained_var: 0.0
        vf_loss: 4245.0224609375
    load_time_ms: 1.876
    num_steps_sampled: 950000
    num_steps_trained: 950000
    sample_time_ms: 100291.954
    update_time_ms: 2.032
  iterations_since_restore: 45
  node_ip: 10.4.1.36
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 2.604895104895105
    ram_util_percent: 5.399999999999999
  pid: 424867
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 6.887998581714296
    mean_inference_ms: 0.5304437401394373
    mean_processing_ms: 2.619469053547661
  time_since_restore: 4535.981205940247
  time_this_iter_s: 100.81459355354309
  time_total_s: 9576.744086503983
  timestamp: 1585580277
  timesteps_since_restore: 450000
  timesteps_this_iter: 10000
  timesteps_total: 950000
  training_iteration: 95
  trial_id: fce6b7f4
  
[2m[36m(pid=424867)[0m 2020-03-30 10:57:57,929	WARNING ppo.py:121 -- The magnitude of your environment rewards are more than 464.0x the scale of `vf_clip_param`. This means that it will take more than 464.0 iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2/2 CPUs, 0/0 GPUs
Memory usage on this node: 10.8/201.2 GB
Result logdir: /users/PYS1027/chnrhughes/ray_results/simple_training_example_ring2_v1
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - PPO_WaveAttenuationPOEnv-v0_0:	RUNNING, 1 failures: /users/PYS1027/chnrhughes/ray_results/simple_training_example_ring2_v1/PPO_WaveAttenuationPOEnv-v0_0_2020-03-30_08-14-21aa4md2pi/error_2020-03-30_09-42-11.txt, [2 CPUs, 0 GPUs], [pid=424867], 9576 s, 95 iter, 950000 ts, 4.64e+03 rew

[2m[36m(pid=425132)[0m 
[2m[36m(pid=425132)[0m -----------------------
[2m[36m(pid=425132)[0m ring length: 505
[2m[36m(pid=425132)[0m v_max: 2.999750077051092
[2m[36m(pid=425132)[0m -----------------------
[2m[36m(pid=425132)[0m 
[2m[36m(pid=425132)[0m -----------------------
[2m[36m(pid=425132)[0m ring length: 507
[2m[36m(pid=425132)[0m v_max: 3.0397343746587766
[2m[36m(pid=425132)[0m -----------------------
[2m[36m(pid=425132)[0m 
[2m[36m(pid=425132)[0m -----------------------
[2m[36m(pid=425132)[0m ring length: 503
[2m[36m(pid=425132)[0m v_max: 2.9597650335315784
[2m[36m(pid=425132)[0m -----------------------
[2m[36m(pid=425132)[0m 
[2m[36m(pid=425132)[0m -----------------------
[2m[36m(pid=425132)[0m ring length: 515
[2m[36m(pid=425132)[0m v_max: 3.199663550695237
[2m[36m(pid=425132)[0m -----------------------
[2m[36m(pid=425132)[0m 
[2m[36m(pid=425132)[0m -----------------------
[2m[36m(pid=425132)[0m ring length: 499
[2m[36m(pid=425132)[0m v_max: 2.8797928146697993
[2m[36m(pid=425132)[0m -----------------------
Result for PPO_WaveAttenuationPOEnv-v0_0:
  custom_metrics: {}
  date: 2020-03-30_10-59-38
  done: false
  episode_len_mean: 2000.0
  episode_reward_max: 4949.432659911163
  episode_reward_mean: 4657.79853234087
  episode_reward_min: 4351.814508430616
  episodes_this_iter: 5
  episodes_total: 480
  experiment_id: ba0edb931dde48dcb020df4b454540a2
  hostname: p0035.ten.osc.edu
  info:
    grad_time_ms: 218.332
    learner:
      default_policy:
        cur_kl_coeff: 1.1368683941568192e-14
        cur_lr: 4.999999873689376e-05
        entropy: -0.2583741843700409
        entropy_coeff: 0.0
        kl: 0.003407201496884227
        policy_loss: -0.001527169020846486
        total_loss: 4560.72802734375
        vf_explained_var: 0.0
        vf_loss: 4560.73046875
    load_time_ms: 1.866
    num_steps_sampled: 960000
    num_steps_trained: 960000
    sample_time_ms: 100400.851
    update_time_ms: 2.034
  iterations_since_restore: 46
  node_ip: 10.4.1.36
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 2.668055555555556
    ram_util_percent: 5.3999999999999995
  pid: 424867
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 6.8882782851053275
    mean_inference_ms: 0.5297040612136642
    mean_processing_ms: 2.6193063670924226
  time_since_restore: 4636.856926441193
  time_this_iter_s: 100.87572050094604
  time_total_s: 9677.619807004929
  timestamp: 1585580378
  timesteps_since_restore: 460000
  timesteps_this_iter: 10000
  timesteps_total: 960000
  training_iteration: 96
  trial_id: fce6b7f4
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2/2 CPUs, 0/0 GPUs
Memory usage on this node: 10.8/201.2 GB
Result logdir: /users/PYS1027/chnrhughes/ray_results/simple_training_example_ring2_v1
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - PPO_WaveAttenuationPOEnv-v0_0:	RUNNING, 1 failures: /users/PYS1027/chnrhughes/ray_results/simple_training_example_ring2_v1/PPO_WaveAttenuationPOEnv-v0_0_2020-03-30_08-14-21aa4md2pi/error_2020-03-30_09-42-11.txt, [2 CPUs, 0 GPUs], [pid=424867], 9677 s, 96 iter, 960000 ts, 4.66e+03 rew

[2m[36m(pid=424867)[0m 2020-03-30 10:59:38,829	WARNING ppo.py:121 -- The magnitude of your environment rewards are more than 466.0x the scale of `vf_clip_param`. This means that it will take more than 466.0 iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.
[2m[36m(pid=425132)[0m 
[2m[36m(pid=425132)[0m -----------------------
[2m[36m(pid=425132)[0m ring length: 492
[2m[36m(pid=425132)[0m v_max: 2.739835119766572
[2m[36m(pid=425132)[0m -----------------------
[2m[36m(pid=425132)[0m 
[2m[36m(pid=425132)[0m -----------------------
[2m[36m(pid=425132)[0m ring length: 502
[2m[36m(pid=425132)[0m v_max: 2.9397722404035362
[2m[36m(pid=425132)[0m -----------------------
[2m[36m(pid=425132)[0m 
[2m[36m(pid=425132)[0m -----------------------
[2m[36m(pid=425132)[0m ring length: 505
[2m[36m(pid=425132)[0m v_max: 2.999750077051092
[2m[36m(pid=425132)[0m -----------------------
[2m[36m(pid=425132)[0m 
[2m[36m(pid=425132)[0m -----------------------
[2m[36m(pid=425132)[0m ring length: 500
[2m[36m(pid=425132)[0m v_max: 2.8997861277614296
[2m[36m(pid=425132)[0m -----------------------
[2m[36m(pid=425132)[0m 
[2m[36m(pid=425132)[0m -----------------------
[2m[36m(pid=425132)[0m ring length: 517
[2m[36m(pid=425132)[0m v_max: 3.2396436965475437
[2m[36m(pid=425132)[0m -----------------------
[2m[36m(pid=424867)[0m 2020-03-30 11:01:19,943	WARNING ppo.py:121 -- The magnitude of your environment rewards are more than 466.0x the scale of `vf_clip_param`. This means that it will take more than 466.0 iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.
Result for PPO_WaveAttenuationPOEnv-v0_0:
  custom_metrics: {}
  date: 2020-03-30_11-01-19
  done: false
  episode_len_mean: 2000.0
  episode_reward_max: 4949.432659911163
  episode_reward_mean: 4658.008079174558
  episode_reward_min: 4351.814508430616
  episodes_this_iter: 5
  episodes_total: 485
  experiment_id: ba0edb931dde48dcb020df4b454540a2
  hostname: p0035.ten.osc.edu
  info:
    grad_time_ms: 219.281
    learner:
      default_policy:
        cur_kl_coeff: 5.684341970784096e-15
        cur_lr: 4.999999873689376e-05
        entropy: -0.26399317383766174
        entropy_coeff: 0.0
        kl: 0.007026643492281437
        policy_loss: -0.0009659606730565429
        total_loss: 4297.5009765625
        vf_explained_var: -1.1920928955078125e-07
        vf_loss: 4297.501953125
    load_time_ms: 1.854
    num_steps_sampled: 970000
    num_steps_trained: 970000
    sample_time_ms: 100496.415
    update_time_ms: 2.018
  iterations_since_restore: 47
  node_ip: 10.4.1.36
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 2.6409722222222225
    ram_util_percent: 5.3999999999999995
  pid: 424867
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 6.888568887010215
    mean_inference_ms: 0.5290265855491773
    mean_processing_ms: 2.6191572407249066
  time_since_restore: 4737.960110664368
  time_this_iter_s: 101.10318422317505
  time_total_s: 9778.722991228104
  timestamp: 1585580479
  timesteps_since_restore: 470000
  timesteps_this_iter: 10000
  timesteps_total: 970000
  training_iteration: 97
  trial_id: fce6b7f4
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2/2 CPUs, 0/0 GPUs
Memory usage on this node: 10.9/201.2 GB
Result logdir: /users/PYS1027/chnrhughes/ray_results/simple_training_example_ring2_v1
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - PPO_WaveAttenuationPOEnv-v0_0:	RUNNING, 1 failures: /users/PYS1027/chnrhughes/ray_results/simple_training_example_ring2_v1/PPO_WaveAttenuationPOEnv-v0_0_2020-03-30_08-14-21aa4md2pi/error_2020-03-30_09-42-11.txt, [2 CPUs, 0 GPUs], [pid=424867], 9778 s, 97 iter, 970000 ts, 4.66e+03 rew

[2m[36m(pid=425132)[0m 
[2m[36m(pid=425132)[0m -----------------------
[2m[36m(pid=425132)[0m ring length: 496
[2m[36m(pid=425132)[0m v_max: 2.819811886031332
[2m[36m(pid=425132)[0m -----------------------
[2m[36m(pid=425132)[0m 
[2m[36m(pid=425132)[0m -----------------------
[2m[36m(pid=425132)[0m ring length: 501
[2m[36m(pid=425132)[0m v_max: 2.919779270736568
[2m[36m(pid=425132)[0m -----------------------
[2m[36m(pid=425132)[0m 
[2m[36m(pid=425132)[0m -----------------------
[2m[36m(pid=425132)[0m ring length: 494
[2m[36m(pid=425132)[0m v_max: 2.7798238064662253
[2m[36m(pid=425132)[0m -----------------------
[2m[36m(pid=425132)[0m 
[2m[36m(pid=425132)[0m -----------------------
[2m[36m(pid=425132)[0m ring length: 501
[2m[36m(pid=425132)[0m v_max: 2.919779270736568
[2m[36m(pid=425132)[0m -----------------------
[2m[36m(pid=425132)[0m 
[2m[36m(pid=425132)[0m -----------------------
[2m[36m(pid=425132)[0m ring length: 515
[2m[36m(pid=425132)[0m v_max: 3.199663550695237
[2m[36m(pid=425132)[0m -----------------------
Result for PPO_WaveAttenuationPOEnv-v0_0:
  custom_metrics: {}
  date: 2020-03-30_11-03-01
  done: false
  episode_len_mean: 2000.0
  episode_reward_max: 4949.432659911163
  episode_reward_mean: 4662.618726200437
  episode_reward_min: 4351.814508430616
  episodes_this_iter: 5
  episodes_total: 490
  experiment_id: ba0edb931dde48dcb020df4b454540a2
  hostname: p0035.ten.osc.edu
  info:
    grad_time_ms: 220.864
    learner:
      default_policy:
        cur_kl_coeff: 2.842170985392048e-15
        cur_lr: 4.999999873689376e-05
        entropy: -0.26746517419815063
        entropy_coeff: 0.0
        kl: 0.005574584007263184
        policy_loss: -0.0005308212130330503
        total_loss: 4368.1318359375
        vf_explained_var: 0.0
        vf_loss: 4368.1318359375
    load_time_ms: 1.929
    num_steps_sampled: 980000
    num_steps_trained: 980000
    sample_time_ms: 100601.887
    update_time_ms: 2.035
  iterations_since_restore: 48
  node_ip: 10.4.1.36
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 2.6222222222222222
    ram_util_percent: 5.3999999999999995
  pid: 424867
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 6.888913133996769
    mean_inference_ms: 0.5283820764691624
    mean_processing_ms: 2.6190309121856252
  time_since_restore: 4839.071668148041
  time_this_iter_s: 101.1115574836731
  time_total_s: 9879.834548711777
  timestamp: 1585580581
  timesteps_since_restore: 480000
  timesteps_this_iter: 10000
  timesteps_total: 980000
  training_iteration: 98
  trial_id: fce6b7f4
  
[2m[36m(pid=424867)[0m 2020-03-30 11:03:01,065	WARNING ppo.py:121 -- The magnitude of your environment rewards are more than 466.0x the scale of `vf_clip_param`. This means that it will take more than 466.0 iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2/2 CPUs, 0/0 GPUs
Memory usage on this node: 10.9/201.2 GB
Result logdir: /users/PYS1027/chnrhughes/ray_results/simple_training_example_ring2_v1
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - PPO_WaveAttenuationPOEnv-v0_0:	RUNNING, 1 failures: /users/PYS1027/chnrhughes/ray_results/simple_training_example_ring2_v1/PPO_WaveAttenuationPOEnv-v0_0_2020-03-30_08-14-21aa4md2pi/error_2020-03-30_09-42-11.txt, [2 CPUs, 0 GPUs], [pid=424867], 9879 s, 98 iter, 980000 ts, 4.66e+03 rew

[2m[36m(pid=425132)[0m 
[2m[36m(pid=425132)[0m -----------------------
[2m[36m(pid=425132)[0m ring length: 490
[2m[36m(pid=425132)[0m v_max: 2.699845849180192
[2m[36m(pid=425132)[0m -----------------------
[2m[36m(pid=425132)[0m 
[2m[36m(pid=425132)[0m -----------------------
[2m[36m(pid=425132)[0m ring length: 505
[2m[36m(pid=425132)[0m v_max: 2.999750077051092
[2m[36m(pid=425132)[0m -----------------------
[2m[36m(pid=425132)[0m 
[2m[36m(pid=425132)[0m -----------------------
[2m[36m(pid=425132)[0m ring length: 492
[2m[36m(pid=425132)[0m v_max: 2.739835119766572
[2m[36m(pid=425132)[0m -----------------------
[2m[36m(pid=425132)[0m 
[2m[36m(pid=425132)[0m -----------------------
[2m[36m(pid=425132)[0m ring length: 507
[2m[36m(pid=425132)[0m v_max: 3.0397343746587766
[2m[36m(pid=425132)[0m -----------------------
[2m[36m(pid=425132)[0m 
[2m[36m(pid=425132)[0m -----------------------
[2m[36m(pid=425132)[0m ring length: 510
[2m[36m(pid=425132)[0m v_max: 3.0997093626421153
[2m[36m(pid=425132)[0m -----------------------
Result for PPO_WaveAttenuationPOEnv-v0_0:
  custom_metrics: {}
  date: 2020-03-30_11-04-41
  done: false
  episode_len_mean: 2000.0
  episode_reward_max: 4949.432659911163
  episode_reward_mean: 4664.573198814459
  episode_reward_min: 4351.814508430616
  episodes_this_iter: 5
  episodes_total: 495
  experiment_id: ba0edb931dde48dcb020df4b454540a2
  hostname: p0035.ten.osc.edu
  info:
    grad_time_ms: 222.032
    learner:
      default_policy:
        cur_kl_coeff: 1.421085492696024e-15
        cur_lr: 4.999999873689376e-05
        entropy: -0.28526851534843445
        entropy_coeff: 0.0
        kl: 0.004017094615846872
        policy_loss: -0.0006041820743121207
        total_loss: 4392.98779296875
        vf_explained_var: 1.1920928955078125e-07
        vf_loss: 4392.98779296875
    load_time_ms: 1.937
    num_steps_sampled: 990000
    num_steps_trained: 990000
    sample_time_ms: 100648.254
    update_time_ms: 2.034
  iterations_since_restore: 49
  node_ip: 10.4.1.36
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 2.6244755244755242
    ram_util_percent: 5.399999999999999
  pid: 424867
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 6.889241102552039
    mean_inference_ms: 0.5276598394405427
    mean_processing_ms: 2.6188951127101996
  time_since_restore: 4939.554332017899
  time_this_iter_s: 100.48266386985779
  time_total_s: 9980.317212581635
  timestamp: 1585580681
  timesteps_since_restore: 490000
  timesteps_this_iter: 10000
  timesteps_total: 990000
  training_iteration: 99
  trial_id: fce6b7f4
  
[2m[36m(pid=424867)[0m 2020-03-30 11:04:41,557	WARNING ppo.py:121 -- The magnitude of your environment rewards are more than 466.0x the scale of `vf_clip_param`. This means that it will take more than 466.0 iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2/2 CPUs, 0/0 GPUs
Memory usage on this node: 10.9/201.2 GB
Result logdir: /users/PYS1027/chnrhughes/ray_results/simple_training_example_ring2_v1
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - PPO_WaveAttenuationPOEnv-v0_0:	RUNNING, 1 failures: /users/PYS1027/chnrhughes/ray_results/simple_training_example_ring2_v1/PPO_WaveAttenuationPOEnv-v0_0_2020-03-30_08-14-21aa4md2pi/error_2020-03-30_09-42-11.txt, [2 CPUs, 0 GPUs], [pid=424867], 9980 s, 99 iter, 990000 ts, 4.66e+03 rew

[2m[36m(pid=425132)[0m 
[2m[36m(pid=425132)[0m -----------------------
[2m[36m(pid=425132)[0m ring length: 501
[2m[36m(pid=425132)[0m v_max: 2.919779270736568
[2m[36m(pid=425132)[0m -----------------------
[2m[36m(pid=425132)[0m 
[2m[36m(pid=425132)[0m -----------------------
[2m[36m(pid=425132)[0m ring length: 502
[2m[36m(pid=425132)[0m v_max: 2.9397722404035362
[2m[36m(pid=425132)[0m -----------------------
[2m[36m(pid=425132)[0m 
[2m[36m(pid=425132)[0m -----------------------
[2m[36m(pid=425132)[0m ring length: 490
[2m[36m(pid=425132)[0m v_max: 2.699845849180192
[2m[36m(pid=425132)[0m -----------------------
[2m[36m(pid=425132)[0m 
[2m[36m(pid=425132)[0m -----------------------
[2m[36m(pid=425132)[0m ring length: 493
[2m[36m(pid=425132)[0m v_max: 2.759829537541262
[2m[36m(pid=425132)[0m -----------------------
[2m[36m(pid=425132)[0m 
[2m[36m(pid=425132)[0m -----------------------
[2m[36m(pid=425132)[0m ring length: 509
[2m[36m(pid=425132)[0m v_max: 3.0797178990784078
[2m[36m(pid=425132)[0m -----------------------
Result for PPO_WaveAttenuationPOEnv-v0_0:
  custom_metrics: {}
  date: 2020-03-30_11-06-22
  done: false
  episode_len_mean: 2000.0
  episode_reward_max: 4949.432659911163
  episode_reward_mean: 4670.17254776682
  episode_reward_min: 4351.814508430616
  episodes_this_iter: 5
  episodes_total: 500
  experiment_id: ba0edb931dde48dcb020df4b454540a2
  hostname: p0035.ten.osc.edu
  info:
    grad_time_ms: 222.719
    learner:
      default_policy:
        cur_kl_coeff: 7.10542746348012e-16
        cur_lr: 4.999999873689376e-05
        entropy: -0.2908955216407776
        entropy_coeff: 0.0
        kl: 0.00793102104216814
        policy_loss: -0.0008532455540262163
        total_loss: 4333.73828125
        vf_explained_var: 0.0
        vf_loss: 4333.740234375
    load_time_ms: 1.933
    num_steps_sampled: 1000000
    num_steps_trained: 1000000
    sample_time_ms: 100601.992
    update_time_ms: 2.05
  iterations_since_restore: 50
  node_ip: 10.4.1.36
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 2.672027972027972
    ram_util_percent: 5.399999999999999
  pid: 424867
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 6.889562157259252
    mean_inference_ms: 0.5268092551373442
    mean_processing_ms: 2.6187636015576543
  time_since_restore: 5040.079493761063
  time_this_iter_s: 100.52516174316406
  time_total_s: 10080.842374324799
  timestamp: 1585580782
  timesteps_since_restore: 500000
  timesteps_this_iter: 10000
  timesteps_total: 1000000
  training_iteration: 100
  trial_id: fce6b7f4
  
[2m[36m(pid=424867)[0m 2020-03-30 11:06:22,092	WARNING ppo.py:121 -- The magnitude of your environment rewards are more than 467.0x the scale of `vf_clip_param`. This means that it will take more than 467.0 iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2/2 CPUs, 0/0 GPUs
Memory usage on this node: 10.8/201.2 GB
Result logdir: /users/PYS1027/chnrhughes/ray_results/simple_training_example_ring2_v1
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - PPO_WaveAttenuationPOEnv-v0_0:	RUNNING, 1 failures: /users/PYS1027/chnrhughes/ray_results/simple_training_example_ring2_v1/PPO_WaveAttenuationPOEnv-v0_0_2020-03-30_08-14-21aa4md2pi/error_2020-03-30_09-42-11.txt, [2 CPUs, 0 GPUs], [pid=424867], 10080 s, 100 iter, 1000000 ts, 4.67e+03 rew

[2m[36m(pid=425132)[0m 
[2m[36m(pid=425132)[0m -----------------------
[2m[36m(pid=425132)[0m ring length: 497
[2m[36m(pid=425132)[0m v_max: 2.839805690709741
[2m[36m(pid=425132)[0m -----------------------
[2m[36m(pid=425132)[0m 
[2m[36m(pid=425132)[0m -----------------------
[2m[36m(pid=425132)[0m ring length: 512
[2m[36m(pid=425132)[0m v_max: 3.139691674719026
[2m[36m(pid=425132)[0m -----------------------
[2m[36m(pid=425132)[0m 
[2m[36m(pid=425132)[0m -----------------------
[2m[36m(pid=425132)[0m ring length: 491
[2m[36m(pid=425132)[0m v_max: 2.719840556029452
[2m[36m(pid=425132)[0m -----------------------
[2m[36m(pid=425132)[0m 
[2m[36m(pid=425132)[0m -----------------------
[2m[36m(pid=425132)[0m ring length: 505
[2m[36m(pid=425132)[0m v_max: 2.999750077051092
[2m[36m(pid=425132)[0m -----------------------
[2m[36m(pid=425132)[0m 
[2m[36m(pid=425132)[0m -----------------------
[2m[36m(pid=425132)[0m ring length: 497
[2m[36m(pid=425132)[0m v_max: 2.839805690709741
[2m[36m(pid=425132)[0m -----------------------
Result for PPO_WaveAttenuationPOEnv-v0_0:
  custom_metrics: {}
  date: 2020-03-30_11-08-02
  done: false
  episode_len_mean: 2000.0
  episode_reward_max: 4949.432659911163
  episode_reward_mean: 4681.552714303679
  episode_reward_min: 4359.185059854841
  episodes_this_iter: 5
  episodes_total: 505
  experiment_id: ba0edb931dde48dcb020df4b454540a2
  hostname: p0035.ten.osc.edu
  info:
    grad_time_ms: 223.155
    learner:
      default_policy:
        cur_kl_coeff: 3.55271373174006e-16
        cur_lr: 4.999999873689376e-05
        entropy: -0.320676326751709
        entropy_coeff: 0.0
        kl: 0.0038344613276422024
        policy_loss: -0.001144607551395893
        total_loss: 4416.27294921875
        vf_explained_var: 0.0
        vf_loss: 4416.2734375
    load_time_ms: 2.002
    num_steps_sampled: 1010000
    num_steps_trained: 1010000
    sample_time_ms: 100600.83
    update_time_ms: 2.051
  iterations_since_restore: 51
  node_ip: 10.4.1.36
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 2.613986013986014
    ram_util_percent: 5.399999999999999
  pid: 424867
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 6.889888573892119
    mean_inference_ms: 0.5260207740066265
    mean_processing_ms: 2.618641307010705
  time_since_restore: 5140.630173921585
  time_this_iter_s: 100.55068016052246
  time_total_s: 10181.393054485321
  timestamp: 1585580882
  timesteps_since_restore: 510000
  timesteps_this_iter: 10000
  timesteps_total: 1010000
  training_iteration: 101
  trial_id: fce6b7f4
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2/2 CPUs, 0/0 GPUs
Memory usage on this node: 10.8/201.2 GB
Result logdir: /users/PYS1027/chnrhughes/ray_results/simple_training_example_ring2_v1
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - PPO_WaveAttenuationPOEnv-v0_0:	RUNNING, 1 failures: /users/PYS1027/chnrhughes/ray_results/simple_training_example_ring2_v1/PPO_WaveAttenuationPOEnv-v0_0_2020-03-30_08-14-21aa4md2pi/error_2020-03-30_09-42-11.txt, [2 CPUs, 0 GPUs], [pid=424867], 10181 s, 101 iter, 1010000 ts, 4.68e+03 rew

[2m[36m(pid=424867)[0m 2020-03-30 11:08:02,665	WARNING ppo.py:121 -- The magnitude of your environment rewards are more than 468.0x the scale of `vf_clip_param`. This means that it will take more than 468.0 iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.
[2m[36m(pid=425132)[0m 
[2m[36m(pid=425132)[0m -----------------------
[2m[36m(pid=425132)[0m ring length: 516
[2m[36m(pid=425132)[0m v_max: 3.2196537366217006
[2m[36m(pid=425132)[0m -----------------------
[2m[36m(pid=425132)[0m 
[2m[36m(pid=425132)[0m -----------------------
[2m[36m(pid=425132)[0m ring length: 494
[2m[36m(pid=425132)[0m v_max: 2.7798238064662253
[2m[36m(pid=425132)[0m -----------------------
[2m[36m(pid=425132)[0m 
[2m[36m(pid=425132)[0m -----------------------
[2m[36m(pid=425132)[0m ring length: 494
[2m[36m(pid=425132)[0m v_max: 2.7798238064662253
[2m[36m(pid=425132)[0m -----------------------
[2m[36m(pid=425132)[0m 
[2m[36m(pid=425132)[0m -----------------------
[2m[36m(pid=425132)[0m ring length: 502
[2m[36m(pid=425132)[0m v_max: 2.9397722404035362
[2m[36m(pid=425132)[0m -----------------------
[2m[36m(pid=425132)[0m 
[2m[36m(pid=425132)[0m -----------------------
[2m[36m(pid=425132)[0m ring length: 517
[2m[36m(pid=425132)[0m v_max: 3.2396436965475437
[2m[36m(pid=425132)[0m -----------------------
Result for PPO_WaveAttenuationPOEnv-v0_0:
  custom_metrics: {}
  date: 2020-03-30_11-09-43
  done: false
  episode_len_mean: 2000.0
  episode_reward_max: 4949.432659911163
  episode_reward_mean: 4684.686330162363
  episode_reward_min: 4359.185059854841
  episodes_this_iter: 5
  episodes_total: 510
  experiment_id: ba0edb931dde48dcb020df4b454540a2
  hostname: p0035.ten.osc.edu
  info:
    grad_time_ms: 222.057
    learner:
      default_policy:
        cur_kl_coeff: 1.77635686587003e-16
        cur_lr: 4.999999873689376e-05
        entropy: -0.326905757188797
        entropy_coeff: 0.0
        kl: 0.008642943575978279
        policy_loss: -0.002054415410384536
        total_loss: 4388.99951171875
        vf_explained_var: 0.0
        vf_loss: 4389.0009765625
    load_time_ms: 2.032
    num_steps_sampled: 1020000
    num_steps_trained: 1020000
    sample_time_ms: 100630.758
    update_time_ms: 2.054
  iterations_since_restore: 52
  node_ip: 10.4.1.36
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 2.6215277777777777
    ram_util_percent: 5.3999999999999995
  pid: 424867
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 6.8901430647124675
    mean_inference_ms: 0.5253255185985263
    mean_processing_ms: 2.6185300263715203
  time_since_restore: 5241.5346891880035
  time_this_iter_s: 100.90451526641846
  time_total_s: 10282.29756975174
  timestamp: 1585580983
  timesteps_since_restore: 520000
  timesteps_this_iter: 10000
  timesteps_total: 1020000
  training_iteration: 102
  trial_id: fce6b7f4
  
[2m[36m(pid=424867)[0m 2020-03-30 11:09:43,579	WARNING ppo.py:121 -- The magnitude of your environment rewards are more than 468.0x the scale of `vf_clip_param`. This means that it will take more than 468.0 iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2/2 CPUs, 0/0 GPUs
Memory usage on this node: 10.9/201.2 GB
Result logdir: /users/PYS1027/chnrhughes/ray_results/simple_training_example_ring2_v1
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - PPO_WaveAttenuationPOEnv-v0_0:	RUNNING, 1 failures: /users/PYS1027/chnrhughes/ray_results/simple_training_example_ring2_v1/PPO_WaveAttenuationPOEnv-v0_0_2020-03-30_08-14-21aa4md2pi/error_2020-03-30_09-42-11.txt, [2 CPUs, 0 GPUs], [pid=424867], 10282 s, 102 iter, 1020000 ts, 4.68e+03 rew

[2m[36m(pid=425132)[0m 
[2m[36m(pid=425132)[0m -----------------------
[2m[36m(pid=425132)[0m ring length: 503
[2m[36m(pid=425132)[0m v_max: 2.9597650335315784
[2m[36m(pid=425132)[0m -----------------------
[2m[36m(pid=425132)[0m 
[2m[36m(pid=425132)[0m -----------------------
[2m[36m(pid=425132)[0m ring length: 515
[2m[36m(pid=425132)[0m v_max: 3.199663550695237
[2m[36m(pid=425132)[0m -----------------------
[2m[36m(pid=425132)[0m 
[2m[36m(pid=425132)[0m -----------------------
[2m[36m(pid=425132)[0m ring length: 500
[2m[36m(pid=425132)[0m v_max: 2.8997861277614296
[2m[36m(pid=425132)[0m -----------------------
[2m[36m(pid=425132)[0m 
[2m[36m(pid=425132)[0m -----------------------
[2m[36m(pid=425132)[0m ring length: 510
[2m[36m(pid=425132)[0m v_max: 3.0997093626421153
[2m[36m(pid=425132)[0m -----------------------
[2m[36m(pid=425132)[0m 
[2m[36m(pid=425132)[0m -----------------------
[2m[36m(pid=425132)[0m ring length: 519
[2m[36m(pid=425132)[0m v_max: 3.2796229229775036
[2m[36m(pid=425132)[0m -----------------------
Result for PPO_WaveAttenuationPOEnv-v0_0:
  custom_metrics: {}
  date: 2020-03-30_11-11-24
  done: false
  episode_len_mean: 2000.0
  episode_reward_max: 4974.736066725257
  episode_reward_mean: 4702.272913668509
  episode_reward_min: 4369.315581564296
  episodes_this_iter: 5
  episodes_total: 515
  experiment_id: ba0edb931dde48dcb020df4b454540a2
  hostname: p0035.ten.osc.edu
  info:
    grad_time_ms: 223.325
    learner:
      default_policy:
        cur_kl_coeff: 8.88178432935015e-17
        cur_lr: 4.999999873689376e-05
        entropy: -0.36062827706336975
        entropy_coeff: 0.0
        kl: 0.005100225564092398
        policy_loss: -0.0018515895353630185
        total_loss: 4627.041015625
        vf_explained_var: 0.0
        vf_loss: 4627.04296875
    load_time_ms: 2.049
    num_steps_sampled: 1030000
    num_steps_trained: 1030000
    sample_time_ms: 100588.963
    update_time_ms: 2.05
  iterations_since_restore: 53
  node_ip: 10.4.1.36
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 2.623776223776223
    ram_util_percent: 5.399999999999999
  pid: 424867
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 6.8904280477694035
    mean_inference_ms: 0.5246943808349812
    mean_processing_ms: 2.6184207841824962
  time_since_restore: 5342.302289962769
  time_this_iter_s: 100.76760077476501
  time_total_s: 10383.065170526505
  timestamp: 1585581084
  timesteps_since_restore: 530000
  timesteps_this_iter: 10000
  timesteps_total: 1030000
  training_iteration: 103
  trial_id: fce6b7f4
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2/2 CPUs, 0/0 GPUs
Memory usage on this node: 10.9/201.2 GB
Result logdir: /users/PYS1027/chnrhughes/ray_results/simple_training_example_ring2_v1
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - PPO_WaveAttenuationPOEnv-v0_0:	RUNNING, 1 failures: /users/PYS1027/chnrhughes/ray_results/simple_training_example_ring2_v1/PPO_WaveAttenuationPOEnv-v0_0_2020-03-30_08-14-21aa4md2pi/error_2020-03-30_09-42-11.txt, [2 CPUs, 0 GPUs], [pid=424867], 10383 s, 103 iter, 1030000 ts, 4.7e+03 rew

[2m[36m(pid=424867)[0m 2020-03-30 11:11:24,358	WARNING ppo.py:121 -- The magnitude of your environment rewards are more than 470.0x the scale of `vf_clip_param`. This means that it will take more than 470.0 iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.
[2m[36m(pid=425132)[0m 
[2m[36m(pid=425132)[0m -----------------------
[2m[36m(pid=425132)[0m ring length: 498
[2m[36m(pid=425132)[0m v_max: 2.8597993346145016
[2m[36m(pid=425132)[0m -----------------------
[2m[36m(pid=425132)[0m 
[2m[36m(pid=425132)[0m -----------------------
[2m[36m(pid=425132)[0m ring length: 519
[2m[36m(pid=425132)[0m v_max: 3.2796229229775036
[2m[36m(pid=425132)[0m -----------------------
[2m[36m(pid=425132)[0m 
[2m[36m(pid=425132)[0m -----------------------
[2m[36m(pid=425132)[0m ring length: 509
[2m[36m(pid=425132)[0m v_max: 3.0797178990784078
[2m[36m(pid=425132)[0m -----------------------
[2m[36m(pid=425132)[0m 
[2m[36m(pid=425132)[0m -----------------------
[2m[36m(pid=425132)[0m ring length: 497
[2m[36m(pid=425132)[0m v_max: 2.839805690709741
[2m[36m(pid=425132)[0m -----------------------
[2m[36m(pid=425132)[0m 
[2m[36m(pid=425132)[0m -----------------------
[2m[36m(pid=425132)[0m ring length: 515
[2m[36m(pid=425132)[0m v_max: 3.199663550695237
[2m[36m(pid=425132)[0m -----------------------
Result for PPO_WaveAttenuationPOEnv-v0_0:
  custom_metrics: {}
  date: 2020-03-30_11-13-05
  done: false
  episode_len_mean: 2000.0
  episode_reward_max: 5013.130025603911
  episode_reward_mean: 4720.809307554879
  episode_reward_min: 4369.315581564296
  episodes_this_iter: 5
  episodes_total: 520
  experiment_id: ba0edb931dde48dcb020df4b454540a2
  hostname: p0035.ten.osc.edu
  info:
    grad_time_ms: 223.184
    learner:
      default_policy:
        cur_kl_coeff: 4.440892164675075e-17
        cur_lr: 4.999999873689376e-05
        entropy: -0.3505440056324005
        entropy_coeff: 0.0
        kl: 0.00269607687368989
        policy_loss: -0.0006471460219472647
        total_loss: 4631.11669921875
        vf_explained_var: 1.1920928955078125e-07
        vf_loss: 4631.11669921875
    load_time_ms: 2.069
    num_steps_sampled: 1040000
    num_steps_trained: 1040000
    sample_time_ms: 100550.287
    update_time_ms: 2.068
  iterations_since_restore: 54
  node_ip: 10.4.1.36
  num_healthy_workers: 1
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 2.6777777777777776
    ram_util_percent: 5.3999999999999995
  pid: 424867
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 6.890797547011503
    mean_inference_ms: 0.5241022052356603
    mean_processing_ms: 2.6183334618755474
  time_since_restore: 5443.005926609039
  time_this_iter_s: 100.70363664627075
  time_total_s: 10483.768807172775
  timestamp: 1585581185
  timesteps_since_restore: 540000
  timesteps_this_iter: 10000
  timesteps_total: 1040000
  training_iteration: 104
  trial_id: fce6b7f4
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2/2 CPUs, 0/0 GPUs
Memory usage on this node: 10.9/201.2 GB
Result logdir: /users/PYS1027/chnrhughes/ray_results/simple_training_example_ring2_v1
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - PPO_WaveAttenuationPOEnv-v0_0:	RUNNING, 1 failures: /users/PYS1027/chnrhughes/ray_results/simple_training_example_ring2_v1/PPO_WaveAttenuationPOEnv-v0_0_2020-03-30_08-14-21aa4md2pi/error_2020-03-30_09-42-11.txt, [2 CPUs, 0 GPUs], [pid=424867], 10483 s, 104 iter, 1040000 ts, 4.72e+03 rew

[2m[36m(pid=424867)[0m 2020-03-30 11:13:05,071	WARNING ppo.py:121 -- The magnitude of your environment rewards are more than 472.0x the scale of `vf_clip_param`. This means that it will take more than 472.0 iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.
[2m[36m(pid=425132)[0m 
[2m[36m(pid=425132)[0m -----------------------
[2m[36m(pid=425132)[0m ring length: 505
[2m[36m(pid=425132)[0m v_max: 2.999750077051092
[2m[36m(pid=425132)[0m -----------------------
[2m[36m(pid=425132)[0m 
[2m[36m(pid=425132)[0m -----------------------
[2m[36m(pid=425132)[0m ring length: 511
[2m[36m(pid=425132)[0m v_max: 3.1197006223865698
[2m[36m(pid=425132)[0m -----------------------
[2m[36m(pid=425132)[0m 
[2m[36m(pid=425132)[0m -----------------------
[2m[36m(pid=425132)[0m ring length: 506
[2m[36m(pid=425132)[0m v_max: 3.0197423207835943
[2m[36m(pid=425132)[0m -----------------------
